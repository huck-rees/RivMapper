{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdc864a",
   "metadata": {},
   "source": [
    "# Mobility and Storage Time Calculator\n",
    "\n",
    "The following code takes processed and \"cleaned\" water masks from a specified working directory and performs a series of operations to calculate the: 1) area-based floodplain reworking timescales (TR), channel overlap decay timescales (TM),the reworking efficiency timescale (TM:TR), the channel migration timescale (TW), and distribution of channel areas (AW); 2) the sediment storage time distributions (tstor) using a probabilistic random walk framework; 3) the reach transit times (treach); 4) the total sediment transit time (ttot).\n",
    "\n",
    "Author: James (Huck) Rees; PhD Student, UCSB Geography\n",
    "\n",
    "Date: November 17, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3318a",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "490111fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "import glob as glob_module\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import ast\n",
    "\n",
    "import re\n",
    "import fiona\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio import warp\n",
    "from rasterio.warp import transform_geom, calculate_default_transform, reproject, Resampling\n",
    "from rasterio.enums import Resampling\n",
    "from pyproj import CRS, Geod\n",
    "\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "import geemap\n",
    "import ee\n",
    "from geopy.distance import geodesic\n",
    "from collections import defaultdict\n",
    "\n",
    "# Authenticate with Google Earth Engine\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a54f4",
   "metadata": {},
   "source": [
    "## Initialize functions to calculate floodplain reworking timescale (Tr), channel width timescale (Tm), channel width timescale (Tw) and channel area (Aw) distributions from mobility sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f10752d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_year(filename):\n",
    "    pattern = r\".*_(\\d{4})_DSWE_level_\\d+_cleaned.tif\"\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def get_utm_epsg(lon, lat):\n",
    "    zone_number = int((lon + 180) / 6) + 1\n",
    "    is_northern = lat >= 0\n",
    "    return 32600 + zone_number if is_northern else 32700 + zone_number\n",
    "\n",
    "def get_aw_dist(base_directory, output_directory, reach_range=None):\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    reach_dirs = [d for d in os.listdir(base_directory) if d.startswith(\"reach_\") and os.path.isdir(os.path.join(base_directory, d))]\n",
    "\n",
    "    for reach_dir in reach_dirs:\n",
    "        try:\n",
    "            reach_number = int(reach_dir.split('_')[1])\n",
    "\n",
    "            if isinstance(reach_range, int) and reach_number != reach_range:\n",
    "                continue\n",
    "            elif isinstance(reach_range, tuple) and not (reach_range[0] <= reach_number <= reach_range[1]):\n",
    "                continue\n",
    "\n",
    "            cleaned_dir = os.path.join(base_directory, reach_dir, \"Cleaned\")\n",
    "            if not os.path.exists(cleaned_dir):\n",
    "                print(f\"Cleaned folder not found for Reach {reach_number}.\")\n",
    "                continue\n",
    "\n",
    "            tif_files = [f for f in os.listdir(cleaned_dir) if f.endswith(\".tif\")]\n",
    "            aw_values = []\n",
    "\n",
    "            for tif_file in tif_files:\n",
    "                with rasterio.open(os.path.join(cleaned_dir, tif_file)) as src:\n",
    "                    data = src.read(1)\n",
    "                    transform = src.transform\n",
    "                    bounds = src.bounds\n",
    "                    centroid_lon = (bounds.left + bounds.right) / 2\n",
    "                    centroid_lat = (bounds.top + bounds.bottom) / 2\n",
    "                    utm_epsg = get_utm_epsg(centroid_lon, centroid_lat)\n",
    "\n",
    "                    dst_crs = CRS.from_epsg(utm_epsg)\n",
    "                    transform_utm, width, height = calculate_default_transform(\n",
    "                        src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "\n",
    "                    reprojected = np.empty((height, width), dtype=data.dtype)\n",
    "\n",
    "                    reproject(\n",
    "                        source=data,\n",
    "                        destination=reprojected,\n",
    "                        src_transform=transform,\n",
    "                        src_crs=src.crs,\n",
    "                        dst_transform=transform_utm,\n",
    "                        dst_crs=dst_crs,\n",
    "                        resampling=Resampling.nearest\n",
    "                    )\n",
    "\n",
    "                    pixel_area = abs(transform_utm.a * transform_utm.e)\n",
    "                    wet_pixel_count = np.sum(reprojected == 1)\n",
    "                    total_area_m2 = wet_pixel_count * pixel_area\n",
    "                    aw_values.append(total_area_m2)\n",
    "\n",
    "            output_df = pd.DataFrame({'A_w_m2': aw_values})\n",
    "            output_csv = os.path.join(output_directory, f\"Reach_{reach_number}_aw_dist.csv\")\n",
    "            output_df.to_csv(output_csv, index=False)\n",
    "\n",
    "            print(f\"Saved corrected A_w totals for Reach {reach_number} to {output_csv}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing reach folder {reach_dir}: {e}\")\n",
    "\n",
    "def load_rasters(directory):\n",
    "    rasters = {}\n",
    "    wetted_areas = []\n",
    "    for filepath in os.listdir(directory):\n",
    "        if filepath.endswith('.tif'):\n",
    "            year = extract_year(filepath)\n",
    "            if year is not None:\n",
    "                with rasterio.open(os.path.join(directory, filepath)) as src:\n",
    "                    data = src.read(1)\n",
    "                    transform = src.transform\n",
    "                    pixel_area = abs(transform[0] * transform[4])\n",
    "                    wetted_area_km2 = np.sum(data == 1) * pixel_area / 1e6\n",
    "                    wetted_areas.append(wetted_area_km2)\n",
    "                    rasters[year] = (data == 1, pixel_area)\n",
    "    median_aw = np.median(wetted_areas)\n",
    "    return dict(sorted(rasters.items())), median_aw\n",
    "\n",
    "def calculate_reworked_areas(rasters):\n",
    "    delta_t_areas = defaultdict(list)\n",
    "    years = sorted(rasters.keys())\n",
    "    for i in range(len(years)):\n",
    "        t1 = years[i]\n",
    "        base_mask, pixel_area = rasters[t1]\n",
    "        union_mask = np.copy(base_mask)\n",
    "        for j in range(i + 1, len(years)):\n",
    "            t2 = years[j]\n",
    "            current_mask, _ = rasters[t2]\n",
    "            union_mask = np.logical_or(union_mask, current_mask)\n",
    "            reworked_pixels = np.sum(union_mask) - np.sum(base_mask)\n",
    "            delta_t = t2 - t1\n",
    "            reworked_area_km2 = (reworked_pixels * pixel_area) / 1e6\n",
    "            delta_t_areas[delta_t].append(reworked_area_km2)\n",
    "    return delta_t_areas\n",
    "\n",
    "def calculate_overlap_areas(rasters):\n",
    "    \"\"\"\n",
    "    Calculate the overlap area (A_m) between baseline and future channel positions.\n",
    "    \n",
    "    For each baseline year, calculates the intersection area with all future years,\n",
    "    representing pixels that remain channelized between the two time points.\n",
    "    \n",
    "    Parameters:\n",
    "        rasters (dict): Dictionary mapping years to tuples of (binary_mask, pixel_area)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary mapping delta_t values to lists of overlap areas in km²\n",
    "    \"\"\"\n",
    "    delta_t_areas = defaultdict(list)\n",
    "    years = sorted(rasters.keys())\n",
    "    \n",
    "    for i in range(len(years)):\n",
    "        t1 = years[i]\n",
    "        base_mask, pixel_area = rasters[t1]\n",
    "        \n",
    "        for j in range(i + 1, len(years)):\n",
    "            t2 = years[j]\n",
    "            current_mask, _ = rasters[t2]\n",
    "            \n",
    "            # Calculate intersection (overlap) between baseline and current mask\n",
    "            overlap_mask = np.logical_and(base_mask, current_mask)\n",
    "            overlap_pixels = np.sum(overlap_mask)\n",
    "            \n",
    "            delta_t = t2 - t1\n",
    "            overlap_area_km2 = (overlap_pixels * pixel_area) / 1e6\n",
    "            delta_t_areas[delta_t].append(overlap_area_km2)\n",
    "    \n",
    "    return delta_t_areas\n",
    "\n",
    "def reworking_exponential(x, Pr_over_AW, Cr):\n",
    "    return -Pr_over_AW * np.exp(-Cr * x) + Pr_over_AW\n",
    "\n",
    "def overlap_exponential(x, Pm_over_AW, Cm):\n",
    "    \"\"\"\n",
    "    Exponential model for channel overlap decay.\n",
    "    \n",
    "    A_M/AW = (1 - Pm_over_AW) * exp(-Cm * x) + Pm_over_AW\n",
    "    \n",
    "    Args:\n",
    "        x: Time (years)\n",
    "        Pm_over_AW: Asymptotic minimum of overlap (normalized by active width)\n",
    "        Cm: Overlap decay rate (year^-1)\n",
    "    \n",
    "    Returns:\n",
    "        Predicted overlap area normalized by active width\n",
    "    \"\"\"\n",
    "    return (1 - Pm_over_AW) * np.exp(-Cm * x) + Pm_over_AW\n",
    "\n",
    "def calculate_pswitch(Tm_over_Tr,  P10=0.57413, P90=2.21004):\n",
    "    \"\"\"\n",
    "    Map Tm:Tr to pswitch using 10th-90th percentile range with physical bounds.\n",
    "    \n",
    "    Maps P10 (inefficient reworking) → 0.50 (high switching)\n",
    "    Maps P90 (efficient reworking) → 0.05 (minimal but non-zero switching)\n",
    "    \n",
    "    Physical justification for pswitch >= 0.05:\n",
    "    - All rivers experience some stochasticity (floods, bank failures, cutoffs)\n",
    "    - Prevents numerical instabilities in Monte Carlo simulations\n",
    "    - Consistent with observed behavior of highly efficient systems (Yukon ≈ 0.06)\n",
    "    \n",
    "    Args:\n",
    "        Tm_over_Tr (float): Ratio of overlap decay timescale to floodplain reworking timescales\n",
    "        P10 (float): 10th percentile of Tm:Tr in dataset (default 0.57413)\n",
    "        P90 (float): 90th percentile of Tm:Tr in dataset (default 2.21004)\n",
    "    \n",
    "    Returns:\n",
    "        float: Switching probability [0.05, 0.50]\n",
    "    \"\"\"\n",
    "    # Linear mapping from [P10, P90] to [0.50, 0.05]\n",
    "    pswitch = 0.50 - 0.45 * ((Tm_over_Tr - P10) / (P90 - P10))\n",
    "    \n",
    "    # Clamp to physical bounds\n",
    "    pswitch = max(0.05, min(0.50, pswitch))\n",
    "    \n",
    "    return pswitch\n",
    "\n",
    "def calculate_Tw(delta_ts, Pr_over_AW, Cr, subsample_n=20):\n",
    "    \"\"\"\n",
    "    Calculate the channel width timescale (Tw) by subsampling \n",
    "    the Greenberg exponential fit and performing linear regression.\n",
    "    \n",
    "    This timescale represents the time required to rework one channel width (Aw)\n",
    "    of floodplain, calculated from the linear approximation of the exponential\n",
    "    reworking curve.\n",
    "    \n",
    "    Parameters:\n",
    "        delta_ts (list or array): Time intervals from the reworked area data\n",
    "        Pr_over_AW (float): Plateau parameter from Greenberg exponential fit\n",
    "        Cr (float): Decay rate from Greenberg exponential fit (year^-1)\n",
    "        subsample_n (int): Number of points to subsample for linear regression (default 20)\n",
    "    \n",
    "    Returns:\n",
    "        float: Tw, the linear channel migration timescale (years)\n",
    "    \"\"\"\n",
    "    # Define the range for subsampling\n",
    "    min_dt = min(delta_ts)\n",
    "    max_dt = max(delta_ts)\n",
    "    \n",
    "    # Subsample the fitted exponential curve\n",
    "    subsample_delta_t = np.linspace(min_dt, max_dt, subsample_n)\n",
    "    subsample_ar_aw = reworking_exponential(subsample_delta_t, Pr_over_AW, Cr)\n",
    "    \n",
    "    # Perform linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(subsample_delta_t, subsample_ar_aw)\n",
    "    \n",
    "    # Calculate Tw as inverse of slope\n",
    "    Tw = 1 / slope\n",
    "    \n",
    "    return Tw\n",
    "\n",
    "def plot_mobility_fits(river_name, ds_order, delta_ts_rework, data_rework, Pr_over_AW, Cr, Tr,\n",
    "                       delta_ts_overlap, data_overlap, Pm_over_AW, Cm, Tm, output_path,\n",
    "                       show_timescale_lines=True, show_equations=False):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Calculate x-axis limits for reworking plot\n",
    "    x_min_rework = (min(delta_ts_rework) // 5) * 5\n",
    "    x_max_rework = ((max(delta_ts_rework) + 4) // 5) * 5\n",
    "    \n",
    "    # Plot 1: Reworked Area with box plots\n",
    "    bp1 = ax1.boxplot(data_rework, positions=delta_ts_rework, widths=0.8, patch_artist=True)\n",
    "    for patch in bp1['boxes']:\n",
    "        patch.set_facecolor('lightblue')\n",
    "    \n",
    "    # TR timescale line\n",
    "    if show_timescale_lines:\n",
    "        ax1.plot([0, Tr], [0, 1], 'k--', linewidth=1.5, alpha=0.7, zorder=2)\n",
    "    \n",
    "    # Fitted curve for reworked area\n",
    "    x_fit_rework = np.linspace(min(delta_ts_rework), max(delta_ts_rework), 200)\n",
    "    y_fit_rework = reworking_exponential(x_fit_rework, Pr_over_AW, Cr)\n",
    "    ax1.plot(x_fit_rework, y_fit_rework, 'r-', linewidth=2, zorder=3)\n",
    "    \n",
    "    # Add equation to plot\n",
    "    if show_equations:\n",
    "        equation_text_1 = f'$A_{{R}}/A_{{W}} = {Pr_over_AW:.3f}(1 - e^{{-{Cr:.4f}t}})$\\n$T_{{R}} = {Tr:.2f}$ years'\n",
    "        ax1.text(0.05, 0.95, equation_text_1, transform=ax1.transAxes, \n",
    "                fontsize=18, verticalalignment='top', \n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax1.set_xlabel('Time interval (years)', fontsize=12)\n",
    "    ax1.set_ylabel('$A_{R} / A_{W}$ (Reworked area : Wetted area)', fontsize=12)\n",
    "    ax1.set_title(f'{river_name} reach {ds_order}: floodplain reworking', fontsize=12)\n",
    "    tick_positions = np.arange(x_min_rework, x_max_rework + 1, 5)\n",
    "    ax1.set_xticks(tick_positions)\n",
    "    ax1.set_xticklabels(tick_positions)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xlim(x_min_rework, x_max_rework + 1)\n",
    "    ax1.set_ylim(0, Pr_over_AW)\n",
    "    \n",
    "    # Calculate x-axis limits for overlap plot\n",
    "    x_min_overlap = (min(delta_ts_overlap) // 5) * 5\n",
    "    x_max_overlap = ((max(delta_ts_overlap) + 4) // 5) * 5\n",
    "    \n",
    "    # Plot 2: Overlap Decay with box plots\n",
    "    bp2 = ax2.boxplot(data_overlap, positions=delta_ts_overlap, widths=0.8, patch_artist=True)\n",
    "    for patch in bp2['boxes']:\n",
    "        patch.set_facecolor('lightgreen')\n",
    "    \n",
    "    # TM timescale line\n",
    "    if show_timescale_lines:\n",
    "        ax2.plot([0, Tm], [1, 0], 'k--', linewidth=1.5, alpha=0.7, zorder=2)\n",
    "    \n",
    "    # Fitted curve for overlap decay\n",
    "    x_fit_overlap = np.linspace(min(delta_ts_overlap), max(delta_ts_overlap), 200)\n",
    "    y_fit_overlap = overlap_exponential(x_fit_overlap, Pm_over_AW, Cm)\n",
    "    ax2.plot(x_fit_overlap, y_fit_overlap, 'b-', linewidth=2, zorder=3)\n",
    "    \n",
    "    # Add equation to plot\n",
    "    if show_equations:\n",
    "        equation_text_2 = f'$A_{{M}}/A_{{W}} = {1-Pm_over_AW:.3f}e^{{-{Cm:.4f}t}} + {Pm_over_AW:.3f}$\\n$T_{{M}} = {Tm:.2f}$ years'\n",
    "        ax2.text(0.05, 0.95, equation_text_2, transform=ax2.transAxes, \n",
    "                fontsize=11, verticalalignment='top', \n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax2.set_xlabel('Time interval (years)', fontsize=12)\n",
    "    ax2.set_ylabel('$A_{M} / A_{W}$ (Overlap area : Wetted area)', fontsize=12)\n",
    "    ax2.set_title(f'{river_name} reach {ds_order}: overlap decay', fontsize=12)\n",
    "    tick_positions = np.arange(x_min_overlap, x_max_overlap + 1, 5)\n",
    "    ax2.set_xticks(tick_positions)\n",
    "    ax2.set_xticklabels(tick_positions)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xlim(x_min_overlap, x_max_overlap + 1)\n",
    "    ax2.set_ylim(Pm_over_AW, 1)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved mobility plots to {output_path}\")\n",
    "\n",
    "def calculate_mobility(river_name, ds_order, working_directory):\n",
    "    \"\"\"\n",
    "    Calculate mobility metrics (Tr, Tm, Cr, Cm, Tw, pswitch) for a single river reach.\n",
    "    \n",
    "    This function analyzes channel overlap decay data to extract floodplain reworking\n",
    "    and overlap decay characteristics. It fits exponential models to both reworked\n",
    "    area and overlap area data, then calculates characteristic timescales.\n",
    "    \n",
    "    Parameters:\n",
    "        river_name (str): Name of the river being analyzed.\n",
    "        ds_order (int): Reach number (downstream order).\n",
    "        working_directory (str): Base path to the working directory containing RiverMapping data.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing:\n",
    "              - Tr (float): Floodplain reworking timescale (years)\n",
    "              - Tm (float): overlap decay timescale (years)\n",
    "              - Tw (float): Linear floodplain reworking timescale (years)\n",
    "              - Cr (float): Floodplain reworking decay rate (year^-1)\n",
    "              - Cm (float): overlap decay rate (year^-1)\n",
    "    \n",
    "    Outputs:\n",
    "        - CSV file: Active width distribution saved to Mobility/{river_name}/AW_distributions/\n",
    "        - PNG plots: Fitted curves for reworked and overlap areas saved to Mobility/{river_name}/MobilityPlots/\n",
    "    \"\"\"\n",
    "    # Define paths\n",
    "    base_raster_dir = f\"{working_directory}/RiverMapping/RiverMasks/{river_name}\"\n",
    "    reach_dir = f\"reach_{ds_order}\"\n",
    "    full_path = os.path.join(base_raster_dir, reach_dir, \"Cleaned\")\n",
    "    \n",
    "    output_dir = f\"{working_directory}/RiverMapping/Mobility/{river_name}\"\n",
    "    aw_output_dir = os.path.join(output_dir, \"AW_distributions\")\n",
    "    plot_output_dir = os.path.join(output_dir, \"Mobility_plots\")\n",
    "    os.makedirs(aw_output_dir, exist_ok=True)\n",
    "    os.makedirs(plot_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate AW distribution using get_aw_dist()\n",
    "    get_aw_dist(base_raster_dir, aw_output_dir, reach_range=ds_order)\n",
    "    \n",
    "    # Load the generated AW distribution\n",
    "    aw_csv_path = os.path.join(aw_output_dir, f\"Reach_{ds_order}_aw_dist.csv\")\n",
    "    aw_distribution = pd.read_csv(aw_csv_path)\n",
    "    \n",
    "    # Load rasters and calculate median active width\n",
    "    rasters, median_aw = load_rasters(full_path)\n",
    "    \n",
    "    # Calculate reworked areas\n",
    "    delta_t_areas = calculate_reworked_areas(rasters)\n",
    "    delta_ts_rework = sorted(delta_t_areas.keys())\n",
    "    data_rework = [[val / median_aw for val in delta_t_areas[dt]] for dt in delta_ts_rework]\n",
    "    medians_rework = [np.median(vals) for vals in data_rework]\n",
    "    \n",
    "    # Fit Greenberg exponential to reworked area data\n",
    "    x_data_rework = np.array(delta_ts_rework)\n",
    "    y_data_rework = np.array(medians_rework)\n",
    "    initial_guess_rework = [max(y_data_rework), 0.1]\n",
    "    popt_rework, _ = curve_fit(reworking_exponential, x_data_rework, y_data_rework, p0=initial_guess_rework)\n",
    "    Pr_over_AW, Cr = popt_rework\n",
    "    \n",
    "    # Calculate TR\n",
    "    Tr = (1 / Cr) * (1 / Pr_over_AW)\n",
    "    \n",
    "    # Calculate Tw (channel width timescale)\n",
    "    Tw = calculate_Tw(delta_ts_rework, Pr_over_AW, Cr)\n",
    "    \n",
    "    # Calculate overlap areas\n",
    "    delta_t_overlap = calculate_overlap_areas(rasters)\n",
    "    delta_ts_overlap = sorted(delta_t_overlap.keys())\n",
    "    data_overlap = [[val / median_aw for val in delta_t_overlap[dt]] for dt in delta_ts_overlap]\n",
    "    medians_overlap = [np.median(vals) for vals in data_overlap]\n",
    "    \n",
    "    # Fit overlap exponential to overlap data\n",
    "    x_data_overlap = np.array(delta_ts_overlap)\n",
    "    y_data_overlap = np.array(medians_overlap)\n",
    "    initial_guess_overlap = [max(y_data_overlap), 0.1]\n",
    "    popt_overlap, _ = curve_fit(overlap_exponential, x_data_overlap, y_data_overlap, p0=initial_guess_overlap)\n",
    "    Pm_over_AW, Cm = popt_overlap\n",
    "    \n",
    "    # Calculate Tm\n",
    "    Tm = (1 / Cm) * (1 / (1 - Pm_over_AW))\n",
    "    \n",
    "    # Calculate floodplain reworking efficiency ratio\n",
    "    Tm_over_Tr = Tm / Tr\n",
    "    \n",
    "    # Calculate pswitch\n",
    "    pswitch = calculate_pswitch(Tm_over_Tr)\n",
    "    \n",
    "    # Create plots\n",
    "    plot_path = os.path.join(plot_output_dir, f\"Reach_{ds_order}_mobility_fits.png\")\n",
    "    plot_mobility_fits(river_name, ds_order, delta_ts_rework, data_rework, Pr_over_AW, Cr, Tr,\n",
    "                       delta_ts_overlap, data_overlap, Pm_over_AW, Cm, Tm, plot_path)\n",
    "    \n",
    "    # Return results\n",
    "    results = {\n",
    "        'Tr_yr': Tr,\n",
    "        'Tw_yr': Tw,\n",
    "        'Tm_over_Tr': Tm_over_Tr,\n",
    "        'Tm_yr': Tm,\n",
    "        'Cr_peryr': Cr,\n",
    "        'Cm_peryr': Cm,\n",
    "        'median_Aw_m2': median_aw,\n",
    "        'Pr_over_Aw': Pr_over_AW,\n",
    "        'Pm_over_Aw': Pm_over_AW,\n",
    "        'Pswitch': pswitch\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "    \n",
    "def get_mobility(csv_path):\n",
    "    \"\"\"\n",
    "    Iterates through a CSV file of river names and paths, calculating mobility metrics\n",
    "    (Tr, Tm, Tw, Cr, Cm) for each reach as specified.\n",
    "    \n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file with columns:\n",
    "                        - river_name\n",
    "                        - working_directory\n",
    "                        - reach_range (e.g., \"All\", \"(1, 3)\", or \"2\")\n",
    "    \n",
    "    Outputs:\n",
    "        CSV file: Mobility metrics saved to Mobility/{river_name}/{river_name}_mobility_metrics.csv\n",
    "                  with columns: ds_order, Tr_yr, Tm_yr, Tw_yr, Cr_peryr, Cm_peryr, median_Aw_m2, Pr_over_Aw, Pm_over_Aw\n",
    "    \"\"\"\n",
    "    river_data = pd.read_csv(csv_path)\n",
    "    \n",
    "    for _, row in river_data.iterrows():\n",
    "        river_name = row['river_name']\n",
    "        working_directory = row['working_directory']\n",
    "        reach_range = row['reach_range']\n",
    "        \n",
    "        # Define base directory for raster masks\n",
    "        base_raster_dir = f\"{working_directory}/RiverMapping/RiverMasks/{river_name}\"\n",
    "        output_dir = f\"{working_directory}/RiverMapping/Mobility/{river_name}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Parse reach_range to determine which reaches to process\n",
    "        reach_dirs = [d for d in os.listdir(base_raster_dir) if d.startswith(\"reach_\")]\n",
    "        available_reaches = sorted([int(d.split('_')[1]) for d in reach_dirs])\n",
    "        \n",
    "        if isinstance(reach_range, str):\n",
    "            reach_range = reach_range.strip()\n",
    "            if reach_range == \"All\":\n",
    "                reaches_to_process = available_reaches\n",
    "            elif reach_range.startswith(\"(\") and reach_range.endswith(\")\"):\n",
    "                # Parse tuple format like \"(1, 3)\"\n",
    "                reach_start, reach_end = map(int, reach_range.strip(\"()\").split(\",\"))\n",
    "                reaches_to_process = [r for r in available_reaches if reach_start <= r <= reach_end]\n",
    "            else:\n",
    "                # Single reach number\n",
    "                reaches_to_process = [int(reach_range)]\n",
    "        elif isinstance(reach_range, int):\n",
    "            reaches_to_process = [reach_range]\n",
    "        elif isinstance(reach_range, tuple):\n",
    "            reach_start, reach_end = reach_range\n",
    "            reaches_to_process = [r for r in available_reaches if reach_start <= r <= reach_end]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid reach_range format: {reach_range}\")\n",
    "        \n",
    "        # Calculate mobility metrics for each reach\n",
    "        all_results = []\n",
    "        \n",
    "        for ds_order in reaches_to_process:\n",
    "            try:\n",
    "                print(f\"Processing {river_name} Reach {ds_order}...\")\n",
    "                results = calculate_mobility(river_name, ds_order, working_directory)\n",
    "                \n",
    "                # Add ds_order to results\n",
    "                results['ds_order'] = ds_order\n",
    "                all_results.append(results)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {river_name} Reach {ds_order}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Compile results into DataFrame\n",
    "        if all_results:\n",
    "            results_df = pd.DataFrame(all_results)\n",
    "            \n",
    "            # Reorder columns for clarity\n",
    "            column_order = ['ds_order', 'Tr_yr', 'Tm_yr', 'Tm_over_Tr', 'Tw_yr', 'Cr_peryr', 'Cm_peryr', 'median_Aw_m2', 'Pr_over_Aw', 'Pm_over_Aw', 'Pswitch']\n",
    "            results_df = results_df[column_order]\n",
    "            \n",
    "            # Sort by ds_order\n",
    "            results_df = results_df.sort_values('ds_order')\n",
    "            \n",
    "            # Save to CSV\n",
    "            output_csv = os.path.join(output_dir, f\"{river_name}_mobility_metrics.csv\")\n",
    "            results_df.to_csv(output_csv, index=False)\n",
    "            print(f\"Saved mobility metrics for {river_name} to {output_csv}\")\n",
    "        else:\n",
    "            print(f\"No results generated for {river_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f34d64",
   "metadata": {},
   "source": [
    "## Initialize functions to calculate first-passage time distributions AKA sediment storage time distributions (Tstor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "935c57a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def import_aw_distribution(river_name, reach_number, working_directory):\n",
    "    \"\"\"\n",
    "    Imports the AW distribution for a specified reach.\n",
    "\n",
    "    Args:\n",
    "        river_name (str): Name of the river.\n",
    "        reach_number (int): Reach number to import AW distribution.\n",
    "        working_directory (str): Base working directory containing the river data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the AW distribution for the specified reach.\n",
    "    \"\"\"\n",
    "    # Define base directory for AW distributions\n",
    "    aw_dir = os.path.join(working_directory, 'RiverMapping', 'Mobility', river_name, 'Aw_distributions')\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(aw_dir):\n",
    "        raise FileNotFoundError(f\"Aw distribution directory not found: {aw_dir}\")\n",
    "\n",
    "    # Load AW distribution for the specified reach\n",
    "    aw_file = os.path.join(aw_dir, f\"Reach_{reach_number}_aw_dist.csv\")\n",
    "    if not os.path.isfile(aw_file):\n",
    "        raise FileNotFoundError(f\"Aw file not found: {aw_file}\")\n",
    "\n",
    "    aw_distribution = pd.read_csv(aw_file)\n",
    "\n",
    "    return aw_distribution\n",
    "\n",
    "def calculate_tstor_distribution(channel_belt_area, aw_distribution, tw, pswitch, num_iterations=10000, max_timesteps=10000):\n",
    "    \"\"\"\n",
    "    Calculates the Tstor distribution for a single reach using the random walk/single event model and returns the result.\n",
    "    \n",
    "    The channel undergoes a random walk, sampling Aw values from the distribution at each timestep,\n",
    "    until it returns to its starting position x0.\n",
    "    \n",
    "    Args:\n",
    "        channel_belt_area (float): Channel belt area (in square km) for the reach.\n",
    "        aw_distribution (DataFrame): DataFrame with column 'A_w_m2' (in square m).\n",
    "        tw (float): Lateral migration timescale.\n",
    "        pswitch (float): The probability of the channel switching direction at each timestep tw.\n",
    "        num_iterations (int): Number of simulations to run (default 10000).\n",
    "        max_timesteps (int): Maximum timesteps per simulation (default 10000).\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the TFP distribution.\n",
    "    \"\"\"\n",
    "    # Convert channel belt area from km² to m²\n",
    "    channel_belt_area_m2 = channel_belt_area * 1_000_000\n",
    "    \n",
    "    if aw_distribution.empty:\n",
    "        raise ValueError(\"Aw distribution is empty.\")\n",
    "    \n",
    "    # Extract all AW values for random sampling\n",
    "    aw_values = aw_distribution['A_w_m2'].values\n",
    "    \n",
    "    tfp_times = []\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        x0 = np.random.uniform(0, channel_belt_area_m2)\n",
    "        x = x0\n",
    "        total_time = 0\n",
    "        timestep_count = 0\n",
    "        current_direction = np.random.choice([-1, 1])  # Initialize first direction randomly\n",
    "        \n",
    "        while timestep_count < max_timesteps:\n",
    "            # Sample a new AW value for this timestep\n",
    "            aw_step = np.random.choice(aw_values)\n",
    "            \n",
    "            # Determine direction based on switching probability\n",
    "            if np.random.random() < pswitch:\n",
    "                # Switch direction\n",
    "                current_direction = -current_direction\n",
    "            # else: keep the same direction\n",
    "            \n",
    "            direction = current_direction\n",
    "            x_intended = x + direction * aw_step\n",
    "            \n",
    "            reflection_occurred = False\n",
    "            \n",
    "            # Reflect at boundaries\n",
    "            if x_intended < 0:\n",
    "                x_new = -x_intended\n",
    "                reflection_occurred = True\n",
    "            elif x_intended > channel_belt_area_m2:\n",
    "                x_new = 2 * channel_belt_area_m2 - x_intended\n",
    "                reflection_occurred = True\n",
    "            else:\n",
    "                x_new = x_intended\n",
    "            \n",
    "            # Check if we've crossed x0 (returned to starting position)\n",
    "            crossed = False\n",
    "            \n",
    "            if reflection_occurred:\n",
    "                if (x_intended < x0 and x_new >= x0) or (x_intended > x0 and x_new <= x0) or (timestep_count > 0 and x == x0 and x_new != x0):\n",
    "                    crossed = True\n",
    "            else:\n",
    "                if (x_new >= x0 and x < x0) or (x_new <= x0 and x > x0):\n",
    "                    crossed = True\n",
    "            \n",
    "            if crossed:\n",
    "                # Calculate fractional time\n",
    "                if reflection_occurred:\n",
    "                    if x_intended < 0:\n",
    "                        distance_to_boundary = abs(x - 0)\n",
    "                        distance_from_boundary_to_x0 = abs(x0 - 0)\n",
    "                        total_distance_to_x0 = distance_to_boundary + distance_from_boundary_to_x0\n",
    "                    else:\n",
    "                        distance_to_boundary = abs(channel_belt_area_m2 - x)\n",
    "                        distance_from_boundary_to_x0 = abs(channel_belt_area_m2 - x0)\n",
    "                        total_distance_to_x0 = distance_to_boundary + distance_from_boundary_to_x0\n",
    "                    \n",
    "                    fractional_tw = (total_distance_to_x0 / aw_step) * tw\n",
    "                else:\n",
    "                    remaining_distance = abs(x0 - x)\n",
    "                    fractional_tw = (remaining_distance / aw_step) * tw\n",
    "                \n",
    "                total_time += fractional_tw\n",
    "                break\n",
    "            \n",
    "            total_time += tw\n",
    "            x = x_new\n",
    "            timestep_count += 1\n",
    "        \n",
    "        if timestep_count < max_timesteps:\n",
    "            tfp_times.append(total_time)\n",
    "    \n",
    "    result_df = pd.DataFrame({'Tstor_yr': tfp_times})\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def get_tstor_distributions(csv_path):\n",
    "    \"\"\"\n",
    "    Processes a range of reaches from a CSV file and calculates TFP distributions for each.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing river name, working directory, and reach range.\n",
    "\n",
    "    Outputs:\n",
    "        CSV files containing Tstor distributions for each processed reach.\n",
    "    \"\"\"\n",
    "    # Load the configuration CSV\n",
    "    config_data = pd.read_csv(csv_path)\n",
    "\n",
    "    for index, row in config_data.iterrows():\n",
    "        # Extract river name, reach range, and working directory for each row\n",
    "        river_name = row['river_name']\n",
    "        reach_range = row['reach_range']\n",
    "        working_directory = row['working_directory']\n",
    "        num_iterations = row['model_iterations']\n",
    "        max_timesteps = row['max_timesteps']\n",
    "\n",
    "        # Define directories for required inputs\n",
    "        channel_belt_file = os.path.join(working_directory, 'ChannelBelts', 'Extracted_ChannelBelts', river_name, f\"{river_name}_channelbelt_areas.csv\")\n",
    "\n",
    "        # Check if the required files exist\n",
    "        if not os.path.isfile(channel_belt_file):\n",
    "            raise FileNotFoundError(f\"Channel belt areas file not found: {channel_belt_file}\")\n",
    "        \n",
    "        # Load channel belt areas data\n",
    "        channel_belt_data = pd.read_csv(channel_belt_file)\n",
    "\n",
    "        # Load mobility metrics file once per river\n",
    "        mobility_file = os.path.join(working_directory, 'RiverMapping', 'Mobility', river_name, f\"{river_name}_mobility_metrics.csv\")\n",
    "        if not os.path.isfile(mobility_file):\n",
    "            raise FileNotFoundError(f\"Mobility metrics file not found: {mobility_file}\")\n",
    "        mobility_all_reaches = pd.read_csv(mobility_file)\n",
    "\n",
    "        # Determine the reach range\n",
    "        if isinstance(reach_range, str):\n",
    "            reach_range = reach_range.strip()  # Remove any extra spaces\n",
    "\n",
    "            if reach_range == \"All\":\n",
    "                reach_start = channel_belt_data['ds_order'].min()\n",
    "                reach_end = channel_belt_data['ds_order'].max()\n",
    "            elif reach_range.isdigit():\n",
    "                # Convert a numeric string to an integer\n",
    "                reach_range = int(reach_range)\n",
    "                reach_start = reach_range\n",
    "                reach_end = reach_range\n",
    "            elif re.match(r'^\\(\\d{1,4}, \\d{1,4}\\)$', reach_range):  # Match (XX, YY) with 1 to 4 digits\n",
    "                try:\n",
    "                    # Convert the string to a tuple of integers\n",
    "                    reach_range = ast.literal_eval(reach_range)\n",
    "                    reach_start, reach_end = reach_range\n",
    "                except (ValueError, SyntaxError):\n",
    "                    raise ValueError(f\"Invalid reach range format: {reach_range}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid string format for reach_range: {reach_range}\")\n",
    "        elif isinstance(reach_range, (int, float)) and float(reach_range).is_integer():\n",
    "            # Convert float-like integers (e.g., 7.0) to int\n",
    "            reach_range = int(reach_range)\n",
    "            reach_start = reach_range\n",
    "            reach_end = reach_range\n",
    "        elif isinstance(reach_range, tuple) and len(reach_range) == 2:\n",
    "            reach_start, reach_end = reach_range\n",
    "        else:\n",
    "            raise ValueError(\"reach_range must be 'All', an int, or a tuple (start, end).\")\n",
    "\n",
    "        # Generate range of reaches to process\n",
    "        reaches = range(reach_start, reach_end + 1)\n",
    "\n",
    "        # Iterate through the range of reaches and calculate Tstor for each\n",
    "        for reach_number in reaches:\n",
    "            # Get Tr and Cr values for this reach\n",
    "            tw = mobility_all_reaches.loc[mobility_all_reaches['ds_order'] == reach_number, 'Tw_yr'].values[0]\n",
    "            pswitch = mobility_all_reaches.loc[mobility_all_reaches['ds_order'] == reach_number, 'Pswitch'].values[0]\n",
    "\n",
    "            # Get channel belt area for the reach\n",
    "            channel_belt_area = channel_belt_data.loc[channel_belt_data['ds_order'] == reach_number, 'area_sq_km'].values[0]\n",
    "\n",
    "            # Import AW distribution for the reach\n",
    "            aw_distribution = import_aw_distribution(river_name, reach_number, working_directory)\n",
    "\n",
    "            # Calculate the Tstor distribution for the reach\n",
    "            tstor_distribution = calculate_tstor_distribution(channel_belt_area, aw_distribution, tw, pswitch, num_iterations, max_timesteps)\n",
    "\n",
    "            # Save Tstor distribution to a CSV (fixed typo: sinlge -> single)\n",
    "            output_file = os.path.join(working_directory, 'RiverMapping', 'Mobility', river_name, 'Tstor_distributions', f\"Reach_{reach_number}_Tstor_distribution.csv\")\n",
    "            os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "            tstor_distribution.to_csv(output_file, index=False)\n",
    "\n",
    "            print(f\"Tstor distribution for Reach {reach_number} saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bc7b87",
   "metadata": {},
   "source": [
    "## Initialize functions to run Monte Carlo simulation to calculate reach transit time (t_reach) from the number of storage events (n) and storage time (tstor) distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7838d83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def monte_carlo_reach_transit_time(\n",
    "    tstor_df,\n",
    "    transit_df,\n",
    "    reach_number,\n",
    "    num_iterations = 10000\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Monte Carlo simulation of reach transit times using tstor sampling based on fractional 'n_stor'.\n",
    "    \n",
    "    Parameters:\n",
    "        tstor_df (pd.DataFrame): One-column DataFrame of storage time values (e.g. 'Tstor_yr').\n",
    "        transit_df (pd.DataFrame): DataFrame with 'ds_order' and 'n_stor' columns.\n",
    "        reach_number (int): Reach number (ds_order) for simulation.\n",
    "        num_iterations (int): Number of Monte Carlo simulations to run.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame of simulated transit times.\n",
    "    \"\"\"\n",
    "    # Clean and check input\n",
    "    transit_df.columns = transit_df.columns.str.strip()\n",
    "    if \"ds_order\" not in transit_df or \"n_stor\" not in transit_df:\n",
    "        raise KeyError(\"transit_df must contain 'ds_order' and 'n_stor' columns.\")\n",
    "    \n",
    "    if tstor_df.shape[1] != 1:\n",
    "        raise ValueError(\"tstor_df must contain exactly one column.\")\n",
    "    \n",
    "    tstor_vals = tstor_df.iloc[:, 0].dropna().values\n",
    "    if len(tstor_vals) == 0:\n",
    "        raise ValueError(\"No valid storage time data found.\")\n",
    "    \n",
    "    # Extract n_stor\n",
    "    n_array = transit_df.loc[transit_df[\"ds_order\"] == reach_number, \"n_stor\"].values\n",
    "    if len(n_array) == 0:\n",
    "        raise ValueError(f\"Reach {reach_number} not found in transit_df.\")\n",
    "    \n",
    "    n = float(n_array[0])\n",
    "    int_part = int(np.floor(n))\n",
    "    frac_part = n - int_part\n",
    "    \n",
    "    results = []\n",
    "    for _ in range(num_iterations):\n",
    "        # Handle the integer part\n",
    "        if int_part > 0:\n",
    "            samples = np.random.choice(tstor_vals, size=int_part, replace=True)\n",
    "            total = samples.sum()\n",
    "        else:\n",
    "            total = 0.0\n",
    "        \n",
    "        # Handle the fractional part\n",
    "        if np.random.rand() < frac_part:\n",
    "            extra = np.random.choice(tstor_vals)\n",
    "            total += extra\n",
    "        \n",
    "        results.append(total)\n",
    "    \n",
    "    return pd.DataFrame({\"treach_yr\": results})\n",
    "\n",
    "def get_reach_transittimes(work_dir: str, river_name: str):\n",
    "    \"\"\"\n",
    "    Processes all reach transit time distributions for a given river.\n",
    "    \n",
    "    Parameters:\n",
    "        work_dir (str): Path to the working directory containing relevant data files.\n",
    "        river_name (str): Name of the river to process.\n",
    "    \"\"\"\n",
    "    # Path to transit length (storage) values\n",
    "    nstor_path = os.path.join(work_dir, \"RiverMapping\", \"Mobility\", river_name, f\"{river_name}_transit_lengths.csv\")\n",
    "    nstor_vals = pd.read_csv(nstor_path)\n",
    "    \n",
    "    # Path where Tstor distribution files are stored\n",
    "    tstor_dir = os.path.join(work_dir, \"RiverMapping\", \"Mobility\", river_name, \"Tstor_distributions\")\n",
    "    tstor_files = {\n",
    "        file: pd.read_csv(os.path.join(tstor_dir, file))\n",
    "        for file in os.listdir(tstor_dir)\n",
    "        if file.endswith(\".csv\") and file.startswith(\"Reach_\")\n",
    "    }\n",
    "    \n",
    "    # Prepare output directory\n",
    "    output_dir = os.path.join(work_dir, \"RiverMapping\", \"Mobility\", river_name, \"treach_distributions\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each reach\n",
    "    for filename, tstor_df in tstor_files.items():\n",
    "        try:\n",
    "            reach_number = int(filename.split(\"_\")[1])\n",
    "            reach_transit_time_df = monte_carlo_reach_transit_time(tstor_df, nstor_vals, reach_number)\n",
    "            output_path = os.path.join(output_dir, f\"Reach_{reach_number}_treach_distribution.csv\")\n",
    "            reach_transit_time_df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c577c1e",
   "metadata": {},
   "source": [
    "## Calculate distributions for total alluvial transit time (t_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05e5a24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_ttot_statistics(directory: str):\n",
    "    \"\"\"\n",
    "    Calculates and saves statistics for all total transit time distribution CSV files\n",
    "    found in the given directory.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Directory containing ttot distribution CSV files.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(directory) if f.endswith(\"_distribution.csv\")]\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        ttt_df = pd.read_csv(file_path)\n",
    "\n",
    "        if \"ttot_yr\" not in ttt_df.columns:\n",
    "            print(f\"Skipping {file} — missing 'ttot_yr' column.\")\n",
    "            continue\n",
    "\n",
    "        # Compute statistics for all columns\n",
    "        stats_list = []\n",
    "        for column in ttt_df.columns:\n",
    "            stats_list.append({\n",
    "                \"Variable\": column,\n",
    "                \"Mean\": np.mean(ttt_df[column]),\n",
    "                \"Standard Deviation\": np.std(ttt_df[column]),\n",
    "                \"Min\": np.min(ttt_df[column]),\n",
    "                \"1st Quartile\": np.percentile(ttt_df[column], 25),\n",
    "                \"Median\": np.median(ttt_df[column]),\n",
    "                \"3rd Quartile\": np.percentile(ttt_df[column], 75),\n",
    "                \"Max\": np.max(ttt_df[column])\n",
    "            })\n",
    "\n",
    "        stats_df = pd.DataFrame(stats_list)\n",
    "\n",
    "        # Build output file name\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        stats_file = f\"{base_name}_stats.csv\"\n",
    "        stats_path = os.path.join(directory, stats_file)\n",
    "        stats_df.to_csv(stats_path, index=False)\n",
    "        print(f\"Saved stats: {stats_path}\")\n",
    "\n",
    "def get_total_transit_times(working_dir: str, river_name: str, num_iterations: int = 10_000, reach_start: int = 1, reach_end: int = None):\n",
    "    \"\"\"\n",
    "    Runs a Monte Carlo simulation to compute the total river transit time distribution,\n",
    "    and includes the sampled reach-level transit times for each iteration.\n",
    "    \n",
    "    Parameters:\n",
    "        working_dir (str): Root directory containing the data folder structure.\n",
    "        river_name (str): Name of the river for output file naming.\n",
    "        num_iterations (int): Number of iterations for the Monte Carlo simulation (default is 10,000).\n",
    "        reach_start (int): Index of the first reach to include (1-based, inclusive).\n",
    "        reach_end (int): Index of the last reach to include (1-based, inclusive). If None, includes all reaches to the end.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the total river transit time and individual reach samples.\n",
    "    \"\"\"\n",
    "    rtt_dir = os.path.join(working_dir, 'RiverMapping', 'Mobility', river_name, 'treach_distributions')\n",
    "    all_rtt_files = os.listdir(rtt_dir)\n",
    "    \n",
    "    # Determine reach range\n",
    "    reach_end = reach_end if reach_end is not None else 100\n",
    "    \n",
    "    selected_reach_dfs = []\n",
    "    actual_reaches = []\n",
    "    \n",
    "    for reach_num in range(reach_start, reach_end + 1):\n",
    "        expected_filename = f\"Reach_{reach_num}_treach_distribution.csv\"\n",
    "        file_path = os.path.join(rtt_dir, expected_filename)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            if \"treach_yr\" not in df.columns:\n",
    "                raise KeyError(f\"Missing 'treach_yr' column in file: {expected_filename}\")\n",
    "            selected_reach_dfs.append(df)\n",
    "            actual_reaches.append(reach_num)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Expected file not found: {expected_filename}\")\n",
    "    \n",
    "    simulation_results = []\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        sampled_reach_times = [np.random.choice(df[\"treach_yr\"], 1)[0] for df in selected_reach_dfs]\n",
    "        total_time = sum(sampled_reach_times)\n",
    "        simulation_results.append(sampled_reach_times + [total_time])\n",
    "    \n",
    "    # Build DataFrame with individual reach samples and total time\n",
    "    columns = [f\"reach_{reach}_tt_yr\" for reach in actual_reaches] + [\"ttot_yr\"]\n",
    "    simulation_df = pd.DataFrame(simulation_results, columns=columns)\n",
    "    \n",
    "    # Create output filename reflecting reach range\n",
    "    reach_range_str = f\"R{reach_start}toR{reach_end}\"\n",
    "    output_filename = f\"{river_name}_{reach_range_str}_ttot_distribution.csv\"\n",
    "    output_path = os.path.join(working_dir, 'RiverMapping', 'Mobility', river_name, output_filename)\n",
    "    \n",
    "    simulation_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "    \n",
    "    stats_directory = os.path.join(working_dir, 'RiverMapping', 'Mobility', river_name)\n",
    "    calculate_ttot_statistics(stats_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b1ad2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_path = r\"E:\\Dissertation\\Data\\GreenbergZhao_river_datasheet.csv\"\n",
    "working_directory = r\"E:\\Dissertation\\Data\"\n",
    "river_name = \"Yukon_Beaver\"\n",
    "iterations = 10000\n",
    "reach_start = 1\n",
    "reach_end = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d4f8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Aladan_VerkhoyanskiyPerevoz Reach 1...\n",
      "Saved corrected A_w totals for Reach 1 to E:\\Dissertation\\Data/RiverMapping/Mobility/Aladan_VerkhoyanskiyPerevoz\\AW_distributions\\Reach_1_aw_dist.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved mobility plots to E:\\Dissertation\\Data/RiverMapping/Mobility/Aladan_VerkhoyanskiyPerevoz\\Mobility_plots\\Reach_1_mobility_fits.png\n",
      "Saved mobility metrics for Aladan_VerkhoyanskiyPerevoz to E:\\Dissertation\\Data/RiverMapping/Mobility/Aladan_VerkhoyanskiyPerevoz\\Aladan_VerkhoyanskiyPerevoz_mobility_metrics.csv\n",
      "Processing Amazonas_Jatuarana Reach 1...\n",
      "Saved corrected A_w totals for Reach 1 to E:\\Dissertation\\Data/RiverMapping/Mobility/Amazonas_Jatuarana\\AW_distributions\\Reach_1_aw_dist.csv\n"
     ]
    }
   ],
   "source": [
    "get_mobility(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cd35063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tstor distribution for Reach 1 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Yukon_Beaver\\Tstor_distributions\\Reach_1_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 1 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Koyukuk_Huslia\\Tstor_distributions\\Reach_1_Tstor_distribution.csv\n"
     ]
    }
   ],
   "source": [
    "get_tstor_distributions(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cab2857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_1_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_2_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_3_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_4_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_5_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_6_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_7_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_8_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_9_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_10_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_11_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_12_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_13_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_14_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_15_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_16_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_17_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_18_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_19_treach_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\treach_distributions\\Reach_20_treach_distribution.csv\n"
     ]
    }
   ],
   "source": [
    "get_reach_transittimes(working_directory, river_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d6393fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Bermejo_R1toR20_ttot_distribution.csv\n",
      "Skipping Bermejo_R1toR20_TTT_distribution.csv — missing 'ttot_yr' column.\n",
      "Skipping Bermejo_R1toR3_TTT_distribution.csv — missing 'ttot_yr' column.\n",
      "Skipping Bermejo_R4toR8_TTT_distribution.csv — missing 'ttot_yr' column.\n",
      "Skipping Bermejo_R9toR15_TTT_distribution.csv — missing 'ttot_yr' column.\n",
      "Skipping Bermejo_R16toR20_TTT_distribution.csv — missing 'ttot_yr' column.\n",
      "Saved stats: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Bermejo_R1toR20_ttot_distribution_stats.csv\n"
     ]
    }
   ],
   "source": [
    "get_total_transit_times(working_directory, river_name, iterations, reach_start, reach_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24f39b1",
   "metadata": {},
   "source": [
    "## This checks what reaches have successfully calculated mobility metrics\n",
    "As well as the number of masks that exist for each reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62cb56ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Aladan_VerkhoyanskiyPerevoz...\n",
      "  Reach 1: 18 masks, Mobility CSV: yes\n",
      "Checking Amazonas_Jatuarana...\n",
      "  Reach 1: 36 masks, Mobility CSV: yes\n",
      "Checking Amur_Komsomolsk...\n",
      "  Reach 1: 37 masks, Mobility CSV: yes\n",
      "Checking Benue_Umaisha...\n",
      "  Reach 1: 19 masks, Mobility CSV: yes\n",
      "Checking BolshayaKet_Rodyonovka...\n",
      "  Reach 1: 22 masks, Mobility CSV: yes\n",
      "Checking Brahmaputra_Pasighat...\n",
      "  Reach 1: 37 masks, Mobility CSV: yes\n",
      "Checking Chari_Bousso...\n",
      "  Reach 1: 20 masks, Mobility CSV: yes\n",
      "Checking Chari_Guelengdeng...\n",
      "  Reach 1: 18 masks, Mobility CSV: no\n",
      "Checking Chari_Ndjamena...\n",
      "  Reach 1: 18 masks, Mobility CSV: no\n",
      "Checking Chari_Sahr...\n",
      "  Reach 1: 20 masks, Mobility CSV: no\n",
      "Checking Fraser_Hope...\n",
      "  Reach 1: 38 masks, Mobility CSV: yes\n",
      "Checking Gandak_Devghat...\n",
      "  Reach 1: 33 masks, Mobility CSV: yes\n",
      "Checking Helmand_Kajaki...\n",
      "  Reach 1: 34 masks, Mobility CSV: no\n",
      "Checking Helmand_Malakhan...\n",
      "  Reach 1: 30 masks, Mobility CSV: no\n",
      "Checking Indus_Attock...\n",
      "  Reach 1: 33 masks, Mobility CSV: yes\n",
      "Checking Irtysh_Bobrovsky...\n",
      "  Reach 1: 32 masks, Mobility CSV: no\n",
      "Checking Irtysh_Hanti-Mansisk...\n",
      "  Reach 1: 34 masks, Mobility CSV: yes\n",
      "Checking Irtysh_Pavlodar...\n",
      "  Reach 1: 31 masks, Mobility CSV: no\n",
      "Checking Irtysh_Semiyarskoje...\n",
      "  Reach 1: 31 masks, Mobility CSV: yes\n",
      "Checking Jutai_PortoSeguro...\n",
      "  Reach 1: 38 masks, Mobility CSV: yes\n",
      "Checking Kamchatka_Kozyrevsk...\n",
      "  Reach 1: 20 masks, Mobility CSV: yes\n",
      "Checking Kan_Kansk...\n",
      "  Reach 1: 31 masks, Mobility CSV: no\n",
      "Checking MadreDeDios_CachuelaEsperanza...\n",
      "  Reach 1: 38 masks, Mobility CSV: yes\n",
      "Checking Magdalena_Calamar...\n",
      "  Reach 1: 33 masks, Mobility CSV: yes\n",
      "Checking Magdalena_PuertoBerrio...\n",
      "  Reach 1: 31 masks, Mobility CSV: yes\n",
      "Checking Manas_Mathanguri...\n",
      "  Reach 1: 33 masks, Mobility CSV: yes\n",
      "Checking Mbam_Goura...\n",
      "  Reach 1: 19 masks, Mobility CSV: no\n",
      "Checking Mekong_Kratie...\n",
      "  Reach 1: 35 masks, Mobility CSV: yes\n",
      "Checking Niger_Tossaye...\n",
      "  Reach 1: 29 masks, Mobility CSV: yes\n",
      "Checking Ob_Barnaul...\n",
      "  Reach 1: 30 masks, Mobility CSV: no\n",
      "Checking Ob_Kolpashevo...\n",
      "  Reach 1: 22 masks, Mobility CSV: no\n",
      "Checking Ob_Mogochin...\n",
      "  Reach 1: 24 masks, Mobility CSV: yes\n",
      "Checking Ob_Phominskoje...\n",
      "  Reach 1: 31 masks, Mobility CSV: yes\n",
      "Checking Orinoco_CiudadBolivar...\n",
      "  Reach 1: 27 masks, Mobility CSV: no\n",
      "Checking Orinoco_Musinacio...\n",
      "  Reach 1: 34 masks, Mobility CSV: no\n",
      "Checking Paraguay_Asuncion...\n",
      "  Reach 1: 37 masks, Mobility CSV: yes\n",
      "Checking Paraguay_PortoMurtinho...\n",
      "  Reach 1: 36 masks, Mobility CSV: no\n",
      "Checking Parana_Chapeton...\n",
      "  Reach 1: 36 masks, Mobility CSV: no\n",
      "Checking Porcupine_NearFortYukon...\n",
      "  Reach 1: 34 masks, Mobility CSV: no\n",
      "Checking Sangha_Ouesso...\n",
      "  Reach 1: 21 masks, Mobility CSV: yes\n",
      "Checking Solimoes_Itapeua...\n",
      "  Reach 1: 38 masks, Mobility CSV: yes\n",
      "Checking Solimoes_Manacapuru...\n",
      "  Reach 1: 38 masks, Mobility CSV: yes\n",
      "Checking SonghuaJiang_Haerbin...\n",
      "  Reach 1: 37 masks, Mobility CSV: yes\n",
      "Checking Vilyuy_KhatyrykKhoma...\n",
      "  Reach 1: 21 masks, Mobility CSV: yes\n",
      "Checking Yangtze_Datong...\n",
      "  Reach 1: 38 masks, Mobility CSV: yes\n",
      "Checking Yellowstone_NearSidney...\n",
      "  Reach 1: 37 masks, Mobility CSV: yes\n",
      "Checking Yukon_Eagle...\n",
      "  Reach 1: 30 masks, Mobility CSV: yes\n",
      "Checking Zambezi_LukuluMission...\n",
      "  Reach 1: 34 masks, Mobility CSV: yes\n",
      "Checking Zambezi_Matundo-Cais...\n",
      "  Reach 1: 37 masks, Mobility CSV: yes\n",
      "\n",
      "Diagnostic results saved to C:\\Users\\huckr\\Desktop\\UCSB\\Dissertation\\Data\\Code\\Troubleshooting\\reach_mobility_calcs_diagnostics.csv\n",
      "Total reaches checked: 49\n",
      "Reaches with masks: 49\n",
      "Rivers with mobility CSV: 33 yes, 16 no\n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "Mean masks per reach: 30.41\n",
      "Median masks per reach: 33\n",
      "Min masks: 18\n",
      "Max masks: 38\n",
      "\n",
      "Reaches with < 5 masks:\n",
      "  None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def check_reach_diagnostics(input_csv_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    Check mask counts and mobility CSV existence for each reach in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        input_csv_path (str): Path to the Greenberg et al. 2024 river datasheet CSV\n",
    "        output_csv_path (str): Path to save the diagnostic output CSV\n",
    "    \n",
    "    Outputs:\n",
    "        CSV file with columns:\n",
    "            - river_name: Name of the river\n",
    "            - ds_order: Reach number\n",
    "            - num_masks: Count of .tif files in the Cleaned folder\n",
    "            - mobility_csv_exists: 'yes' or 'no' indicating if mobility metrics CSV exists\n",
    "    \"\"\"\n",
    "    # Read the input CSV\n",
    "    river_data = pd.read_csv(input_csv_path)\n",
    "    \n",
    "    # List to store diagnostic results\n",
    "    diagnostics = []\n",
    "    \n",
    "    # Iterate through each river\n",
    "    for _, row in river_data.iterrows():\n",
    "        river_name = row['river_name']\n",
    "        working_directory = row['working_directory']\n",
    "        \n",
    "        print(f\"Checking {river_name}...\")\n",
    "        \n",
    "        # Define paths\n",
    "        base_raster_dir = os.path.join(working_directory, \"RiverMapping\", \"RiverMasks\", river_name)\n",
    "        mobility_csv_path = os.path.join(working_directory, \"RiverMapping\", \"Mobility\", river_name, \n",
    "                                        f\"{river_name}_mobility_metrics.csv\")\n",
    "        \n",
    "        # Check if mobility CSV exists (once per river, applies to all reaches)\n",
    "        mobility_exists = \"yes\" if os.path.exists(mobility_csv_path) else \"no\"\n",
    "        \n",
    "        # Check if base raster directory exists\n",
    "        if not os.path.exists(base_raster_dir):\n",
    "            print(f\"  Warning: Raster directory not found for {river_name}\")\n",
    "            diagnostics.append({\n",
    "                'river_name': river_name,\n",
    "                'ds_order': 'N/A',\n",
    "                'num_masks': 0,\n",
    "                'mobility_csv_exists': mobility_exists\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Find all reach directories\n",
    "        try:\n",
    "            reach_dirs = [d for d in os.listdir(base_raster_dir) \n",
    "                         if d.startswith(\"reach_\") and os.path.isdir(os.path.join(base_raster_dir, d))]\n",
    "            \n",
    "            if not reach_dirs:\n",
    "                print(f\"  Warning: No reach directories found for {river_name}\")\n",
    "                diagnostics.append({\n",
    "                    'river_name': river_name,\n",
    "                    'ds_order': 'N/A',\n",
    "                    'num_masks': 0,\n",
    "                    'mobility_csv_exists': mobility_exists\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Sort reaches numerically\n",
    "            reach_numbers = sorted([int(d.split('_')[1]) for d in reach_dirs])\n",
    "            \n",
    "            # Process each reach\n",
    "            for ds_order in reach_numbers:\n",
    "                cleaned_dir = os.path.join(base_raster_dir, f\"reach_{ds_order}\", \"Cleaned\")\n",
    "                \n",
    "                # Count .tif files\n",
    "                if os.path.exists(cleaned_dir):\n",
    "                    tif_files = [f for f in os.listdir(cleaned_dir) if f.endswith('.tif')]\n",
    "                    num_masks = len(tif_files)\n",
    "                else:\n",
    "                    num_masks = 0\n",
    "                    print(f\"  Warning: Cleaned directory not found for reach {ds_order}\")\n",
    "                \n",
    "                # Add to diagnostics\n",
    "                diagnostics.append({\n",
    "                    'river_name': river_name,\n",
    "                    'ds_order': ds_order,\n",
    "                    'num_masks': num_masks,\n",
    "                    'mobility_csv_exists': mobility_exists\n",
    "                })\n",
    "                \n",
    "                print(f\"  Reach {ds_order}: {num_masks} masks, Mobility CSV: {mobility_exists}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {river_name}: {e}\")\n",
    "            diagnostics.append({\n",
    "                'river_name': river_name,\n",
    "                'ds_order': 'ERROR',\n",
    "                'num_masks': 0,\n",
    "                'mobility_csv_exists': mobility_exists\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    diagnostics_df = pd.DataFrame(diagnostics)\n",
    "    diagnostics_df.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f\"\\nDiagnostic results saved to {output_csv_path}\")\n",
    "    print(f\"Total reaches checked: {len(diagnostics_df)}\")\n",
    "    print(f\"Reaches with masks: {len(diagnostics_df[diagnostics_df['num_masks'] > 0])}\")\n",
    "    print(f\"Rivers with mobility CSV: {diagnostics_df['mobility_csv_exists'].value_counts().get('yes', 0)} yes, {diagnostics_df['mobility_csv_exists'].value_counts().get('no', 0)} no\")\n",
    "    \n",
    "    return diagnostics_df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = r\"E:\\Dissertation\\Data\\Zhaoetal2025_river_datasheet.csv\"\n",
    "    output_csv = r\"C:\\Users\\huckr\\Desktop\\UCSB\\Dissertation\\Data\\Code\\Troubleshooting\\reach_mobility_calcs_diagnostics.csv\"\n",
    "    \n",
    "    results = check_reach_diagnostics(input_csv, output_csv)\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\n=== SUMMARY STATISTICS ===\")\n",
    "    print(f\"Mean masks per reach: {results['num_masks'].mean():.2f}\")\n",
    "    print(f\"Median masks per reach: {results['num_masks'].median():.0f}\")\n",
    "    print(f\"Min masks: {results['num_masks'].min()}\")\n",
    "    print(f\"Max masks: {results['num_masks'].max()}\")\n",
    "    print(f\"\\nReaches with < 5 masks:\")\n",
    "    low_mask_reaches = results[results['num_masks'] < 5]\n",
    "    if len(low_mask_reaches) > 0:\n",
    "        for _, row in low_mask_reaches.iterrows():\n",
    "            print(f\"  {row['river_name']} Reach {row['ds_order']}: {row['num_masks']} masks\")\n",
    "    else:\n",
    "        print(\"  None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3812fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
