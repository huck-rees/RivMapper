{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdc864a",
   "metadata": {},
   "source": [
    "# Mobility and Storage Time Calculator\n",
    "\n",
    "The following code takes processed and \"cleaned\" water masks from a specified working directory and performs four different operations to calculate the area-based channel mobility and the sediment storage time distributions of river reaches. The first operation is conducted by running the \"get_mobility_dfs()\" function which produces dataframes for each reach of the given river, calculating the evolution of wet and dry pixels over time; these dataframes are output as .csvs to local folders. The second operation is conducted by running the get_TR_and_AW_distribution()\" which calculates the lateral channel mobility of each reach (TR) and outputs a .csv with TR by reach, as well as individual .csvs for each reach including all AW values (one from each annual median water mask). The third opertion is conducted by running the get_TCB() function, and calculates a distribution of channel belt turnover times (TCB), outputting them to reach-specific .csvs. The fourth and final operation is conducted by running the get_TFP(), which runs the random walk model and develops a first passage time distriubtion (storage time distribution) that is output as a .csv.\n",
    "\n",
    "Author: James (Huck) Rees; PhD Student, UCSB Geography\n",
    "\n",
    "Date: January 17, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3318a",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490111fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "from glob import glob\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import ast\n",
    "\n",
    "import re\n",
    "import fiona\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio import warp\n",
    "from rasterio.warp import transform_geom\n",
    "from rasterio.enums import Resampling\n",
    "from pyproj import CRS\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "import geemap\n",
    "import ee\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# Authenticate with Google Earth Engine\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c2bec",
   "metadata": {},
   "source": [
    "## Initialize functions to produce mobility dataframes and CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c427763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mobility_yearly(images, mask, scale=30):\n",
    "\n",
    "    A = len(np.where(mask == 1)[1])\n",
    "\n",
    "    year_range = list(images.keys())\n",
    "    ranges = [year_range[i:] for i, yr in enumerate(year_range)]\n",
    "    river_dfs = {}\n",
    "    for yrange in ranges:\n",
    "        data = {\n",
    "            'year': [],\n",
    "            'i': [],\n",
    "            'O_avg': [],\n",
    "            'O_wd': [],\n",
    "            'O_dw': [],\n",
    "            'O_wick': [],\n",
    "            'fR': [],\n",
    "            'fR_wick': [],\n",
    "            'w_b': [],\n",
    "            'd_b': [],\n",
    "        }\n",
    "        length = images[yrange[0]].shape[0]\n",
    "        width = images[yrange[0]].shape[1]\n",
    "        long = len(yrange)\n",
    "        all_images = np.empty((length, width, long))\n",
    "        years = []\n",
    "        for j, year in enumerate(yrange):\n",
    "            years.append(year)\n",
    "            im = images[str(year)].astype(int)\n",
    "            filt = np.where(~np.array(mask) + 2)\n",
    "            im[filt] = 0\n",
    "            all_images[:, :, j] = im\n",
    "\n",
    "        baseline = all_images[:, :, 0]\n",
    "        w_b = len(np.where(baseline == 1)[0])\n",
    "        fb = mask - baseline\n",
    "        fw_b = w_b / A\n",
    "        fd_b = np.sum(fb) / A\n",
    "        Na = A * fd_b\n",
    "\n",
    "        for j in range(all_images.shape[2]):\n",
    "            im = all_images[:, :, j]\n",
    "\n",
    "            kb = (\n",
    "                np.sum(all_images[:, :, :j + 1], axis=(2))\n",
    "                + mask\n",
    "            )\n",
    "            kb[np.where(kb != 1)] = 0\n",
    "            Nb = np.sum(kb)\n",
    "            # fR = (Na / w_b) - (Nb / w_b)\n",
    "            fR = (Na - Nb)\n",
    "            fR_wick = 1 - (Nb / Na)\n",
    "\n",
    "            # Calculate D - EQ. (1)\n",
    "            D = np.subtract(baseline, im)\n",
    "            # 1 - wet -> dry\n",
    "            d_wd = len((np.where(D == 1))[0])\n",
    "            # -1 - dry -> wet\n",
    "            d_dw = len((np.where(D == -1))[0])\n",
    "\n",
    "            # Calculate Phi\n",
    "            w_t = len(np.where(im == 1)[0])\n",
    "            fw_t = w_t / A\n",
    "            fd_t = (A - w_t) / A\n",
    "\n",
    "            # Calculate O_Phi\n",
    "            PHI = (fw_b * fd_t) + (fd_b * fw_t)\n",
    "            o_wick = 1 - (np.sum(np.abs(D)) / (A * PHI))\n",
    "            o_avg = w_b - np.mean([d_wd, d_dw])\n",
    "            o_wd = w_b - d_wd\n",
    "            o_dw = w_b - d_dw\n",
    "\n",
    "            data['i'].append(j)\n",
    "            data['O_avg'].append(o_avg * (scale**2))\n",
    "            data['O_wd'].append(o_wd * (scale**2))\n",
    "            data['O_dw'].append(o_dw * (scale**2))\n",
    "            data['O_wick'].append(o_wick)\n",
    "            data['fR'].append(fR * (scale**2))\n",
    "            data['fR_wick'].append(fR_wick)\n",
    "            data['w_b'].append(w_b * (scale**2))\n",
    "            data['d_b'].append(Na * (scale**2))\n",
    "\n",
    "        data['year'] = years\n",
    "        data['i'] = np.array(years).astype(int) - int(years[0])\n",
    "        river_dfs[yrange[0]] = pd.DataFrame(data=data)\n",
    "\n",
    "    return river_dfs\n",
    "\n",
    "def get_mobility_rivers(folder_path, river, mob_storage, reach_range=\"All\"):\n",
    "    \"\"\"\n",
    "    Processes mobility metrics for specified reaches of a river and saves\n",
    "    the results to separate CSV files with the reach number in the filename.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str): The root directory that contains subfolders for each reach.\n",
    "        river (str): Name of the river.\n",
    "        mob_storage (str): Path to store the output CSV files.\n",
    "        reach_range (str/int/tuple): Specifies which reaches to process. Can be:\n",
    "            - An integer for a single reach (e.g., 3).\n",
    "            - A tuple for a range of reaches (e.g., (1, 4)).\n",
    "            - \"All\" to process all reaches.\n",
    "\n",
    "    Returns:\n",
    "        str: Name of the river (for confirmation or chaining).\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from glob import glob\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from natsort import natsorted\n",
    "\n",
    "    def create_mask_shape(river, fps):\n",
    "        \"\"\"\n",
    "        Reads the first raster file in fps and applies a mask processing step to return a binary raster\n",
    "        where pixel values are transformed as follows:\n",
    "            - Values < 10 are set to 0\n",
    "            - Values >= 10 are set to 1\n",
    "\n",
    "        Parameters:\n",
    "        river (str): Unused in this version, kept for consistency with the original function signature.\n",
    "        fps (list): List of file paths to raster images, with the first path being used for processing.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: A 2D array with the processed binary mask.\n",
    "        \"\"\"\n",
    "        import rasterio\n",
    "\n",
    "        # Use the first file path in fps to open the raster file\n",
    "        image = fps[0]\n",
    "        with rasterio.open(image) as ds:\n",
    "            # Read the data as a 2D array (assuming single-band raster)\n",
    "            out_image = ds.read(1).astype('int64')\n",
    "            \n",
    "            # Mask processing\n",
    "            out_image += 11  # Offset values as in the original function\n",
    "            out_image[np.where(out_image < 10)] = 0\n",
    "            out_image[np.where(out_image > 10)] = 1\n",
    "\n",
    "        return out_image\n",
    "\n",
    "    def clean(river, fps):\n",
    "        \"\"\"\n",
    "        Processes a set of raster images by creating binary water masks without using any polygon for masking.\n",
    "        Each raster file in `fps` is read, transformed into a binary water mask, and stored in a dictionary\n",
    "        by year (derived from filenames).\n",
    "\n",
    "        Parameters:\n",
    "        river (str): Unused in this version, kept for compatibility with the original function signature.\n",
    "        fps (list): List of file paths to raster images.\n",
    "\n",
    "        Returns:\n",
    "        tuple: A dictionary of images (binary masks by year) and their respective metadata.\n",
    "        \"\"\"\n",
    "        import rasterio\n",
    "        from rasterio.enums import Resampling\n",
    "        import re\n",
    "\n",
    "        images = {}\n",
    "        metas = {}\n",
    "\n",
    "        # Process each file path in fps\n",
    "        for fp in fps:\n",
    "            # Extract year from filename using regex\n",
    "            year_match = re.findall(r\"[0-9]{4,7}\", fp)\n",
    "            if year_match:\n",
    "                year = year_match[-1]  # Take the last match as the year\n",
    "            else:\n",
    "                continue  # Skip files without a year identifier\n",
    "\n",
    "            # Open the raster file\n",
    "            with rasterio.open(fp) as ds:\n",
    "                # Read the data and apply threshold to create a binary water mask\n",
    "                image = ds.read(1, resampling=Resampling.nearest) > 0  # Binary mask where pixel > 0 is water\n",
    "\n",
    "                # Skip images with no water (all values are 0)\n",
    "                if not np.any(image):\n",
    "                    continue\n",
    "\n",
    "                # Update metadata for the binary water mask\n",
    "                meta = ds.meta\n",
    "                meta.update(\n",
    "                    width=image.shape[1],\n",
    "                    height=image.shape[0],\n",
    "                    count=1,\n",
    "                    dtype=rasterio.int8\n",
    "                )\n",
    "\n",
    "                # Save the binary water mask and its metadata\n",
    "                images[year] = image\n",
    "                metas[year] = meta\n",
    "\n",
    "        return images, metas\n",
    "\n",
    "    # Ensure the storage directory exists\n",
    "    if not os.path.exists(mob_storage):\n",
    "        os.makedirs(mob_storage)\n",
    "\n",
    "    print(f\"Processing river: {river}\")\n",
    "\n",
    "    # Generate the dictionary of paths for each reach\n",
    "    paths = {}\n",
    "    river_folder = os.path.join(folder_path, river)\n",
    "    for reach_folder in os.listdir(river_folder):\n",
    "        reach_path = os.path.join(river_folder, reach_folder, 'Cleaned')\n",
    "        if os.path.isdir(reach_path):\n",
    "            tif_files = glob(os.path.join(reach_path, \"*.tif\"))\n",
    "            if tif_files:\n",
    "                paths[reach_folder] = tif_files\n",
    "\n",
    "    # Filter reaches based on reach_range\n",
    "    if isinstance(reach_range, int):\n",
    "        # Single reach\n",
    "        reach_keys = [f\"reach_{reach_range}\"]\n",
    "    elif isinstance(reach_range, tuple):\n",
    "        # Range of reaches\n",
    "        start, end = reach_range\n",
    "        reach_keys = [f\"reach_{i}\" for i in range(start, end + 1)]\n",
    "    elif reach_range == \"All\":\n",
    "        # All reaches\n",
    "        reach_keys = list(paths.keys())\n",
    "    else:\n",
    "        raise ValueError(\"Invalid reach_range format. Must be an integer, tuple, or 'All'.\")\n",
    "\n",
    "    # Iterate through specified reaches\n",
    "    for reach_key in reach_keys:\n",
    "        if reach_key not in paths:\n",
    "            print(f\"Reach {reach_key} not found in paths. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        path_list = paths[reach_key]\n",
    "\n",
    "        # Extract the reach number from the reach_key (assumes format \"reach_x\")\n",
    "        reach_number = reach_key.split('_')[1]  # Gets the 'x' part of \"reach_x\"\n",
    "\n",
    "        # Sort paths naturally\n",
    "        path_list = natsorted(path_list)\n",
    "\n",
    "        # Generate the mask for the reach\n",
    "        mask = create_mask_shape(river, path_list)\n",
    "\n",
    "        # Clean and retrieve images and metadata\n",
    "        images, metas = clean(river, path_list)\n",
    "\n",
    "        # Set a fixed scale for processing\n",
    "        scale = 30\n",
    "\n",
    "        # Calculate yearly mobility metrics\n",
    "        river_dfs = get_mobility_yearly(images, mask, scale=scale)\n",
    "\n",
    "        # Combine data into a full DataFrame for the reach\n",
    "        full_df = pd.DataFrame()\n",
    "        for year, df in river_dfs.items():\n",
    "            rnge = f\"{year}_{df.iloc[-1]['year']}\"\n",
    "            df['dt'] = pd.to_datetime(df['year'], format='%Y')\n",
    "            df['range'] = rnge\n",
    "\n",
    "            # Append data to the final DataFrame\n",
    "            full_df = pd.concat([full_df, df], ignore_index=True)\n",
    "\n",
    "        # Define the output path with reach number in the filename\n",
    "        out_path = os.path.join(mob_storage, f'{river}_reach_{reach_number}_yearly_mobility.csv')\n",
    "        full_df.to_csv(out_path, index=False)\n",
    "        print(f\"Saved mobility metrics for {river} reach {reach_number} to {out_path}\")\n",
    "\n",
    "def get_mobility_dfs(csv_path):\n",
    "    \"\"\"\n",
    "    Wrapper function to process multiple rivers and reaches based on a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file containing river and reach information.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Read the CSV file into a DataFrame\n",
    "    river_data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in river_data.iterrows():\n",
    "        river_name = row['river_name']\n",
    "        working_directory = row['working_directory']\n",
    "        reach_range = row['reach_range']\n",
    "\n",
    "        # Parse reach_range\n",
    "        if isinstance(reach_range, str) and reach_range != \"All\":\n",
    "            if reach_range.startswith(\"(\") and reach_range.endswith(\")\"):\n",
    "                # Convert tuple-like string to actual tuple\n",
    "                reach_range = tuple(map(int, reach_range.strip(\"() \").split(\",\")))\n",
    "            else:\n",
    "                # Single integer as string\n",
    "                reach_range = int(reach_range)\n",
    "\n",
    "        # Construct input and output paths\n",
    "        folder_path = f\"{working_directory}/RiverMapping/RiverMasks\"\n",
    "        mob_storage = os.path.join(working_directory, \"RiverMapping\", \"Mobility\", river_name, \"Mobility_dfs\")\n",
    "        os.makedirs(mob_storage, exist_ok=True)\n",
    "\n",
    "        # Call the get_mobility_dfs function for the current river\n",
    "        print(f\"Processing {river_name} with reach range {reach_range}...\")\n",
    "        get_mobility_rivers(folder_path, river_name, mob_storage, reach_range)\n",
    "\n",
    "    print(\"All rivers processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a54f4",
   "metadata": {},
   "source": [
    "## Initialize functions to calculate floodplain reworking timescale (TR) from mobility sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f10752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TR(csv_path):\n",
    "    \"\"\"\n",
    "    Processes TR values for reaches based on a CSV file and generates aw distributions.\n",
    "\n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file containing river and reach information.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import numpy as np\n",
    "    from scipy.optimize import curve_fit\n",
    "\n",
    "    def calculate_median_fit_with_TR_and_uncertainty(data):\n",
    "        \"\"\"\n",
    "        A helper function that computes TR from a DataFrame containing channel mobility data.\n",
    "        \"\"\"\n",
    "        data['AR_over_AW'] = data['fR'] / data['w_b']\n",
    "        grouped = data.groupby('i')\n",
    "        median_values = []\n",
    "        i_values = []\n",
    "        for i, group in grouped:\n",
    "            i_values.append(i)\n",
    "            median_values.append(np.median(group['AR_over_AW']))\n",
    "\n",
    "        i_values = np.array(i_values)\n",
    "        median_values = np.array(median_values)\n",
    "\n",
    "        def exp_decay_asymptote(i, PR_over_AW, CR):\n",
    "            return -PR_over_AW * np.exp(-CR * i) + PR_over_AW\n",
    "\n",
    "        initial_guess = [1, 0.1]\n",
    "        params, _ = curve_fit(exp_decay_asymptote, i_values, median_values, p0=initial_guess, maxfev=10000)\n",
    "        PR_over_AW, CR = params\n",
    "        Aw = 1\n",
    "        return (1 / CR) * (Aw / PR_over_AW)\n",
    "\n",
    "    def get_aw_dist(input_directory, output_directory, reach_range):\n",
    "        \"\"\"\n",
    "        Extracts the distribution of `w_b` values when `i=0` for specified reaches and saves them.\n",
    "\n",
    "        Parameters:\n",
    "            input_directory (str): Directory containing the mobility CSV files.\n",
    "            output_directory (str): Directory to save the output CSV files.\n",
    "            reach_range (str/int/tuple): Specifies which reaches to process. Can be:\n",
    "                - An integer for a single reach (e.g., 3).\n",
    "                - A tuple for a range of reaches (e.g., (1, 4)).\n",
    "                - \"All\" to process all reaches.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "        # List all mobility CSV files\n",
    "        csv_files = [f for f in os.listdir(input_directory) if f.endswith(\"_yearly_mobility.csv\")]\n",
    "\n",
    "        for csv_file in csv_files:\n",
    "            try:\n",
    "                # Extract reach number\n",
    "                reach_number = int(csv_file.split('_')[2])\n",
    "\n",
    "                # Filter based on reach_range\n",
    "                if isinstance(reach_range, int) and reach_number != reach_range:\n",
    "                    continue\n",
    "                elif isinstance(reach_range, tuple) and not (reach_range[0] <= reach_number <= reach_range[1]):\n",
    "                    continue\n",
    "\n",
    "                # Read the mobility CSV file\n",
    "                data = pd.read_csv(os.path.join(input_directory, csv_file))\n",
    "\n",
    "                # Filter rows where `i == 0` and get `w_b` values\n",
    "                w_b_values = data.loc[data['i'] == 0, 'w_b'].tolist()\n",
    "\n",
    "                # Create a DataFrame for the distribution\n",
    "                output_df = pd.DataFrame(w_b_values, columns=['a_w'])\n",
    "\n",
    "                # Save to a CSV file\n",
    "                output_file = os.path.join(output_directory, f\"Reach_{reach_number}_aw_dist.csv\")\n",
    "                output_df.to_csv(output_file, index=False)\n",
    "\n",
    "                print(f\"Saved `a_w` distribution for Reach {reach_number} to {output_file}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {csv_file}: {e}\")\n",
    "\n",
    "    river_data = pd.read_csv(csv_path)\n",
    "    for index, row in river_data.iterrows():\n",
    "        river_name = row['river_name']\n",
    "        working_directory = row['working_directory']\n",
    "        reach_range = row['reach_range']\n",
    "\n",
    "        # Parse reach_range\n",
    "        if isinstance(reach_range, str) and reach_range != \"All\":\n",
    "            if reach_range.startswith(\"(\") and reach_range.endswith(\")\"):\n",
    "                reach_range = tuple(map(int, reach_range.strip(\"() \").split(\",\")))\n",
    "            else:\n",
    "                reach_range = int(reach_range)\n",
    "\n",
    "        input_directory = f\"{working_directory}/RiverMapping/Mobility/{river_name}/Mobility_DFs\"\n",
    "        tr_output_directory = f\"{working_directory}/RiverMapping/Mobility/{river_name}\"\n",
    "        aw_output_directory = f\"{working_directory}/RiverMapping/Mobility/{river_name}/AW_Distributions\"\n",
    "\n",
    "        os.makedirs(tr_output_directory, exist_ok=True)\n",
    "        os.makedirs(aw_output_directory, exist_ok=True)\n",
    "\n",
    "        csv_files = [f for f in os.listdir(input_directory) if f.endswith(\"_yearly_mobility.csv\")]\n",
    "        results = []\n",
    "\n",
    "        for csv_file in csv_files:\n",
    "            reach_number = int(csv_file.split('_')[2])\n",
    "\n",
    "            # Filter based on reach_range\n",
    "            if isinstance(reach_range, int) and reach_number != reach_range:\n",
    "                continue\n",
    "            elif isinstance(reach_range, tuple) and not (reach_range[0] <= reach_number <= reach_range[1]):\n",
    "                continue\n",
    "\n",
    "            data = pd.read_csv(os.path.join(input_directory, csv_file))\n",
    "            try:\n",
    "                TR = calculate_median_fit_with_TR_and_uncertainty(data)\n",
    "                results.append((reach_number, TR))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {csv_file}: {e}\")\n",
    "\n",
    "        results_df = pd.DataFrame(results, columns=['Reach_Number', 'TR'])\n",
    "        results_df.sort_values(by='Reach_Number', inplace=True)\n",
    "\n",
    "        output_file = os.path.join(tr_output_directory, f\"{river_name}_TR_values.csv\")\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        print(f\"TR values saved to {output_file}\")\n",
    "\n",
    "        # Generate AW distributions for the specified reaches\n",
    "        get_aw_dist(input_directory, aw_output_directory, reach_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ba3eb",
   "metadata": {},
   "source": [
    "## Initialize functions to calculate channel-belt turnover timescale (TCB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_aw_distribution(river_name, reach_number, working_directory):\n",
    "    \"\"\"\n",
    "    Imports the AW distribution for a specified reach.\n",
    "\n",
    "    Args:\n",
    "        river_name (str): Name of the river.\n",
    "        reach_number (int): Reach number to import AW distribution.\n",
    "        working_directory (str): Base working directory containing the river data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the AW distribution for the specified reach.\n",
    "    \"\"\"\n",
    "    # Define base directory for AW distributions\n",
    "    aw_dir = os.path.join(working_directory, 'RiverMapping', 'Mobility', river_name, 'AW_Distributions')\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(aw_dir):\n",
    "        raise FileNotFoundError(f\"AW distribution directory not found: {aw_dir}\")\n",
    "\n",
    "    # Load AW distribution for the specified reach\n",
    "    aw_file = os.path.join(aw_dir, f\"Reach_{reach_number}_aw_dist.csv\")\n",
    "    if not os.path.isfile(aw_file):\n",
    "        raise FileNotFoundError(f\"AW file not found: {aw_file}\")\n",
    "\n",
    "    aw_distribution = pd.read_csv(aw_file)\n",
    "\n",
    "    return aw_distribution\n",
    "\n",
    "def calculate_tcb_distribution(tr_value, channel_belt_area, aw_distribution):\n",
    "    \"\"\"\n",
    "    Calculates the TCB distribution for a single reach and returns the result.\n",
    "\n",
    "    Args:\n",
    "        tr_value (float): TR value for the reach.\n",
    "        channel_belt_area (float): Channel belt area (in square km) for the reach.\n",
    "        aw_distribution (DataFrame): AW distribution for the reach.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the TCB distribution for the specified reach.\n",
    "    \"\"\"\n",
    "    # Ensure the AW distribution is not empty\n",
    "    if aw_distribution.empty:\n",
    "        raise ValueError(\"AW distribution is empty.\")\n",
    "\n",
    "    # Generate 10,000 random draws from the AW distribution\n",
    "    aw_random_draws = np.random.choice(aw_distribution['a_w'], size=10000, replace=True)\n",
    "\n",
    "    # Calculate TCB for each random draw, converting channel belt area from square km to square m\n",
    "    tcb_values = tr_value * (channel_belt_area * 1000000 / aw_random_draws)\n",
    "\n",
    "    return pd.DataFrame({'TCB': tcb_values})\n",
    "\n",
    "def get_tcb_distributions(csv_path):\n",
    "    \"\"\"\n",
    "    Processes a range of reaches from a CSV file and calculates TCB distributions for each.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing river name and reach range.\n",
    "\n",
    "    Outputs:\n",
    "        CSV files containing TCB distributions for each processed reach.\n",
    "    \"\"\"\n",
    "    # Load the configuration CSV\n",
    "    config_data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Extract river name, reach range, and working directory\n",
    "    river_name = config_data['river_name'].iloc[0]\n",
    "    reach_range = config_data['reach_range'].iloc[0]\n",
    "    working_directory = config_data['working_directory'].iloc[0]\n",
    "\n",
    "    # Define directories for required inputs\n",
    "    tr_file = os.path.join(working_directory, 'RiverMapping', 'Mobility', river_name, f\"{river_name}_TR_values.csv\")\n",
    "    channel_belt_file = os.path.join(working_directory, 'ChannelBelts', 'Extracted_ChannelBelts', river_name, f\"{river_name}_channelbelt_areas.csv\")\n",
    "\n",
    "    # Check if the required files exist\n",
    "    if not os.path.isfile(tr_file):\n",
    "        raise FileNotFoundError(f\"TR file not found: {tr_file}\")\n",
    "    if not os.path.isfile(channel_belt_file):\n",
    "        raise FileNotFoundError(f\"Channel belt areas file not found: {channel_belt_file}\")\n",
    "\n",
    "    # Load the TR and channel belt areas data\n",
    "    tr_data = pd.read_csv(tr_file)\n",
    "    channel_belt_data = pd.read_csv(channel_belt_file)\n",
    "\n",
    "    # Parse reach_range\n",
    "    if isinstance(reach_range, str) and reach_range != \"All\":\n",
    "        if reach_range.startswith(\"(\") and reach_range.endswith(\")\"):\n",
    "            # Convert tuple-like string to actual tuple\n",
    "            reach_range = tuple(map(int, reach_range.strip(\"() \").split(\",\")))\n",
    "        else:\n",
    "            # Single integer as string\n",
    "            reach_range = reach_range.astype(int)\n",
    "    \n",
    "    # Determine the range of reaches to process\n",
    "    if reach_range == \"All\":\n",
    "        reaches = tr_data['Reach_Number'].unique()\n",
    "    elif isinstance(reach_range, tuple):\n",
    "        reaches = range(reach_range[0], reach_range[1] + 1)\n",
    "    else:\n",
    "        reaches = [reach_range]\n",
    "\n",
    "    # Iterate through the range of reaches and calculate TCB for each\n",
    "    for reach_number in reaches:\n",
    "        # Get TR value for the reach\n",
    "        tr_value = tr_data.loc[tr_data['Reach_Number'] == reach_number, 'TR'].values[0]\n",
    "\n",
    "        # Get channel belt area for the reach\n",
    "        channel_belt_area = channel_belt_data.loc[channel_belt_data['ds_order'] == reach_number, 'area_sq_km'].values[0]\n",
    "\n",
    "        # Import AW distribution for the reach\n",
    "        aw_distribution = import_aw_distribution(river_name, reach_number, working_directory)\n",
    "\n",
    "        # Calculate the TCB distribution for the reach\n",
    "        tcb_distribution = calculate_tcb_distribution(tr_value, channel_belt_area, aw_distribution)\n",
    "\n",
    "        # Save TCB distribution to a CSV\n",
    "        output_file = os.path.join(working_directory, 'RiverMapping', 'Mobility', river_name, 'TCB_Distributions', f\"Reach_{reach_number}_TCB_distribution.csv\")\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        tcb_distribution.to_csv(output_file, index=False)\n",
    "\n",
    "        print(f\"TCB distribution for Reach {reach_number} saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f34d64",
   "metadata": {},
   "source": [
    "## Initialize functions to calculate first-passage time distributions of sediment storage time (TFP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935c57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tfp_distribution(tr_value, channel_belt_area, aw_distribution):\n",
    "    \"\"\"\n",
    "    Calculates the TFP distribution for a single reach using the random walk model and returns the result.\n",
    "\n",
    "    Args:\n",
    "        tr_value (float): TR value for the reach.\n",
    "        channel_belt_area (float): Channel belt area (in square km) for the reach.\n",
    "        aw_distribution (DataFrame): AW distribution (in square m) for the reach.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the TFP distribution for the specified reach.\n",
    "    \"\"\"\n",
    "    # Convert channel belt area from square km to square m\n",
    "    channel_belt_area_m2 = channel_belt_area * 1000000\n",
    "\n",
    "    # Ensure the AW distribution is not empty\n",
    "    if aw_distribution.empty:\n",
    "        raise ValueError(\"AW distribution is empty.\")\n",
    "\n",
    "    # Extract the 'a_w' values from the distribution\n",
    "    aw_values = aw_distribution['a_w'].values\n",
    "\n",
    "    # Number of iterations for the Monte Carlo simulation\n",
    "    num_iterations = 10000\n",
    "\n",
    "    # Maximum number of timesteps per iteration\n",
    "    max_timesteps = 10000\n",
    "\n",
    "    # Initialize storage for the first passage times\n",
    "    tfp_times = []\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        # Randomly initialize the channel's starting position within the domain\n",
    "        x0 = np.random.uniform(0, channel_belt_area_m2)\n",
    "        x = x0\n",
    "\n",
    "        total_time = 0\n",
    "        timestep_count = 0\n",
    "\n",
    "        while timestep_count < max_timesteps:\n",
    "            # Draw a random step size from the AW distribution\n",
    "            aw_step = np.random.choice(aw_values)\n",
    "\n",
    "            # Randomly determine the direction (+ or -)\n",
    "            direction = np.random.choice([-1, 1])\n",
    "\n",
    "            # Move the channel\n",
    "            x_new = x + direction * aw_step\n",
    "\n",
    "            # Reflect at boundaries if needed\n",
    "            if x_new < 0:\n",
    "                x_new = -x_new\n",
    "            elif x_new > channel_belt_area_m2:\n",
    "                x_new = 2 * channel_belt_area_m2 - x_new\n",
    "\n",
    "            # Check if the channel has reached or passed the starting position\n",
    "            if (x_new >= x0 and x < x0) or (x_new <= x0 and x > x0):\n",
    "                # Calculate fractional time for the overshoot\n",
    "                remaining_distance = abs(x0 - x)\n",
    "                fractional_tr = (remaining_distance / aw_step) * tr_value\n",
    "                total_time += fractional_tr\n",
    "                break\n",
    "\n",
    "            # Increment total time for this full step\n",
    "            total_time += tr_value\n",
    "            timestep_count += 1\n",
    "            x = x_new\n",
    "\n",
    "        # If the loop exited due to timestep limit, skip this iteration\n",
    "        if timestep_count >= max_timesteps:\n",
    "            continue\n",
    "\n",
    "        # Store the total time for this iteration\n",
    "        tfp_times.append(total_time)\n",
    "\n",
    "    # Return the TFP distribution as a DataFrame\n",
    "    return pd.DataFrame({'TFP': tfp_times})\n",
    "\n",
    "def get_tfp_distributions(csv_path):\n",
    "    \"\"\"\n",
    "    Processes a range of reaches from a CSV file and calculates TFP distributions for each.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing river name and reach range.\n",
    "\n",
    "    Outputs:\n",
    "        CSV files containing TFP distributions for each processed reach.\n",
    "    \"\"\"\n",
    "    # Load the configuration CSV\n",
    "    config_data = pd.read_csv(csv_path)\n",
    "\n",
    "    for index, row in config_data.iterrows():\n",
    "        # Extract river name, reach range, and working directory for each row\n",
    "        river_name = row['river_name']\n",
    "        reach_range = row['reach_range']\n",
    "        working_directory = row['working_directory']\n",
    "\n",
    "        # Define directories for required inputs\n",
    "        tr_file = os.path.join(working_directory, 'RiverMapping', 'Mobility', river_name, f\"{river_name}_TR_values.csv\")\n",
    "        channel_belt_file = os.path.join(working_directory, 'ChannelBelts', 'Extracted_ChannelBelts', river_name, f\"{river_name}_channelbelt_areas.csv\")\n",
    "\n",
    "        # Check if the required files exist\n",
    "        if not os.path.isfile(tr_file):\n",
    "            raise FileNotFoundError(f\"TR file not found: {tr_file}\")\n",
    "        if not os.path.isfile(channel_belt_file):\n",
    "            raise FileNotFoundError(f\"Channel belt areas file not found: {channel_belt_file}\")\n",
    "\n",
    "        # Load the TR and channel belt areas data\n",
    "        tr_data = pd.read_csv(tr_file)\n",
    "        channel_belt_data = pd.read_csv(channel_belt_file)\n",
    "\n",
    "        # Determine the reach range\n",
    "        if isinstance(reach_range, str):\n",
    "            reach_range = reach_range.strip()  # Remove any extra spaces\n",
    "\n",
    "            if reach_range == \"All\":\n",
    "                reach_start = tr_data['Reach_Number'].min()\n",
    "                reach_end = tr_data['Reach_Number'].max()\n",
    "            elif reach_range.isdigit():\n",
    "                # Convert a numeric string to an integer\n",
    "                reach_range = int(reach_range)\n",
    "                reach_start = reach_range\n",
    "                reach_end = reach_range\n",
    "            elif re.match(r'^\\(\\d{1,4}, \\d{1,4}\\)$', reach_range):  # Match (XX, YY) with 1 to 4 digits\n",
    "                try:\n",
    "                    # Convert the string to a tuple of integers\n",
    "                    reach_range = ast.literal_eval(reach_range)\n",
    "                    reach_start, reach_end = reach_range\n",
    "                except (ValueError, SyntaxError):\n",
    "                    raise ValueError(f\"Invalid reach range format: {reach_range}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid string format for reach_range: {reach_range}\")\n",
    "        elif isinstance(reach_range, (int, float)) and float(reach_range).is_integer():\n",
    "            # Convert float-like integers (e.g., 7.0) to int\n",
    "            reach_range = int(reach_range)\n",
    "            reach_start = reach_range\n",
    "            reach_end = reach_range\n",
    "        elif isinstance(reach_range, tuple) and len(reach_range) == 2:\n",
    "            reach_start, reach_end = reach_range\n",
    "        else:\n",
    "            raise ValueError(\"reach_range must be 'All', an int, or a tuple (start, end).\")\n",
    "\n",
    "        # Generate range of reaches to process\n",
    "        reaches = range(reach_start, reach_end + 1)\n",
    "\n",
    "        # Iterate through the range of reaches and calculate TFP for each\n",
    "        for reach_number in reaches:\n",
    "            # Get TR value for the reach\n",
    "            tr_value = tr_data.loc[tr_data['Reach_Number'] == reach_number, 'TR'].values[0]\n",
    "\n",
    "            # Get channel belt area for the reach\n",
    "            channel_belt_area = channel_belt_data.loc[channel_belt_data['ds_order'] == reach_number, 'area_sq_km'].values[0]\n",
    "\n",
    "            # Import AW distribution for the reach\n",
    "            aw_distribution = import_aw_distribution(river_name, reach_number, working_directory)\n",
    "\n",
    "            # Calculate the TFP distribution for the reach\n",
    "            tfp_distribution = calculate_tfp_distribution(tr_value, channel_belt_area, aw_distribution)\n",
    "\n",
    "            # Save TFP distribution to a CSV\n",
    "            output_file = os.path.join(working_directory, 'RiverMapping', 'Mobility', river_name, 'TFP_Distributions', f\"Reach_{reach_number}_TFP_distribution.csv\")\n",
    "            os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "            tfp_distribution.to_csv(output_file, index=False)\n",
    "\n",
    "            print(f\"TFP distribution for Reach {reach_number} saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r\"C:\\Users\\huckr\\Desktop\\UCSB\\Dissertation\\Data\\RiverMapping\\Bermejo_river_datasheet.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mobility_dfs(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_TR(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tcb_distributions(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tfp_distributions(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ecbb9c",
   "metadata": {},
   "source": [
    "## Initialize functions to calculate sediment transit times and velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfcad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_wbsed(working_directory, river_name):\n",
    "    \"\"\"\n",
    "    Imports a spreadsheet of sediment flux data from a specified local folder.\n",
    "\n",
    "    Parameters:\n",
    "        working_directory (str): The root directory containing the sediment flux data.\n",
    "        river_name (str): The name of the target river.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the sediment flux data.\n",
    "    \"\"\"\n",
    "    # Construct the full path to the file\n",
    "    file_path = os.path.join(working_directory, 'WBMsed', f'{river_name}_wbmsed.csv')\n",
    "    \n",
    "    # Read the CSV file into a DataFrame\n",
    "    return pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f5d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory = r'D:\\Dissertation\\Data'\n",
    "river_name = 'Beni'\n",
    "beni = import_wbsed(working_directory, river_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e3ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(beni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95615e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sed_flux(sed_flux_df, qs_inclusion = 1, sediment_bulk_density = 1600):\n",
    "    \"\"\"\n",
    "    Calculates sediment flux by reach using different sediment flux combinations.\n",
    "    \n",
    "    Parameters:\n",
    "        sed_flux_df (pd.DataFrame): DataFrame of sediment flux data from the WBMsed model.\n",
    "        qs_inclusion (int): Determines which sediment flux combination to use (1 or 2).\n",
    "            1 -> Bedload + Suspended Bedload\n",
    "            2 -> Bedload + Suspended Bedload + Washload\n",
    "        sediment_bulk_density (float): Estimated density of floodplain sediment in kg per cubic meter.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing sediment flux per reach in cubic meters per year.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select the appropriate sediment flux combination\n",
    "    if qs_inclusion == 1:\n",
    "        sed_flux_df[\"Selected_Flux_kg_s\"] = (\n",
    "            sed_flux_df[\"mean_BedloadFlux_kg_s\"] + sed_flux_df[\"mean_SuspendedBedFlux_kg_s\"]\n",
    "        )\n",
    "    elif qs_inclusion == 2:\n",
    "        sed_flux_df[\"Selected_Flux_kg_s\"] = (\n",
    "            sed_flux_df[\"mean_BedloadFlux_kg_s\"] + \n",
    "            sed_flux_df[\"mean_SuspendedBedFlux_kg_s\"] + \n",
    "            sed_flux_df[\"mean_WashloadFlux_kg_s\"]\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"qs_inclusion must be either 1 (Bedload + Suspended Bedload) or 2 (Bedload + Suspended Bedload + Washload).\")\n",
    "\n",
    "    # Convert mass flux (kg/s) to volumetric flux (m³/year)\n",
    "    seconds_per_year = 60 * 60 * 24 * 365  # 31,536,000 seconds in a year\n",
    "    sed_flux_df[\"SedimentFlux_m3_yr\"] = (sed_flux_df[\"Selected_Flux_kg_s\"] / sediment_bulk_density) * seconds_per_year\n",
    "    \n",
    "    # Ensure ds_order is an integer\n",
    "    sed_flux_df[\"ds_order\"] = sed_flux_df[\"ds_order\"].astype(int)\n",
    "\n",
    "    # Retain only necessary columns\n",
    "    result_df = sed_flux_df[[\"ds_order\", \"SedimentFlux_m3_yr\"]]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0bf330",
   "metadata": {},
   "outputs": [],
   "source": [
    "beni_sedflux = calculate_sed_flux(beni)\n",
    "print(beni_sedflux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_channel_slope(channel_gdf):\n",
    "    \"\"\"\n",
    "    Calculates the slope of a river channel from its main channel line.\n",
    "    \n",
    "    Parameters:\n",
    "        channel_gdf (gpd.GeoDataFrame): A GeoDataFrame containing the main channel line geometry.\n",
    "    \n",
    "    Returns:\n",
    "        float: The channel slope (dimensionless).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the first (start) and last (end) points of the main channel line\n",
    "    main_channel_line = channel_gdf.geometry.iloc[0]  # Assume the first row is the main channel\n",
    "    start_point = main_channel_line.coords[0]  # First coordinate (lon, lat)\n",
    "    end_point = main_channel_line.coords[-1]   # Last coordinate (lon, lat)\n",
    "\n",
    "    # Convert to Earth Engine Points\n",
    "    start_ee = ee.Geometry.Point(start_point)\n",
    "    end_ee = ee.Geometry.Point(end_point)\n",
    "\n",
    "    # Get elevation data from NASA SRTM (30m resolution)\n",
    "    srtm = ee.Image(\"USGS/SRTMGL1_003\")  # SRTM 30m DEM\n",
    "\n",
    "    # Extract elevation at start and end points\n",
    "    start_elev = srtm.sample(start_ee, 30).first().get(\"elevation\").getInfo()\n",
    "    end_elev = srtm.sample(end_ee, 30).first().get(\"elevation\").getInfo()\n",
    "\n",
    "    # Calculate elevation difference\n",
    "    elevation_diff = start_elev - end_elev\n",
    "\n",
    "    # Calculate geodesic length of the channel (meters)\n",
    "    channel_length = channel_gdf.length.sum()\n",
    "    print(channel_length)\n",
    "\n",
    "    # Compute channel slope (dimensionless)\n",
    "    slope = abs(elevation_diff / channel_length)\n",
    "\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3edfe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefile into a GeoDataFrame\n",
    "channel_gdf = gpd.read_file(r\"D:\\Dissertation\\Data\\RiverMapping\\Channels\\Beni\\reach_4\\2024\\main_channel.shp\")\n",
    "\n",
    "# Ensure it is a LineString geometry\n",
    "if not all(channel_gdf.geometry.geom_type == \"LineString\"):\n",
    "    raise ValueError(\"The shapefile must contain LineString geometries only.\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(channel_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e42dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = calculate_channel_slope(channel_gdf)\n",
    "print(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0011b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_channel_width(channel_mask, channel_gdf, pixel_resolution=30, raster_path=None):\n",
    "    \"\"\"\n",
    "    Estimates the channel width by dividing the wetted area by the main channel length.\n",
    "\n",
    "    Parameters:\n",
    "        channel_mask (np.ndarray): A 2D array where 1 indicates water (channel) pixels and 0 is non-water.\n",
    "        channel_gdf (gpd.GeoDataFrame): A GeoDataFrame containing the main channel line geometry.\n",
    "        pixel_resolution (float, optional): The spatial resolution of the raster in meters (default = 30m).\n",
    "        raster_path (str, optional): Path to the original raster file for reprojection.\n",
    "\n",
    "    Returns:\n",
    "        float: Estimated channel width in meters.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1️⃣ Check and Assign CRS if Missing ---\n",
    "    if channel_gdf.crs is None:\n",
    "        print(\"⚠️ Warning: No CRS found in channel shapefile. Assuming WGS84 (EPSG:4326).\")\n",
    "        channel_gdf.set_crs(epsg=4326, inplace=True)  # Assign WGS84 if missing\n",
    "\n",
    "    # --- 2️⃣ Reproject to a Projected CRS (UTM) ---\n",
    "    projected_crs = channel_gdf.estimate_utm_crs()  # Find the best UTM CRS\n",
    "    channel_gdf = channel_gdf.to_crs(projected_crs)  # Convert to UTM for accurate distance\n",
    "\n",
    "    # --- 3️⃣ Reproject Raster to Match CRS ---\n",
    "    if raster_path:\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            transform, width, height = calculate_default_transform(\n",
    "                src.crs, projected_crs, src.width, src.height, *src.bounds\n",
    "            )\n",
    "\n",
    "            kwargs = src.meta.copy()\n",
    "            kwargs.update({\"crs\": projected_crs, \"transform\": transform, \"width\": width, \"height\": height})\n",
    "\n",
    "            # Reproject the raster\n",
    "            with rasterio.open(\"reprojected_raster.tif\", \"w\", **kwargs) as dst:\n",
    "                for i in range(1, src.count + 1):\n",
    "                    reproject(\n",
    "                        source=rasterio.band(src, i),\n",
    "                        destination=rasterio.band(dst, i),\n",
    "                        src_transform=src.transform,\n",
    "                        src_crs=src.crs,\n",
    "                        dst_transform=transform,\n",
    "                        dst_crs=projected_crs,\n",
    "                        resampling=Resampling.nearest,\n",
    "                    )\n",
    "\n",
    "            # Load the reprojected raster\n",
    "            with rasterio.open(\"reprojected_raster.tif\") as reprojected_src:\n",
    "                channel_mask = reprojected_src.read(1)  # Read first band\n",
    "                pixel_resolution = reprojected_src.res[0]  # Update pixel resolution after reprojection\n",
    "\n",
    "    # --- 4️⃣ Compute Wetted Area Using Projected Pixel Resolution ---\n",
    "    water_pixel_count = np.sum(channel_mask == 1)  # Count water pixels\n",
    "    wetted_area = water_pixel_count * (pixel_resolution ** 2)  # Convert to square meters\n",
    "    print(wetted_area)\n",
    "\n",
    "    # --- 5️⃣ Compute Total Channel Length ---\n",
    "    total_channel_length = channel_gdf.length.sum()  # Sum all segment lengths in meters\n",
    "    print(total_channel_length)\n",
    "\n",
    "    # --- 6️⃣ Compute Estimated Channel Width ---\n",
    "    estimated_width = wetted_area / total_channel_length\n",
    "\n",
    "    return estimated_width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(r\"D:\\Dissertation\\Data\\RiverMapping\\RiverMasks\\Beni\\reach_4\\Cleaned\\Beni_reach_4_2024_DSWE_level_3_cleaned.tif\") as src:\n",
    "    channel_mask = src.read(1)  # Read first band\n",
    "    pixel_size = src.res[0]  # Assuming square pixels, take resolution\n",
    "\n",
    "# Load main channel shapefile\n",
    "channel_gdf = gpd.read_file(r\"D:\\Dissertation\\Data\\RiverMapping\\Channels\\Beni\\reach_4\\2024\\main_channel.shp\")\n",
    "\n",
    "# Compute estimated width\n",
    "channel_width = calculate_channel_width(channel_mask, channel_gdf, pixel_size)\n",
    "print(f\"Estimated Channel Width: {channel_width:.2f} meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7636a1c",
   "metadata": {},
   "source": [
    "## Run Monte Carlo simulation to calculate total transit time from the number of storage events and storage time distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90488a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def monte_carlo_reach_transit_time(tfp_df: pd.DataFrame, storage_df: pd.DataFrame, reach_number: int, num_iterations: int = 10_000) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Runs a Monte Carlo Simulation to compute reach transit time values.\n",
    "    \n",
    "    Parameters:\n",
    "        tfp_df (pd.DataFrame): DataFrame containing TFP values for a specific reach.\n",
    "        storage_df (pd.DataFrame): DataFrame containing storage events data for multiple reaches.\n",
    "        reach_number (int): The reach number for which to calculate transit time.\n",
    "        num_iterations (int): Number of iterations for the Monte Carlo simulation (default is 10,000).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the reach transit time distribution.\n",
    "    \"\"\"\n",
    "    # Ensure column names are properly formatted\n",
    "    storage_df.columns = storage_df.columns.str.strip()\n",
    "    \n",
    "    reach_storage_events = storage_df.loc[storage_df[\"Reach\"] == reach_number, \"number_storage_events\"].values\n",
    "    if len(reach_storage_events) == 0:\n",
    "        raise ValueError(f\"No storage event data found for Reach {reach_number}.\")\n",
    "    reach_storage_events = reach_storage_events[0]\n",
    "    \n",
    "    # Randomly sample TFP values from the distribution\n",
    "    random_tfp_samples = np.random.choice(tfp_df[\"TCB\"], size=num_iterations, replace=True)\n",
    "    \n",
    "    # Compute reach transit time\n",
    "    reach_transit_time = random_tfp_samples * reach_storage_events\n",
    "    \n",
    "    # Create DataFrame for results\n",
    "    return pd.DataFrame({\"reach_transit_time_yr\": reach_transit_time})\n",
    "\n",
    "def process_all_reaches(work_dir: str, output_subfolder: str = \"RTT_fromTCB_Distributions\"):\n",
    "    \"\"\"\n",
    "    Processes all reach transit time distributions in the working directory.\n",
    "    \n",
    "    Parameters:\n",
    "        work_dir (str): Path to the working directory containing relevant data files.\n",
    "        output_subfolder (str): Name of the subfolder where output CSVs will be saved.\n",
    "    \"\"\"\n",
    "    # Define input file paths\n",
    "    storage_events_path = r\"C:\\Users\\huckr\\Desktop\\Scholarships_Apps\\FINESST\\Figures\\FINESST_storage_transit_calcs.xlsx\"\n",
    "    tfp_files = [f for f in os.listdir(work_dir) if f.startswith(\"Reach_\") and f.endswith(\"_TCB_distribution.csv\")]\n",
    "    \n",
    "    # Load storage events data\n",
    "    xls = pd.ExcelFile(storage_events_path)\n",
    "    beni_df = pd.read_excel(xls, sheet_name=\"Bermejo\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = os.path.join(work_dir, output_subfolder)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each reach\n",
    "    for tfp_file in tfp_files:\n",
    "        reach_number = int(tfp_file.split(\"_\")[1])  # Extract reach number from filename\n",
    "        tfp_df = pd.read_csv(os.path.join(work_dir, tfp_file))\n",
    "        \n",
    "        # Run Monte Carlo Simulation\n",
    "        reach_transit_time_df = monte_carlo_reach_transit_time(tfp_df, beni_df, reach_number)\n",
    "        \n",
    "        # Save output\n",
    "        output_path = os.path.join(output_dir, f\"Reach_{reach_number}_RTT_fromTCB_distribution.csv\")\n",
    "        reach_transit_time_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdf95e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_1_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_2_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_3_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_4_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_5_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_6_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_7_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_8_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_9_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_10_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_11_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_12_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_13_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_14_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_15_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_16_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_17_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_18_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_19_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_20_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_21_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_22_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_23_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_24_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_25_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_26_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_27_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_28_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_29_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_30_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_31_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_32_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_33_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_34_RTT_fromTCB_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions\\RTT_fromTCB_Distributions\\Reach_35_RTT_fromTCB_distribution.csv\n"
     ]
    }
   ],
   "source": [
    "wd = r'D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\TCB_Distributions'\n",
    "process_all_reaches(wd, 'RTT_fromTCB_Distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750620e",
   "metadata": {},
   "source": [
    "## Calculate distributions for total alluvial transit time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "353d73ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def monte_carlo_total_transit_time(rtt_dir: str, river_name: str, num_iterations: int = 10_000):\n",
    "    \"\"\"\n",
    "    Runs a Monte Carlo simulation to compute the total river transit time distribution.\n",
    "    \n",
    "    Parameters:\n",
    "        rtt_dir (str): Directory containing reach transit time distributions.\n",
    "        river_name (str): Name of the river for output file naming.\n",
    "        num_iterations (int): Number of iterations for the Monte Carlo simulation (default is 10,000).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the total river transit time distribution.\n",
    "    \"\"\"\n",
    "    rtt_files = [f for f in os.listdir(rtt_dir) if f.startswith(\"Reach_\") and f.endswith(\"_RTT_fromTCB_distribution.csv\")]\n",
    "    reach_dfs = [pd.read_csv(os.path.join(rtt_dir, file)) for file in rtt_files]\n",
    "    \n",
    "    # Ensure all distributions have the correct format\n",
    "    for df in reach_dfs:\n",
    "        if \"reach_transit_time_yr\" not in df.columns:\n",
    "            raise KeyError(\"Expected column 'reach_transit_time_yr' missing from a reach distribution file.\")\n",
    "    \n",
    "    # Monte Carlo simulation: summing random samples from each reach distribution\n",
    "    total_transit_times = [sum(np.random.choice(df[\"reach_transit_time_yr\"], 1)[0] for df in reach_dfs) for _ in range(num_iterations)]\n",
    "    \n",
    "    # Compute statistics\n",
    "    stats = {\n",
    "        \"Mean\": np.mean(total_transit_times),\n",
    "        \"Standard Deviation\": np.std(total_transit_times),\n",
    "        \"Min\": np.min(total_transit_times),\n",
    "        \"1st Quartile\": np.percentile(total_transit_times, 25),\n",
    "        \"Median\": np.median(total_transit_times),\n",
    "        \"3rd Quartile\": np.percentile(total_transit_times, 75),\n",
    "        \"Max\": np.max(total_transit_times)\n",
    "    }\n",
    "    \n",
    "    for stat, value in stats.items():\n",
    "        print(f\"{stat}: {value}\")\n",
    "    \n",
    "    # Create DataFrame for results\n",
    "    total_transit_time_df = pd.DataFrame({\"total_transit_time_yr\": total_transit_times})\n",
    "    \n",
    "    # Save output\n",
    "    output_path = os.path.join(rtt_dir, f\"{river_name}_TTT_fromTCB_distribution.csv\")\n",
    "    total_transit_time_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"Saved: {output_path}\")\n",
    "    return total_transit_time_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d6393fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 13566.868321286403\n",
      "Standard Deviation: 1701.077686646581\n",
      "Min: 10976.456775682582\n",
      "1st Quartile: 12619.830372423265\n",
      "Median: 13029.438888396508\n",
      "3rd Quartile: 13752.182449898666\n",
      "Max: 25563.612976883112\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\RTT_fromTCB_Distributions\\Bermejo_TTT_fromTCB_distribution.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_transit_time_yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13070.253949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12767.528591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12785.305558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14096.059628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13934.345422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>12419.390133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>13496.188568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>12511.151890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>13008.388194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>14192.148441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      total_transit_time_yr\n",
       "0              13070.253949\n",
       "1              12767.528591\n",
       "2              12785.305558\n",
       "3              14096.059628\n",
       "4              13934.345422\n",
       "...                     ...\n",
       "9995           12419.390133\n",
       "9996           13496.188568\n",
       "9997           12511.151890\n",
       "9998           13008.388194\n",
       "9999           14192.148441\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte_carlo_total_transit_time(r'D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\RTT_fromTCB_Distributions', 'Bermejo', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccd954b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_ttt_statistics(ttt_csv_path: str):\n",
    "    \"\"\"\n",
    "    Reads a total transit time distribution CSV and prints key statistics.\n",
    "    \n",
    "    Parameters:\n",
    "        ttt_csv_path (str): Path to the total transit time distribution CSV file.\n",
    "    \"\"\"\n",
    "    ttt_df = pd.read_csv(ttt_csv_path)\n",
    "    \n",
    "    if \"total_transit_time_yr\" not in ttt_df.columns:\n",
    "        raise KeyError(\"Expected column 'total_transit_time_yr' missing from the input file.\")\n",
    "    \n",
    "    # Compute statistics\n",
    "    stats = {\n",
    "        \"Mean\": np.mean(ttt_df[\"total_transit_time_yr\"]),\n",
    "        \"Standard Deviation\": np.std(ttt_df[\"total_transit_time_yr\"]),\n",
    "        \"Min\": np.min(ttt_df[\"total_transit_time_yr\"]),\n",
    "        \"1st Quartile\": np.percentile(ttt_df[\"total_transit_time_yr\"], 25),\n",
    "        \"Median\": np.median(ttt_df[\"total_transit_time_yr\"]),\n",
    "        \"3rd Quartile\": np.percentile(ttt_df[\"total_transit_time_yr\"], 75),\n",
    "        \"Max\": np.max(ttt_df[\"total_transit_time_yr\"])\n",
    "    }\n",
    "    \n",
    "    for stat, value in stats.items():\n",
    "        print(f\"{stat}: {value}\")\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afbf9828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 5403.3538147015415\n",
      "Standard Deviation: 141.08441148352148\n",
      "Min: 4877.258722602724\n",
      "1st Quartile: 5307.332000266164\n",
      "Median: 5403.638093746336\n",
      "3rd Quartile: 5501.716028022813\n",
      "Max: 5930.325937854683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Mean': 5403.3538147015415,\n",
       " 'Standard Deviation': 141.08441148352148,\n",
       " 'Min': 4877.258722602724,\n",
       " '1st Quartile': 5307.332000266164,\n",
       " 'Median': 5403.638093746336,\n",
       " '3rd Quartile': 5501.716028022813,\n",
       " 'Max': 5930.325937854683}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_ttt_statistics(r\"D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\Beni_TTT_fromTCB_distribution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6709d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
