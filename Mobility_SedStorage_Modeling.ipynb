{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdc864a",
   "metadata": {},
   "source": [
    "# Mobility and Storage Time Calculator\n",
    "\n",
    "The following code takes processed and \"cleaned\" water masks from a specified working directory and performs a series of operations to calculate the: 1) area-based floodplain reworking timescales (TR) and distribution of channel areas (AW); 2) the sediment storage time distributions (tstor) using the deterministic (TCB) and probabilistic (TFP) approaches; 3) the reach transit times for both tstor approaches; 4) the total sediment transit time (ttot) for both tstor approaches.\n",
    "\n",
    "Author: James (Huck) Rees; PhD Student, UCSB Geography\n",
    "\n",
    "Date: April 9, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc3318a",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490111fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "import glob as glob_module\n",
    "import math\n",
    "import geopandas as gpd\n",
    "import ast\n",
    "\n",
    "import re\n",
    "import fiona\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio import warp\n",
    "from rasterio.warp import transform_geom, calculate_default_transform, reproject, Resampling\n",
    "from rasterio.enums import Resampling\n",
    "from pyproj import CRS, Geod\n",
    "\n",
    "from scipy.stats import linregress\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "import geemap\n",
    "import ee\n",
    "from geopy.distance import geodesic\n",
    "from collections import defaultdict\n",
    "\n",
    "# Authenticate with Google Earth Engine\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a54f4",
   "metadata": {},
   "source": [
    "## Initialize functions to calculate floodplain reworking timescale (TR), channel overlap decay timescale (TM) and channel area (AW) distributions from mobility sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f10752d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_year(filename):\n",
    "    pattern = r\".*_(\\d{4})_DSWE_level_\\d+_cleaned.tif\"\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def get_utm_epsg(lon, lat):\n",
    "    zone_number = int((lon + 180) / 6) + 1\n",
    "    is_northern = lat >= 0\n",
    "    return 32600 + zone_number if is_northern else 32700 + zone_number\n",
    "\n",
    "def get_aw_dist(base_directory, output_directory, reach_range=None):\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    reach_dirs = [d for d in os.listdir(base_directory) if d.startswith(\"reach_\") and os.path.isdir(os.path.join(base_directory, d))]\n",
    "\n",
    "    for reach_dir in reach_dirs:\n",
    "        try:\n",
    "            reach_number = int(reach_dir.split('_')[1])\n",
    "\n",
    "            if isinstance(reach_range, int) and reach_number != reach_range:\n",
    "                continue\n",
    "            elif isinstance(reach_range, tuple) and not (reach_range[0] <= reach_number <= reach_range[1]):\n",
    "                continue\n",
    "\n",
    "            cleaned_dir = os.path.join(base_directory, reach_dir, \"Cleaned\")\n",
    "            if not os.path.exists(cleaned_dir):\n",
    "                print(f\"Cleaned folder not found for Reach {reach_number}.\")\n",
    "                continue\n",
    "\n",
    "            tif_files = [f for f in os.listdir(cleaned_dir) if f.endswith(\".tif\")]\n",
    "            aw_values = []\n",
    "\n",
    "            for tif_file in tif_files:\n",
    "                with rasterio.open(os.path.join(cleaned_dir, tif_file)) as src:\n",
    "                    data = src.read(1)\n",
    "                    transform = src.transform\n",
    "                    bounds = src.bounds\n",
    "                    centroid_lon = (bounds.left + bounds.right) / 2\n",
    "                    centroid_lat = (bounds.top + bounds.bottom) / 2\n",
    "                    utm_epsg = get_utm_epsg(centroid_lon, centroid_lat)\n",
    "\n",
    "                    dst_crs = CRS.from_epsg(utm_epsg)\n",
    "                    transform_utm, width, height = calculate_default_transform(\n",
    "                        src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "\n",
    "                    reprojected = np.empty((height, width), dtype=data.dtype)\n",
    "\n",
    "                    reproject(\n",
    "                        source=data,\n",
    "                        destination=reprojected,\n",
    "                        src_transform=transform,\n",
    "                        src_crs=src.crs,\n",
    "                        dst_transform=transform_utm,\n",
    "                        dst_crs=dst_crs,\n",
    "                        resampling=Resampling.nearest\n",
    "                    )\n",
    "\n",
    "                    pixel_area = abs(transform_utm.a * transform_utm.e)\n",
    "                    wet_pixel_count = np.sum(reprojected == 1)\n",
    "                    total_area_m2 = wet_pixel_count * pixel_area\n",
    "                    aw_values.append(total_area_m2)\n",
    "\n",
    "            output_df = pd.DataFrame({'a_w': aw_values})\n",
    "            output_csv = os.path.join(output_directory, f\"Reach_{reach_number}_aw_dist.csv\")\n",
    "            output_df.to_csv(output_csv, index=False)\n",
    "\n",
    "            print(f\"Saved corrected a_w totals for Reach {reach_number} to {output_csv}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing reach folder {reach_dir}: {e}\")\n",
    "\n",
    "def load_rasters(directory):\n",
    "    rasters = {}\n",
    "    wetted_areas = []\n",
    "    for filepath in os.listdir(directory):\n",
    "        if filepath.endswith('.tif'):\n",
    "            year = extract_year(filepath)\n",
    "            if year is not None:\n",
    "                with rasterio.open(os.path.join(directory, filepath)) as src:\n",
    "                    data = src.read(1)\n",
    "                    transform = src.transform\n",
    "                    pixel_area = abs(transform[0] * transform[4])\n",
    "                    wetted_area_km2 = np.sum(data == 1) * pixel_area / 1e6\n",
    "                    wetted_areas.append(wetted_area_km2)\n",
    "                    rasters[year] = (data == 1, pixel_area)\n",
    "    median_aw = np.median(wetted_areas)\n",
    "    return dict(sorted(rasters.items())), median_aw\n",
    "\n",
    "def calculate_reworked_areas(rasters):\n",
    "    delta_t_areas = defaultdict(list)\n",
    "    years = sorted(rasters.keys())\n",
    "    for i in range(len(years)):\n",
    "        t1 = years[i]\n",
    "        base_mask, pixel_area = rasters[t1]\n",
    "        union_mask = np.copy(base_mask)\n",
    "        for j in range(i + 1, len(years)):\n",
    "            t2 = years[j]\n",
    "            current_mask, _ = rasters[t2]\n",
    "            union_mask = np.logical_or(union_mask, current_mask)\n",
    "            reworked_pixels = np.sum(union_mask) - np.sum(base_mask)\n",
    "            delta_t = t2 - t1\n",
    "            reworked_area_km2 = (reworked_pixels * pixel_area) / 1e6\n",
    "            delta_t_areas[delta_t].append(reworked_area_km2)\n",
    "    return delta_t_areas\n",
    "\n",
    "def calculate_overlap_areas(rasters):\n",
    "    \"\"\"\n",
    "    Calculate the overlapping channel area (AM) between baseline and future channel positions.\n",
    "    \n",
    "    For each baseline year, calculates the intersection area with all future years,\n",
    "    representing pixels that remain channelized between the two time points.\n",
    "    \n",
    "    Parameters:\n",
    "        rasters (dict): Dictionary mapping years to tuples of (binary_mask, pixel_area)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary mapping delta_t values to lists of overlap areas in km²\n",
    "    \"\"\"\n",
    "    delta_t_areas = defaultdict(list)\n",
    "    years = sorted(rasters.keys())\n",
    "    \n",
    "    for i in range(len(years)):\n",
    "        t1 = years[i]\n",
    "        base_mask, pixel_area = rasters[t1]\n",
    "        \n",
    "        for j in range(i + 1, len(years)):\n",
    "            t2 = years[j]\n",
    "            current_mask, _ = rasters[t2]\n",
    "            \n",
    "            # Calculate intersection (overlap) between baseline and current mask\n",
    "            overlap_mask = np.logical_and(base_mask, current_mask)\n",
    "            overlap_pixels = np.sum(overlap_mask)\n",
    "            \n",
    "            delta_t = t2 - t1\n",
    "            overlap_area_km2 = (overlap_pixels * pixel_area) / 1e6\n",
    "            delta_t_areas[delta_t].append(overlap_area_km2)\n",
    "    \n",
    "    return delta_t_areas\n",
    "\n",
    "def greenberg_exponential(x, PR_over_AW, CR):\n",
    "    return -PR_over_AW * np.exp(-CR * x) + PR_over_AW\n",
    "\n",
    "def overlap_exponential(x, PM_over_AW, CM):\n",
    "    \"\"\"\n",
    "    Exponential model for overlap decay.\n",
    "    \n",
    "    AM/AW = (1 - PM_over_AW) * exp(-CM * x) + PM_over_AW\n",
    "    \n",
    "    Args:\n",
    "        x: Time (years)\n",
    "        PM_over_AW: Asymptotic minimum of overlap (normalized by active width)\n",
    "        CM: Overlap decay rate (year^-1)\n",
    "    \n",
    "    Returns:\n",
    "        Predicted overlap area normalized by active width\n",
    "    \"\"\"\n",
    "    return (1 - PM_over_AW) * np.exp(-CM * x) + PM_over_AW\n",
    "\n",
    "def calculate_pswitch(TM_over_TR,  P10=0.5903, P90=1.7413):\n",
    "    \"\"\"\n",
    "    Map TM:TR to pswitch using 10th-90th percentile range with physical bounds.\n",
    "    \n",
    "    Maps P10 (inefficient reworking) → 0.50 (high switching)\n",
    "    Maps P90 (efficient reworking) → 0.05 (minimal but non-zero switching)\n",
    "    \n",
    "    Physical justification for pswitch >= 0.05:\n",
    "    - All rivers experience some stochasticity (floods, bank failures, cutoffs)\n",
    "    - Prevents numerical instabilities in Monte Carlo simulations\n",
    "    - Consistent with observed behavior of highly efficient systems (Yukon ≈ 0.06)\n",
    "    \n",
    "    Args:\n",
    "        TM_over_TR (float): Ratio of overlap decay to reworking timescales\n",
    "        P10 (float): 10th percentile of TM:TR in dataset (default 0.5903)\n",
    "        P90 (float): 90th percentile of TM:TR in dataset (default 1.7413)\n",
    "    \n",
    "    Returns:\n",
    "        float: Switching probability [0.05, 0.50]\n",
    "    \"\"\"\n",
    "    # Linear mapping from [P10, P90] to [0.50, 0.05]\n",
    "    pswitch = 0.50 - 0.45 * ((TM_over_TR - P10) / (P90 - P10))\n",
    "    \n",
    "    # Clamp to physical bounds\n",
    "    pswitch = max(0.05, min(0.50, pswitch))\n",
    "    \n",
    "    return pswitch\n",
    "\n",
    "def calculate_TW(delta_ts, PR_over_AW, CR, subsample_n=20):\n",
    "    \"\"\"\n",
    "    Calculate the linear floodplain reworking timescale (TW) by subsampling \n",
    "    the Greenberg exponential fit and performing linear regression.\n",
    "    \n",
    "    This timescale represents the time required to rework one channel width\n",
    "    of floodplain, calculated from the linear approximation of the exponential\n",
    "    reworking curve.\n",
    "    \n",
    "    Parameters:\n",
    "        delta_ts (list or array): Time intervals from the reworked area data\n",
    "        PR_over_AW (float): Plateau parameter from Greenberg exponential fit\n",
    "        CR (float): Decay rate from Greenberg exponential fit (year^-1)\n",
    "        subsample_n (int): Number of points to subsample for linear regression (default 20)\n",
    "    \n",
    "    Returns:\n",
    "        float: TW, the linear floodplain reworking timescale (years)\n",
    "    \"\"\"\n",
    "    # Define the range for subsampling\n",
    "    min_dt = min(delta_ts)\n",
    "    max_dt = max(delta_ts)\n",
    "    \n",
    "    # Subsample the fitted exponential curve\n",
    "    subsample_delta_t = np.linspace(min_dt, max_dt, subsample_n)\n",
    "    subsample_ar_aw = greenberg_exponential(subsample_delta_t, PR_over_AW, CR)\n",
    "    \n",
    "    # Perform linear regression\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(subsample_delta_t, subsample_ar_aw)\n",
    "    \n",
    "    # Calculate TW as inverse of slope\n",
    "    TW = 1 / slope\n",
    "    \n",
    "    return TW\n",
    "\n",
    "def plot_mobility_fits(river_name, ds_order, delta_ts_rework, data_rework, PR_over_AW, CR, TR,\n",
    "                       delta_ts_overlap, data_overlap, PM_over_AW, CM, TM, output_path):\n",
    "    \"\"\"\n",
    "    Create box-and-whisker plots with fitted curves for reworked area and overlap decay.\n",
    "    \n",
    "    Parameters:\n",
    "        river_name (str): Name of the river\n",
    "        ds_order (int): Reach number\n",
    "        delta_ts_rework (list): Time intervals for reworked area data\n",
    "        data_rework (list): List of normalized reworked area distributions for each delta_t\n",
    "        PR_over_AW (float): Plateau parameter for reworked area fit\n",
    "        CR (float): Decay rate for reworked area (year^-1)\n",
    "        TR (float): Floodplain reworking timescale (years)\n",
    "        delta_ts_overlap (list): Time intervals for overlap area data\n",
    "        data_overlap (list): List of normalized overlap area distributions for each delta_t\n",
    "        PM_over_AW (float): Minimum parameter for overlap decay fit\n",
    "        CM (float): Decay rate for overlap area (year^-1)\n",
    "        TM (float): Overlap decay timescale (years)\n",
    "        output_path (str): Path to save the figure\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Reworked Area with box plots\n",
    "    bp1 = ax1.boxplot(data_rework, positions=delta_ts_rework, widths=0.8, patch_artist=True)\n",
    "    for patch in bp1['boxes']:\n",
    "        patch.set_facecolor('lightblue')\n",
    "    \n",
    "    # Fitted curve for reworked area\n",
    "    x_fit_rework = np.linspace(min(delta_ts_rework), max(delta_ts_rework), 200)\n",
    "    y_fit_rework = greenberg_exponential(x_fit_rework, PR_over_AW, CR)\n",
    "    ax1.plot(x_fit_rework, y_fit_rework, 'r-', linewidth=2, label='Greenberg fit')\n",
    "    \n",
    "    # Add equation to plot\n",
    "    equation_text_1 = f'$A_R/A_W = {PR_over_AW:.3f}(1 - e^{{-{CR:.4f}t}})$\\nTR = {TR:.2f} years'\n",
    "    ax1.text(0.05, 0.95, equation_text_1, transform=ax1.transAxes, \n",
    "            fontsize=11, verticalalignment='top', \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax1.set_xlabel('Time interval (years)', fontsize=12)\n",
    "    ax1.set_ylabel('$A_R / A_W$ (Reworked Area / Active Width)', fontsize=12)\n",
    "    ax1.set_title(f'{river_name} Reach {ds_order}: Floodplain Reworking', fontsize=14)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Overlap Decay with box plots\n",
    "    bp2 = ax2.boxplot(data_overlap, positions=delta_ts_overlap, widths=0.8, patch_artist=True)\n",
    "    for patch in bp2['boxes']:\n",
    "        patch.set_facecolor('lightgreen')\n",
    "    \n",
    "    # Fitted curve for overlap decay\n",
    "    x_fit_overlap = np.linspace(min(delta_ts_overlap), max(delta_ts_overlap), 200)\n",
    "    y_fit_overlap = overlap_exponential(x_fit_overlap, PM_over_AW, CM)\n",
    "    ax2.plot(x_fit_overlap, y_fit_overlap, 'b-', linewidth=2, label='Exponential decay fit')\n",
    "    \n",
    "    # Add equation to plot\n",
    "    equation_text_2 = f'$A_M/A_W = {1-PM_over_AW:.3f}e^{{-{CM:.4f}t}} + {PM_over_AW:.3f}$\\nTM = {TM:.2f} years'\n",
    "    ax2.text(0.05, 0.95, equation_text_2, transform=ax2.transAxes, \n",
    "            fontsize=11, verticalalignment='top', \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax2.set_xlabel('Time interval (years)', fontsize=12)\n",
    "    ax2.set_ylabel('$A_M / A_W$ (Overlap Area / Active Width)', fontsize=12)\n",
    "    ax2.set_title(f'{river_name} Reach {ds_order}: Overlap Decay', fontsize=14)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Saved mobility plots to {output_path}\")\n",
    "\n",
    "\n",
    "def calculate_mobility(river_name, ds_order, working_directory):\n",
    "    \"\"\"\n",
    "    Calculate mobility metrics (TR, TM, CR, CM, TW, pswitch) for a single river reach.\n",
    "    \n",
    "    This function analyzes channel migration data to extract floodplain reworking\n",
    "    and overlap decay characteristics. It fits exponential models to both reworked\n",
    "    area and overlap area data, then calculates characteristic timescales.\n",
    "    \n",
    "    Parameters:\n",
    "        river_name (str): Name of the river being analyzed.\n",
    "        ds_order (int): Reach number (downstream order).\n",
    "        working_directory (str): Base path to the working directory containing RiverMapping data.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing:\n",
    "              - TR (float): Floodplain reworking timescale (years)\n",
    "              - TM (float): Overlap decay timescale (years)\n",
    "              - TW (float): Linear floodplain reworking timescale (years)\n",
    "              - CR (float): Floodplain reworking decay rate (year^-1)\n",
    "              - CM (float): Overlap decay rate (year^-1)\n",
    "    \n",
    "    Outputs:\n",
    "        - CSV file: Active width distribution saved to Mobility/{river_name}/AW_distributions/\n",
    "        - PNG plots: Fitted curves for reworked and overlap areas saved to Mobility/{river_name}/MobilityPlots/\n",
    "    \"\"\"\n",
    "    # Define paths\n",
    "    base_raster_dir = f\"{working_directory}/RiverMapping/RiverMasks/{river_name}\"\n",
    "    reach_dir = f\"reach_{ds_order}\"\n",
    "    full_path = os.path.join(base_raster_dir, reach_dir, \"Cleaned\")\n",
    "    \n",
    "    output_dir = f\"{working_directory}/RiverMapping/Mobility/{river_name}\"\n",
    "    aw_output_dir = os.path.join(output_dir, \"AW_distributions\")\n",
    "    plot_output_dir = os.path.join(output_dir, \"MobilityPlots\")\n",
    "    os.makedirs(aw_output_dir, exist_ok=True)\n",
    "    os.makedirs(plot_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate AW distribution using get_aw_dist()\n",
    "    get_aw_dist(base_raster_dir, aw_output_dir, reach_range=ds_order)\n",
    "    \n",
    "    # Load the generated AW distribution\n",
    "    aw_csv_path = os.path.join(aw_output_dir, f\"Reach_{ds_order}_aw_dist.csv\")\n",
    "    aw_distribution = pd.read_csv(aw_csv_path)\n",
    "    \n",
    "    # Load rasters and calculate median active width\n",
    "    rasters, median_aw = load_rasters(full_path)\n",
    "    \n",
    "    # Calculate reworked areas\n",
    "    delta_t_areas = calculate_reworked_areas(rasters)\n",
    "    delta_ts_rework = sorted(delta_t_areas.keys())\n",
    "    data_rework = [[val / median_aw for val in delta_t_areas[dt]] for dt in delta_ts_rework]\n",
    "    medians_rework = [np.median(vals) for vals in data_rework]\n",
    "    \n",
    "    # Fit Greenberg exponential to reworked area data\n",
    "    x_data_rework = np.array(delta_ts_rework)\n",
    "    y_data_rework = np.array(medians_rework)\n",
    "    initial_guess_rework = [max(y_data_rework), 0.1]\n",
    "    popt_rework, _ = curve_fit(greenberg_exponential, x_data_rework, y_data_rework, p0=initial_guess_rework)\n",
    "    PR_over_AW, CR = popt_rework\n",
    "    \n",
    "    # Calculate TR\n",
    "    TR = (1 / CR) * (1 / PR_over_AW)\n",
    "    \n",
    "    # Calculate TW (linear floodplain reworking timescale)\n",
    "    TW = calculate_TW(delta_ts_rework, PR_over_AW, CR)\n",
    "    \n",
    "    # Calculate overlap areas\n",
    "    delta_t_overlap = calculate_overlap_areas(rasters)\n",
    "    delta_ts_overlap = sorted(delta_t_overlap.keys())\n",
    "    data_overlap = [[val / median_aw for val in delta_t_overlap[dt]] for dt in delta_ts_overlap]\n",
    "    medians_overlap = [np.median(vals) for vals in data_overlap]\n",
    "    \n",
    "    # Fit overlap exponential to overlap decay data\n",
    "    x_data_overlap = np.array(delta_ts_overlap)\n",
    "    y_data_overlap = np.array(medians_overlap)\n",
    "    initial_guess_overlap = [max(y_data_overlap), 0.1]\n",
    "    popt_overlap, _ = curve_fit(overlap_exponential, x_data_overlap, y_data_overlap, p0=initial_guess_overlap)\n",
    "    PM_over_AW, CM = popt_overlap\n",
    "    \n",
    "    # Calculate TM\n",
    "    TM = (1 / CM) * (1 / (1 - PM_over_AW))\n",
    "    \n",
    "    # Calculate floodplain reworking efficiency ratio\n",
    "    TM_over_TR = TM / TR\n",
    "    \n",
    "    # Calculate pswitch\n",
    "    pswitch = calculate_pswitch(TM_over_TR)\n",
    "    \n",
    "    # Create plots\n",
    "    plot_path = os.path.join(plot_output_dir, f\"Reach_{ds_order}_mobility_fits.png\")\n",
    "    plot_mobility_fits(river_name, ds_order, delta_ts_rework, data_rework, PR_over_AW, CR, TR,\n",
    "                       delta_ts_overlap, data_overlap, PM_over_AW, CM, TM, plot_path)\n",
    "    \n",
    "    # Return results\n",
    "    results = {\n",
    "        'TR': TR,\n",
    "        'TM': TM,\n",
    "        'TM_over_TR': TM_over_TR,\n",
    "        'TW': TW,\n",
    "        'CR': CR,\n",
    "        'CM': CM,\n",
    "        'median_aw': median_aw,\n",
    "        'PR_over_AW': PR_over_AW,\n",
    "        'PM_over_AW': PM_over_AW,\n",
    "        'pswitch': pswitch\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "    \n",
    "def get_mobility(csv_path):\n",
    "    \"\"\"\n",
    "    Iterates through a CSV file of river names and paths, calculating mobility metrics\n",
    "    (TR, TM, TW, CR, CM) for each reach as specified.\n",
    "    \n",
    "    Parameters:\n",
    "        csv_path (str): Path to the CSV file with columns:\n",
    "                        - river_name\n",
    "                        - working_directory\n",
    "                        - reach_range (e.g., \"All\", \"(1, 3)\", or \"2\")\n",
    "    \n",
    "    Outputs:\n",
    "        CSV file: Mobility metrics saved to Mobility/{river_name}/{river_name}_mobility_metrics.csv\n",
    "                  with columns: ds_order, TR, TM, TW, CR, CM, median_aw, PR_over_AW, PM_over_AW\n",
    "    \"\"\"\n",
    "    river_data = pd.read_csv(csv_path)\n",
    "    \n",
    "    for _, row in river_data.iterrows():\n",
    "        river_name = row['river_name']\n",
    "        working_directory = row['working_directory']\n",
    "        reach_range = row['reach_range']\n",
    "        \n",
    "        # Define base directory for raster masks\n",
    "        base_raster_dir = f\"{working_directory}/RiverMapping/RiverMasks/{river_name}\"\n",
    "        output_dir = f\"{working_directory}/RiverMapping/Mobility/{river_name}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Parse reach_range to determine which reaches to process\n",
    "        reach_dirs = [d for d in os.listdir(base_raster_dir) if d.startswith(\"reach_\")]\n",
    "        available_reaches = sorted([int(d.split('_')[1]) for d in reach_dirs])\n",
    "        \n",
    "        if isinstance(reach_range, str):\n",
    "            reach_range = reach_range.strip()\n",
    "            if reach_range == \"All\":\n",
    "                reaches_to_process = available_reaches\n",
    "            elif reach_range.startswith(\"(\") and reach_range.endswith(\")\"):\n",
    "                # Parse tuple format like \"(1, 3)\"\n",
    "                reach_start, reach_end = map(int, reach_range.strip(\"()\").split(\",\"))\n",
    "                reaches_to_process = [r for r in available_reaches if reach_start <= r <= reach_end]\n",
    "            else:\n",
    "                # Single reach number\n",
    "                reaches_to_process = [int(reach_range)]\n",
    "        elif isinstance(reach_range, int):\n",
    "            reaches_to_process = [reach_range]\n",
    "        elif isinstance(reach_range, tuple):\n",
    "            reach_start, reach_end = reach_range\n",
    "            reaches_to_process = [r for r in available_reaches if reach_start <= r <= reach_end]\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid reach_range format: {reach_range}\")\n",
    "        \n",
    "        # Calculate mobility metrics for each reach\n",
    "        all_results = []\n",
    "        \n",
    "        for ds_order in reaches_to_process:\n",
    "            try:\n",
    "                print(f\"Processing {river_name} Reach {ds_order}...\")\n",
    "                results = calculate_mobility(river_name, ds_order, working_directory)\n",
    "                \n",
    "                # Add ds_order to results\n",
    "                results['ds_order'] = ds_order\n",
    "                all_results.append(results)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {river_name} Reach {ds_order}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Compile results into DataFrame\n",
    "        if all_results:\n",
    "            results_df = pd.DataFrame(all_results)\n",
    "            \n",
    "            # Reorder columns for clarity\n",
    "            column_order = ['ds_order', 'TR', 'TM', 'TM_over_TR', 'TW', 'CR', 'CM', 'median_aw', 'PR_over_AW', 'PM_over_AW', 'pswitch']\n",
    "            results_df = results_df[column_order]\n",
    "            \n",
    "            # Sort by ds_order\n",
    "            results_df = results_df.sort_values('ds_order')\n",
    "            \n",
    "            # Save to CSV\n",
    "            output_csv = os.path.join(output_dir, f\"{river_name}_mobility_metrics.csv\")\n",
    "            results_df.to_csv(output_csv, index=False)\n",
    "            print(f\"Saved mobility metrics for {river_name} to {output_csv}\")\n",
    "        else:\n",
    "            print(f\"No results generated for {river_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f34d64",
   "metadata": {},
   "source": [
    "## Initialize functions to calculate first-passage time distributions of sediment storage time (TFP; probablistic tstor estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "935c57a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def import_aw_distribution(river_name, reach_number, working_directory):\n",
    "    \"\"\"\n",
    "    Imports the AW distribution for a specified reach.\n",
    "\n",
    "    Args:\n",
    "        river_name (str): Name of the river.\n",
    "        reach_number (int): Reach number to import AW distribution.\n",
    "        working_directory (str): Base working directory containing the river data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the AW distribution for the specified reach.\n",
    "    \"\"\"\n",
    "    # Define base directory for AW distributions\n",
    "    aw_dir = os.path.join(working_directory, 'RiverMapping', 'Mobility', river_name, 'AW_Distributions')\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(aw_dir):\n",
    "        raise FileNotFoundError(f\"AW distribution directory not found: {aw_dir}\")\n",
    "\n",
    "    # Load AW distribution for the specified reach\n",
    "    aw_file = os.path.join(aw_dir, f\"Reach_{reach_number}_aw_dist.csv\")\n",
    "    if not os.path.isfile(aw_file):\n",
    "        raise FileNotFoundError(f\"AW file not found: {aw_file}\")\n",
    "\n",
    "    aw_distribution = pd.read_csv(aw_file)\n",
    "\n",
    "    return aw_distribution\n",
    "\n",
    "def calculate_tstor_distribution(channel_belt_area, aw_distribution, tw, pswitch, num_iterations=10000, max_timesteps=10000):\n",
    "    \"\"\"\n",
    "    Calculates the Tstor distribution for a single reach using the random walk/single event model and returns the result.\n",
    "    \n",
    "    The channel undergoes a random walk, sampling AW values from the distribution at each timestep,\n",
    "    until it returns to its starting position x0.\n",
    "    \n",
    "    Args:\n",
    "        channel_belt_area (float): Channel belt area (in square km) for the reach.\n",
    "        aw_distribution (DataFrame): DataFrame with column 'a_w' (in square m).\n",
    "        tw (float): Lateral migration timescale.\n",
    "        pswitch (float): The probability of the channel switching direction at each timestep tw.\n",
    "        num_iterations (int): Number of simulations to run (default 10000).\n",
    "        max_timesteps (int): Maximum timesteps per simulation (default 10000).\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: A DataFrame containing the TFP distribution.\n",
    "    \"\"\"\n",
    "    # Convert channel belt area from km² to m²\n",
    "    channel_belt_area_m2 = channel_belt_area * 1_000_000\n",
    "    \n",
    "    if aw_distribution.empty:\n",
    "        raise ValueError(\"AW distribution is empty.\")\n",
    "    \n",
    "    # Extract all AW values for random sampling\n",
    "    aw_values = aw_distribution['a_w'].values\n",
    "    \n",
    "    tfp_times = []\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        x0 = np.random.uniform(0, channel_belt_area_m2)\n",
    "        x = x0\n",
    "        total_time = 0\n",
    "        timestep_count = 0\n",
    "        current_direction = np.random.choice([-1, 1])  # Initialize first direction randomly\n",
    "        \n",
    "        while timestep_count < max_timesteps:\n",
    "            # Sample a new AW value for this timestep\n",
    "            aw_step = np.random.choice(aw_values)\n",
    "            \n",
    "            # Determine direction based on switching probability\n",
    "            if np.random.random() < pswitch:\n",
    "                # Switch direction\n",
    "                current_direction = -current_direction\n",
    "            # else: keep the same direction\n",
    "            \n",
    "            direction = current_direction\n",
    "            x_intended = x + direction * aw_step\n",
    "            \n",
    "            reflection_occurred = False\n",
    "            \n",
    "            # Reflect at boundaries\n",
    "            if x_intended < 0:\n",
    "                x_new = -x_intended\n",
    "                reflection_occurred = True\n",
    "            elif x_intended > channel_belt_area_m2:\n",
    "                x_new = 2 * channel_belt_area_m2 - x_intended\n",
    "                reflection_occurred = True\n",
    "            else:\n",
    "                x_new = x_intended\n",
    "            \n",
    "            # Check if we've crossed x0 (returned to starting position)\n",
    "            crossed = False\n",
    "            \n",
    "            if reflection_occurred:\n",
    "                if (x_intended < x0 and x_new >= x0) or (x_intended > x0 and x_new <= x0) or (timestep_count > 0 and x == x0 and x_new != x0):\n",
    "                    crossed = True\n",
    "            else:\n",
    "                if (x_new >= x0 and x < x0) or (x_new <= x0 and x > x0):\n",
    "                    crossed = True\n",
    "            \n",
    "            if crossed:\n",
    "                # Calculate fractional time\n",
    "                if reflection_occurred:\n",
    "                    if x_intended < 0:\n",
    "                        distance_to_boundary = abs(x - 0)\n",
    "                        distance_from_boundary_to_x0 = abs(x0 - 0)\n",
    "                        total_distance_to_x0 = distance_to_boundary + distance_from_boundary_to_x0\n",
    "                    else:\n",
    "                        distance_to_boundary = abs(channel_belt_area_m2 - x)\n",
    "                        distance_from_boundary_to_x0 = abs(channel_belt_area_m2 - x0)\n",
    "                        total_distance_to_x0 = distance_to_boundary + distance_from_boundary_to_x0\n",
    "                    \n",
    "                    fractional_tw = (total_distance_to_x0 / aw_step) * tw\n",
    "                else:\n",
    "                    remaining_distance = abs(x0 - x)\n",
    "                    fractional_tw = (remaining_distance / aw_step) * tw\n",
    "                \n",
    "                total_time += fractional_tw\n",
    "                break\n",
    "            \n",
    "            total_time += tw\n",
    "            x = x_new\n",
    "            timestep_count += 1\n",
    "        \n",
    "        if timestep_count < max_timesteps:\n",
    "            tfp_times.append(total_time)\n",
    "    \n",
    "    result_df = pd.DataFrame({'TFP': tfp_times})\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def get_tstor_distributions(csv_path):\n",
    "    \"\"\"\n",
    "    Processes a range of reaches from a CSV file and calculates TFP distributions for each.\n",
    "\n",
    "    Args:\n",
    "        csv_path (str): Path to the CSV file containing river name, working directory, and reach range.\n",
    "\n",
    "    Outputs:\n",
    "        CSV files containing TFP distributions for each processed reach.\n",
    "    \"\"\"\n",
    "    # Load the configuration CSV\n",
    "    config_data = pd.read_csv(csv_path)\n",
    "\n",
    "    for index, row in config_data.iterrows():\n",
    "        # Extract river name, reach range, and working directory for each row\n",
    "        river_name = row['river_name']\n",
    "        reach_range = row['reach_range']\n",
    "        working_directory = row['working_directory']\n",
    "        num_iterations = row['model_iterations']\n",
    "        max_timesteps = row['max_timesteps']\n",
    "\n",
    "        # Define directories for required inputs\n",
    "        channel_belt_file = os.path.join(working_directory, 'ChannelBelts', 'Extracted_ChannelBelts', river_name, f\"{river_name}_channelbelt_areas.csv\")\n",
    "\n",
    "        # Check if the required files exist\n",
    "        if not os.path.isfile(channel_belt_file):\n",
    "            raise FileNotFoundError(f\"Channel belt areas file not found: {channel_belt_file}\")\n",
    "        \n",
    "        # Load channel belt areas data\n",
    "        channel_belt_data = pd.read_csv(channel_belt_file)\n",
    "\n",
    "        # Load mobility metrics file once per river\n",
    "        mobility_file = os.path.join(working_directory, 'RiverMapping', 'Mobility', river_name, f\"{river_name}_mobility_metrics.csv\")\n",
    "        if not os.path.isfile(mobility_file):\n",
    "            raise FileNotFoundError(f\"Mobility metrics file not found: {mobility_file}\")\n",
    "        mobility_all_reaches = pd.read_csv(mobility_file)\n",
    "\n",
    "        # Determine the reach range\n",
    "        if isinstance(reach_range, str):\n",
    "            reach_range = reach_range.strip()  # Remove any extra spaces\n",
    "\n",
    "            if reach_range == \"All\":\n",
    "                reach_start = channel_belt_data['ds_order'].min()\n",
    "                reach_end = channel_belt_data['ds_order'].max()\n",
    "            elif reach_range.isdigit():\n",
    "                # Convert a numeric string to an integer\n",
    "                reach_range = int(reach_range)\n",
    "                reach_start = reach_range\n",
    "                reach_end = reach_range\n",
    "            elif re.match(r'^\\(\\d{1,4}, \\d{1,4}\\)$', reach_range):  # Match (XX, YY) with 1 to 4 digits\n",
    "                try:\n",
    "                    # Convert the string to a tuple of integers\n",
    "                    reach_range = ast.literal_eval(reach_range)\n",
    "                    reach_start, reach_end = reach_range\n",
    "                except (ValueError, SyntaxError):\n",
    "                    raise ValueError(f\"Invalid reach range format: {reach_range}\")\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid string format for reach_range: {reach_range}\")\n",
    "        elif isinstance(reach_range, (int, float)) and float(reach_range).is_integer():\n",
    "            # Convert float-like integers (e.g., 7.0) to int\n",
    "            reach_range = int(reach_range)\n",
    "            reach_start = reach_range\n",
    "            reach_end = reach_range\n",
    "        elif isinstance(reach_range, tuple) and len(reach_range) == 2:\n",
    "            reach_start, reach_end = reach_range\n",
    "        else:\n",
    "            raise ValueError(\"reach_range must be 'All', an int, or a tuple (start, end).\")\n",
    "\n",
    "        # Generate range of reaches to process\n",
    "        reaches = range(reach_start, reach_end + 1)\n",
    "\n",
    "        # Iterate through the range of reaches and calculate TFP for each\n",
    "        for reach_number in reaches:\n",
    "            # Get TR and CR values for this reach\n",
    "            tw = mobility_all_reaches.loc[mobility_all_reaches['ds_order'] == reach_number, 'TW'].values[0]\n",
    "            pswitch = mobility_all_reaches.loc[mobility_all_reaches['ds_order'] == reach_number, 'pswitch'].values[0]\n",
    "\n",
    "            # Get channel belt area for the reach\n",
    "            channel_belt_area = channel_belt_data.loc[channel_belt_data['ds_order'] == reach_number, 'area_sq_km'].values[0]\n",
    "\n",
    "            # Import AW distribution for the reach\n",
    "            aw_distribution = import_aw_distribution(river_name, reach_number, working_directory)\n",
    "\n",
    "            # Calculate the TFP distribution for the reach\n",
    "            tfp_distribution = calculate_tstor_distribution(channel_belt_area, aw_distribution, tw, pswitch, num_iterations, max_timesteps)\n",
    "\n",
    "            # Save TFP distribution to a CSV (fixed typo: sinlge -> single)\n",
    "            output_file = os.path.join(working_directory, 'RiverMapping', 'Mobility', river_name, 'Tstor_distributions', f\"Reach_{reach_number}_Tstor_distribution.csv\")\n",
    "            os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "            tfp_distribution.to_csv(output_file, index=False)\n",
    "\n",
    "            print(f\"Tstor distribution for Reach {reach_number} saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bc7b87",
   "metadata": {},
   "source": [
    "## Initialize functions to run Monte Carlo simulation to calculate total transit time from the number of storage events and storage time distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7838d83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def monte_carlo_reach_transit_time(\n",
    "    tstor_df,\n",
    "    transit_df,\n",
    "    reach_number,\n",
    "    num_iterations = 10000\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Monte Carlo simulation of reach transit times using tstor sampling based on fractional 'n_stor'.\n",
    "    \n",
    "    Parameters:\n",
    "        tstor_df (pd.DataFrame): One-column DataFrame of storage time values (e.g. 'Tstor_yr').\n",
    "        transit_df (pd.DataFrame): DataFrame with 'ds_order' and 'n_stor' columns.\n",
    "        reach_number (int): Reach number (ds_order) for simulation.\n",
    "        num_iterations (int): Number of Monte Carlo simulations to run.\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame of simulated transit times.\n",
    "    \"\"\"\n",
    "    # Clean and check input\n",
    "    transit_df.columns = transit_df.columns.str.strip()\n",
    "    if \"ds_order\" not in transit_df or \"n_stor\" not in transit_df:\n",
    "        raise KeyError(\"transit_df must contain 'ds_order' and 'n_stor' columns.\")\n",
    "    \n",
    "    if tstor_df.shape[1] != 1:\n",
    "        raise ValueError(\"tstor_df must contain exactly one column.\")\n",
    "    \n",
    "    tstor_vals = tstor_df.iloc[:, 0].dropna().values\n",
    "    if len(tstor_vals) == 0:\n",
    "        raise ValueError(\"No valid storage time data found.\")\n",
    "    \n",
    "    # Extract n_stor\n",
    "    n_array = transit_df.loc[transit_df[\"ds_order\"] == reach_number, \"n_stor\"].values\n",
    "    if len(n_array) == 0:\n",
    "        raise ValueError(f\"Reach {reach_number} not found in transit_df.\")\n",
    "    \n",
    "    n = float(n_array[0])\n",
    "    int_part = int(np.floor(n))\n",
    "    frac_part = n - int_part\n",
    "    \n",
    "    results = []\n",
    "    for _ in range(num_iterations):\n",
    "        # Handle the integer part\n",
    "        if int_part > 0:\n",
    "            samples = np.random.choice(tstor_vals, size=int_part, replace=True)\n",
    "            total = samples.sum()\n",
    "        else:\n",
    "            total = 0.0\n",
    "        \n",
    "        # Handle the fractional part\n",
    "        if np.random.rand() < frac_part:\n",
    "            extra = np.random.choice(tstor_vals)\n",
    "            total += extra\n",
    "        \n",
    "        results.append(total)\n",
    "    \n",
    "    return pd.DataFrame({\"reach_transit_time_yr\": results})\n",
    "\n",
    "def get_reach_transittimes(work_dir: str, river_name: str):\n",
    "    \"\"\"\n",
    "    Processes all reach transit time distributions for a given river.\n",
    "    \n",
    "    Parameters:\n",
    "        work_dir (str): Path to the working directory containing relevant data files.\n",
    "        river_name (str): Name of the river to process.\n",
    "    \"\"\"\n",
    "    # Path to transit length (storage) values\n",
    "    nstor_path = os.path.join(work_dir, \"RiverMapping\", \"Mobility\", river_name, f\"{river_name}_transit_lengths.csv\")\n",
    "    nstor_vals = pd.read_csv(nstor_path)\n",
    "    \n",
    "    # Path where Tstor distribution files are stored\n",
    "    tstor_dir = os.path.join(work_dir, \"RiverMapping\", \"Mobility\", river_name, \"Tstor_distributions\")\n",
    "    tstor_files = {\n",
    "        file: pd.read_csv(os.path.join(tstor_dir, file))\n",
    "        for file in os.listdir(tstor_dir)\n",
    "        if file.endswith(\".csv\") and file.startswith(\"Reach_\")\n",
    "    }\n",
    "    \n",
    "    # Prepare output directory\n",
    "    output_dir = os.path.join(work_dir, \"RiverMapping\", \"Mobility\", river_name, \"RTT_Distributions\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each reach\n",
    "    for filename, tstor_df in tstor_files.items():\n",
    "        try:\n",
    "            reach_number = int(filename.split(\"_\")[1])\n",
    "            reach_transit_time_df = monte_carlo_reach_transit_time(tstor_df, nstor_vals, reach_number)\n",
    "            output_path = os.path.join(output_dir, f\"Reach_{reach_number}_RTT_distribution.csv\")\n",
    "            reach_transit_time_df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c577c1e",
   "metadata": {},
   "source": [
    "## Calculate distributions for total alluvial transit time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05e5a24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_ttt_statistics(directory: str):\n",
    "    \"\"\"\n",
    "    Calculates and saves statistics for all total transit time distribution CSV files\n",
    "    found in the given directory.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Directory containing TTT distribution CSV files.\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(directory) if f.endswith(\"_distribution.csv\")]\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        ttt_df = pd.read_csv(file_path)\n",
    "\n",
    "        if \"total_transit_time_yr\" not in ttt_df.columns:\n",
    "            print(f\"Skipping {file} — missing 'total_transit_time_yr' column.\")\n",
    "            continue\n",
    "\n",
    "        # Compute statistics for all columns\n",
    "        stats_list = []\n",
    "        for column in ttt_df.columns:\n",
    "            stats_list.append({\n",
    "                \"Variable\": column,\n",
    "                \"Mean\": np.mean(ttt_df[column]),\n",
    "                \"Standard Deviation\": np.std(ttt_df[column]),\n",
    "                \"Min\": np.min(ttt_df[column]),\n",
    "                \"1st Quartile\": np.percentile(ttt_df[column], 25),\n",
    "                \"Median\": np.median(ttt_df[column]),\n",
    "                \"3rd Quartile\": np.percentile(ttt_df[column], 75),\n",
    "                \"Max\": np.max(ttt_df[column])\n",
    "            })\n",
    "\n",
    "        stats_df = pd.DataFrame(stats_list)\n",
    "\n",
    "        # Build output file name\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        stats_file = f\"{base_name}_stats.csv\"\n",
    "        stats_path = os.path.join(directory, stats_file)\n",
    "        stats_df.to_csv(stats_path, index=False)\n",
    "        print(f\"Saved stats: {stats_path}\")\n",
    "\n",
    "def get_total_transit_times(working_dir: str, river_name: str, num_iterations: int = 10_000, reach_start: int = 1, reach_end: int = None):\n",
    "    \"\"\"\n",
    "    Runs a Monte Carlo simulation to compute the total river transit time distribution,\n",
    "    and includes the sampled reach-level transit times for each iteration.\n",
    "    \n",
    "    Parameters:\n",
    "        working_dir (str): Root directory containing the data folder structure.\n",
    "        river_name (str): Name of the river for output file naming.\n",
    "        num_iterations (int): Number of iterations for the Monte Carlo simulation (default is 10,000).\n",
    "        reach_start (int): Index of the first reach to include (1-based, inclusive).\n",
    "        reach_end (int): Index of the last reach to include (1-based, inclusive). If None, includes all reaches to the end.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the total river transit time and individual reach samples.\n",
    "    \"\"\"\n",
    "    rtt_dir = os.path.join(working_dir, 'RiverMapping', 'Mobility', river_name, 'RTT_Distributions')\n",
    "    all_rtt_files = os.listdir(rtt_dir)\n",
    "    \n",
    "    # Determine reach range\n",
    "    reach_end = reach_end if reach_end is not None else 100\n",
    "    \n",
    "    selected_reach_dfs = []\n",
    "    actual_reaches = []\n",
    "    \n",
    "    for reach_num in range(reach_start, reach_end + 1):\n",
    "        expected_filename = f\"Reach_{reach_num}_RTT_distribution.csv\"\n",
    "        file_path = os.path.join(rtt_dir, expected_filename)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            if \"reach_transit_time_yr\" not in df.columns:\n",
    "                raise KeyError(f\"Missing 'reach_transit_time_yr' column in file: {expected_filename}\")\n",
    "            selected_reach_dfs.append(df)\n",
    "            actual_reaches.append(reach_num)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Expected file not found: {expected_filename}\")\n",
    "    \n",
    "    simulation_results = []\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        sampled_reach_times = [np.random.choice(df[\"reach_transit_time_yr\"], 1)[0] for df in selected_reach_dfs]\n",
    "        total_time = sum(sampled_reach_times)\n",
    "        simulation_results.append(sampled_reach_times + [total_time])\n",
    "    \n",
    "    # Build DataFrame with individual reach samples and total time\n",
    "    columns = [f\"reach_{reach}_tt\" for reach in actual_reaches] + [\"total_transit_time_yr\"]\n",
    "    simulation_df = pd.DataFrame(simulation_results, columns=columns)\n",
    "    \n",
    "    # Create output filename reflecting reach range\n",
    "    reach_range_str = f\"R{reach_start}toR{reach_end}\"\n",
    "    output_filename = f\"{river_name}_{reach_range_str}_TTT_distribution.csv\"\n",
    "    output_path = os.path.join(working_dir, 'RiverMapping', 'Mobility', river_name, output_filename)\n",
    "    \n",
    "    simulation_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved: {output_path}\")\n",
    "    \n",
    "    stats_directory = os.path.join(working_dir, 'RiverMapping', 'Mobility', river_name)\n",
    "    calculate_ttt_statistics(stats_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b1ad2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_path = r\"D:\\Dissertation\\Data\\RiverMapping\\Bermejo_river_datasheet.csv\"\n",
    "working_directory = r\"D:\\Dissertation\\Data\"\n",
    "river_name = \"Bermejo\"\n",
    "iterations = 10000\n",
    "reach_start = 16\n",
    "reach_end = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0d4f8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Beni Reach 1...\n",
      "Saved corrected a_w totals for Reach 1 to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\AW_distributions\\Reach_1_aw_dist.csv\n",
      "Saved mobility plots to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\MobilityPlots\\Reach_1_mobility_fits.png\n",
      "Processing Beni Reach 2...\n",
      "Saved corrected a_w totals for Reach 2 to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\AW_distributions\\Reach_2_aw_dist.csv\n",
      "Saved mobility plots to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\MobilityPlots\\Reach_2_mobility_fits.png\n",
      "Processing Beni Reach 3...\n",
      "Saved corrected a_w totals for Reach 3 to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\AW_distributions\\Reach_3_aw_dist.csv\n",
      "Saved mobility plots to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\MobilityPlots\\Reach_3_mobility_fits.png\n",
      "Processing Beni Reach 4...\n",
      "Saved corrected a_w totals for Reach 4 to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\AW_distributions\\Reach_4_aw_dist.csv\n",
      "Saved mobility plots to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\MobilityPlots\\Reach_4_mobility_fits.png\n",
      "Processing Beni Reach 5...\n",
      "Saved corrected a_w totals for Reach 5 to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\AW_distributions\\Reach_5_aw_dist.csv\n",
      "Saved mobility plots to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\MobilityPlots\\Reach_5_mobility_fits.png\n",
      "Processing Beni Reach 6...\n",
      "Saved corrected a_w totals for Reach 6 to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\AW_distributions\\Reach_6_aw_dist.csv\n",
      "Saved mobility plots to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\MobilityPlots\\Reach_6_mobility_fits.png\n",
      "Processing Beni Reach 7...\n",
      "Saved corrected a_w totals for Reach 7 to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\AW_distributions\\Reach_7_aw_dist.csv\n",
      "Saved mobility plots to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\MobilityPlots\\Reach_7_mobility_fits.png\n",
      "Processing Beni Reach 8...\n",
      "Saved corrected a_w totals for Reach 8 to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\AW_distributions\\Reach_8_aw_dist.csv\n",
      "Saved mobility plots to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\MobilityPlots\\Reach_8_mobility_fits.png\n",
      "Processing Beni Reach 9...\n",
      "Saved corrected a_w totals for Reach 9 to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\AW_distributions\\Reach_9_aw_dist.csv\n",
      "Saved mobility plots to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\MobilityPlots\\Reach_9_mobility_fits.png\n",
      "Processing Beni Reach 10...\n",
      "Saved corrected a_w totals for Reach 10 to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\AW_distributions\\Reach_10_aw_dist.csv\n",
      "Saved mobility plots to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\MobilityPlots\\Reach_10_mobility_fits.png\n",
      "Saved mobility metrics for Beni to D:\\Dissertation\\Data/RiverMapping/Mobility/Beni\\Beni_mobility_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "get_mobility(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cd35063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tstor distribution for Reach 1 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_1_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 2 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_2_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 3 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_3_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 4 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_4_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 5 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_5_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 6 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_6_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 7 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_7_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 8 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_8_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 9 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_9_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 10 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_10_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 11 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_11_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 12 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_12_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 13 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_13_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 14 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_14_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 15 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_15_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 16 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_16_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 17 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_17_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 18 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_18_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 19 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_19_Tstor_distribution.csv\n",
      "Tstor distribution for Reach 20 saved to D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Tstor_distributions\\Reach_20_Tstor_distribution.csv\n"
     ]
    }
   ],
   "source": [
    "get_tstor_distributions(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cab2857",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\RTT_Distributions\\Reach_1_RTT_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\RTT_Distributions\\Reach_2_RTT_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\RTT_Distributions\\Reach_3_RTT_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\RTT_Distributions\\Reach_4_RTT_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\RTT_Distributions\\Reach_5_RTT_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\RTT_Distributions\\Reach_6_RTT_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\RTT_Distributions\\Reach_7_RTT_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\RTT_Distributions\\Reach_8_RTT_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\RTT_Distributions\\Reach_9_RTT_distribution.csv\n",
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\RTT_Distributions\\Reach_10_RTT_distribution.csv\n"
     ]
    }
   ],
   "source": [
    "get_reach_transittimes(working_directory, river_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d6393fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Bermejo_R16toR20_TTT_distribution.csv\n",
      "Saved stats: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Bermejo_R1toR20_TTT_distribution_stats.csv\n",
      "Saved stats: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Bermejo_R1toR3_TTT_distribution_stats.csv\n",
      "Saved stats: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Bermejo_R4toR8_TTT_distribution_stats.csv\n",
      "Saved stats: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Bermejo_R9toR15_TTT_distribution_stats.csv\n",
      "Saved stats: D:\\Dissertation\\Data\\RiverMapping\\Mobility\\Bermejo\\Bermejo_R16toR20_TTT_distribution_stats.csv\n"
     ]
    }
   ],
   "source": [
    "get_total_transit_times(working_directory, river_name, iterations, reach_start, reach_end)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
