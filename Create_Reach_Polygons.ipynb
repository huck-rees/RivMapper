{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22608716",
   "metadata": {},
   "source": [
    "# Create reach polygons\n",
    "\n",
    "The following code takes a river polyline shapefile extracted from the HydroAtlas HydroRIVERS database, and splits it into reaches that are scaled based on a linear relationship between upstream drainage area and reach length, meaning that reaches become progressively longer downstream. This relationship was deduced by examining upstream drainage area estimates at specific points along the Ganges River in India and manually measuring the width of an ideal reach at that point. Finally, buffers are applied to each reach line to create a polygon encompassing the entire reach, which is used in a subsequent script to extract river masks from that area. The script is meant to take a .csv path as an input, and iterate through each row to create reach polygons for the given rivers.\n",
    "\n",
    "Author: James (Huck) Rees; PhD Student, UCSB Geography\n",
    "\n",
    "Date: August 12th, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be3687",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98ef2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.ops import unary_union, split\n",
    "from shapely.geometry import LineString, MultiLineString, Point\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9f236",
   "metadata": {},
   "source": [
    "## Initialize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc530b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Reads the input CSV containing the necessary parameters for processing.\n",
    "\n",
    "    Parameters:\n",
    "    csv_path (str): Path to the input CSV file.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing the parameters.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    required_columns = ['river_name', 'buffer_width', 'output_folder_directory', 'output_reaches_path']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column in CSV: {col}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def reimport_river_segments(shapefile_path):\n",
    "    \"\"\"\n",
    "    Reimport river segments from a shapefile.\n",
    "\n",
    "    Parameters:\n",
    "    shapefile_path (str): Path to the shapefile.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: A GeoDataFrame containing the river segments.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(shapefile_path):\n",
    "        raise FileNotFoundError(f\"Shapefile not found: {shapefile_path}\")\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    if gdf.is_empty.any():\n",
    "        raise ValueError(\"Input shapefile contains empty geometries.\")\n",
    "    return gdf\n",
    "\n",
    "def transform_to_crs(gdf, epsg_code=3395):\n",
    "    \"\"\"\n",
    "    Transform the CRS of a GeoDataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    gdf (GeoDataFrame): GeoDataFrame to transform.\n",
    "    epsg_code (int): EPSG code of the target CRS.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: GeoDataFrame with transformed CRS.\n",
    "    \"\"\"\n",
    "    return gdf.to_crs(epsg=epsg_code)\n",
    "\n",
    "def merge_river_segments(river_segs):\n",
    "    \"\"\"\n",
    "    Merge river segments into a single LineString.\n",
    "\n",
    "    Parameters:\n",
    "    river_segs (GeoDataFrame): GeoDataFrame containing river segments.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: A GeoDataFrame containing the merged river segments.\n",
    "    \"\"\"\n",
    "    merged_line = unary_union(river_segs.geometry)\n",
    "    if isinstance(merged_line, MultiLineString):\n",
    "        all_coords = []\n",
    "        for line in merged_line.geoms:\n",
    "            all_coords.extend(line.coords)\n",
    "        merged_line = LineString(all_coords)\n",
    "    river_merged = gpd.GeoDataFrame(geometry=[merged_line], crs=river_segs.crs)\n",
    "    return river_merged\n",
    "\n",
    "def calculate_reach_len(upland_skm):\n",
    "    \"\"\"\n",
    "    Calculate reach length from upland_skm.\n",
    "\n",
    "    Parameters:\n",
    "    upland_skm (float): Upland area in square kilometers.\n",
    "\n",
    "    Returns:\n",
    "    float: Reach length in meters.\n",
    "    \"\"\"\n",
    "    return 0.0668 * upland_skm + 14316\n",
    "\n",
    "def get_upland_skm_at_distance(river_segs, distance):\n",
    "    \"\"\"\n",
    "    Sample UPLAND_SKM at a specified downstream distance.\n",
    "\n",
    "    Parameters:\n",
    "    river_segs (GeoDataFrame): GeoDataFrame containing river segments.\n",
    "    distance (float): Distance downstream in meters.\n",
    "\n",
    "    Returns:\n",
    "    float: UPLAND_SKM value at the specified distance.\n",
    "    \"\"\"\n",
    "    cumulative_length = 0\n",
    "    for _, segment in river_segs.iterrows():\n",
    "        segment_length = segment['LENGTH_KM'] * 1000  # Convert km to meters\n",
    "        if cumulative_length + segment_length >= distance:\n",
    "            return segment['UPLAND_SKM']\n",
    "        cumulative_length += segment_length\n",
    "    return river_segs.iloc[-1]['UPLAND_SKM']  # Return the UPLAND_SKM of the last segment if distance exceeds total length\n",
    "\n",
    "def create_reach_lengths(river_segs):\n",
    "    \"\"\"\n",
    "    Create reach lengths iteratively.\n",
    "\n",
    "    Parameters:\n",
    "    river_segs (GeoDataFrame): GeoDataFrame containing river segments.\n",
    "\n",
    "    Returns:\n",
    "    list: List of reach lengths in meters.\n",
    "    \"\"\"\n",
    "    reach_lengths = []\n",
    "    current_distance = 0\n",
    "    total_length = river_segs['LENGTH_KM'].sum() * 1000  # Total length in meters\n",
    "\n",
    "    while current_distance < total_length:\n",
    "        upland_skm = get_upland_skm_at_distance(river_segs, current_distance)\n",
    "        reach_length = calculate_reach_len(upland_skm)\n",
    "        reach_lengths.append(reach_length)\n",
    "        current_distance += reach_length\n",
    "\n",
    "    return reach_lengths\n",
    "\n",
    "def cut(line, distance):\n",
    "    \"\"\"\n",
    "    Cut a line at a specified distance from its starting point.\n",
    "\n",
    "    Parameters:\n",
    "    line (LineString): The line to be cut.\n",
    "    distance (float): The distance from the start of the line where the cut should be made.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two LineStrings. The first LineString is the portion of the original\n",
    "           line from the start to the cut point, and the second LineString is the portion from the\n",
    "           cut point to the end of the original line.\n",
    "    \"\"\"\n",
    "    # If the distance is 0 or greater than the line length, return the line and an empty LineString\n",
    "    if distance <= 0.0 or distance >= line.length:\n",
    "        return line, LineString()  # Return the original line and an empty LineString\n",
    "    \n",
    "    # Otherwise, split the line\n",
    "    for i, seg in enumerate(line.coords):\n",
    "        pd = line.project(Point(seg))\n",
    "        if pd == distance:\n",
    "            return LineString(line.coords[:i+1]), LineString(line.coords[i:])\n",
    "        if pd > distance:\n",
    "            cp = line.interpolate(distance)\n",
    "            return (\n",
    "                LineString(line.coords[:i] + [(cp.x, cp.y)]),\n",
    "                LineString([(cp.x, cp.y)] + line.coords[i:])\n",
    "            )\n",
    "\n",
    "def split_line_with_points(line, points):\n",
    "    \"\"\"\n",
    "    Split a LineString with a list of points.\n",
    "\n",
    "    Parameters:\n",
    "    line (LineString): The LineString to split.\n",
    "    points (list): List of Points at which to split the line.\n",
    "\n",
    "    Returns:\n",
    "    list: List of LineStrings resulting from the split.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    current_line = line\n",
    "    for p in points:\n",
    "        d = current_line.project(p)\n",
    "        seg, current_line = cut(current_line, d)\n",
    "        segments.append(seg)\n",
    "    segments.append(current_line)\n",
    "    return segments\n",
    "\n",
    "def process_river_reaches(folder_name, output_reaches_partial_path, shapefile_partial_path):\n",
    "    \"\"\"\n",
    "    Main function to process river reaches.\n",
    "\n",
    "    Parameters:\n",
    "    shapefile_path (str): Path to the input shapefile.\n",
    "    output_reaches_path (str): Path to save the output shapefile.\n",
    "    \"\"\"\n",
    "    shapefile_path = f\"{shapefile_partial_path}/{folder_name}/{folder_name}.shp\"\n",
    "    river_segs = reimport_river_segments(shapefile_path)\n",
    "    river_segs = transform_to_crs(river_segs)\n",
    "    river_merged_gdf = merge_river_segments(river_segs)\n",
    "    river_merged = river_merged_gdf.geometry[0]  # Convert to shapely LineString\n",
    "\n",
    "    # Create reach lengths and points\n",
    "    reach_lengths = create_reach_lengths(river_segs)\n",
    "    cumulative_distances = [sum(reach_lengths[:i+1]) for i in range(len(reach_lengths))]\n",
    "    points = [river_merged.interpolate(distance) for distance in cumulative_distances]\n",
    "\n",
    "    # Split the river_merged line at the points\n",
    "    split_geometries = split_line_with_points(river_merged, points)\n",
    "\n",
    "    # Create a GeoDataFrame for the split reaches\n",
    "    river_reaches = gpd.GeoDataFrame(geometry=split_geometries, crs=river_merged_gdf.crs)\n",
    "\n",
    "    # Add downstream order, reach length, and distance downstream fields\n",
    "    river_reaches['ds_order'] = range(1, len(river_reaches) + 1)\n",
    "    river_reaches['reach_len'] = [segment.length for segment in river_reaches.geometry]\n",
    "    river_reaches['ds_dist'] = river_reaches['reach_len'].cumsum()\n",
    "    \n",
    "    # Delete artifact reaches with length that equals 0\n",
    "    river_reaches = river_reaches[river_reaches['reach_len'] != 0]\n",
    "    \n",
    "    # Delete the most downstream reach if it's too small\n",
    "    river_reaches = river_reaches.sort_values(by='ds_order', ascending=False)\n",
    "    record_largest_ds_order = river_reaches.iloc[0]\n",
    "    record_second_largest_ds_order = river_reaches.iloc[1]\n",
    "\n",
    "    # Compare their 'reach_len' values\n",
    "    if record_largest_ds_order['reach_len'] < 0.8 * record_second_largest_ds_order['reach_len']:\n",
    "        # Delete the record with the largest 'ds_order' value\n",
    "        river_reaches = river_reaches.drop(record_largest_ds_order.name)\n",
    "\n",
    "    # Reorder columns to move 'geometry' to the end\n",
    "    cols = [col for col in river_reaches.columns if col != 'geometry'] + ['geometry']\n",
    "    river_reaches = river_reaches[cols]\n",
    "    \n",
    "    output_file_name = f\"{output_reaches_partial_path}/{folder_name}/{folder_name}_reaches.shp\"\n",
    "\n",
    "    # Optionally, save the river_reaches to a shapefile\n",
    "    river_reaches.to_file(output_file_name)\n",
    "\n",
    "    return river_reaches\n",
    "\n",
    "def create_buffered_reaches(folder_name, output_buffers_partial_path, river_reaches, buffer_width):\n",
    "    \"\"\"\n",
    "    Create buffers for each river segment.\n",
    "\n",
    "    Parameters:\n",
    "    river_reaches (GeoDataFrame): GeoDataFrame containing river reaches.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: A GeoDataFrame containing buffered river reaches.\n",
    "    \"\"\"\n",
    "    # Calculate buffer width as 1/8th of the reach length\n",
    "    buffer_widths = river_reaches['reach_len'] * buffer_width\n",
    "\n",
    "    # Create buffers for each segment\n",
    "    buffers = river_reaches.geometry.buffer(buffer_widths)\n",
    "\n",
    "    # Create a GeoDataFrame for the buffers\n",
    "    river_reach_buffers = river_reaches.copy()\n",
    "    river_reach_buffers['geometry'] = buffers\n",
    "    river_reach_buffers['bufwid_m'] = buffer_widths\n",
    "    river_reach_buffers['bufar_m2'] = river_reach_buffers.geometry.area\n",
    "    \n",
    "    # Construct the full path to the output shapefile, including a subfolder named river_name\n",
    "    output_directory = os.path.join(output_buffers_partial_path, folder_name)\n",
    "    output_buffers_path = os.path.join(output_directory, folder_name + '.shp')\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    # Save the river_reach_buffers to a shapefile\n",
    "    river_reach_buffers.to_file(output_buffers_path)\n",
    "\n",
    "def main(csv_path):\n",
    "    \"\"\"\n",
    "    Main function to process river data based on input from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    csv_path (str): The path to the input CSV file.\n",
    "    \"\"\"\n",
    "    # Read the input CSV\n",
    "    input_df = read_input_csv(csv_path)\n",
    "\n",
    "    # Process each row in the CSV\n",
    "    for index, row in input_df.iterrows():\n",
    "        try:\n",
    "            folder_name = row['river_name']\n",
    "            buffer_width = row['buffer_width']\n",
    "            shapefile_path = row['output_folder_directory']\n",
    "            output_reaches_path = row['output_folder_directory']\n",
    "            output_buffers_path = row['output_reaches_path']\n",
    "            \n",
    "            # Check for missing values in required columns\n",
    "            if pd.isna(folder_name) or pd.isna(buffer_width) or pd.isna(shapefile_path) or pd.isna(output_reaches_path) or pd.isna(output_buffers_path):\n",
    "                print(f\"Skipping {folder_name or 'Unknown River'} due to missing data.\")\n",
    "                continue\n",
    "            \n",
    "            # Process the river reaches\n",
    "            river_reaches = process_river_reaches(folder_name, output_reaches_path, shapefile_path)\n",
    "            \n",
    "            # Create buffered reaches\n",
    "            create_buffered_reaches(folder_name, output_buffers_path, river_reaches, buffer_width)\n",
    "        \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Skipping {folder_name or 'Unknown River'}: {e}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping {folder_name or 'Unknown River'}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while processing {folder_name or 'Unknown River'}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295493c",
   "metadata": {},
   "source": [
    "## Enter input variables and run\n",
    "\n",
    "The user only needs to enter the path to the .csv file they wish to process from. An formatted example for the input datasheet may be found here: (need to add this in later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "024d145e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n"
     ]
    }
   ],
   "source": [
    "csv_path = r\"C:\\Users\\huckr\\Desktop\\UCSB\\Dissertation\\Data\\RiverMapping\\New_Guinea_river_datasheet.csv\"  # Replace with the actual path to the CSV file\n",
    "\n",
    "main(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d0dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
