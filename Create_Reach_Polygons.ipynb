{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22608716",
   "metadata": {},
   "source": [
    "# Create reach polygons\n",
    "\n",
    "The following code takes a river polyline shapefile extracted from the HydroAtlas HydroRIVERS database (see Extract_River_Segments_from_HydroRIVERS.ipynb), and splits it into reaches that are scaled based on a linear relationship between upstream drainage area and reach length, meaning that reaches become progressively longer downstream. This relationship was deduced by examining upstream drainage area estimates at specific points along the Ganges River in India and manually measuring the width of an ideal reach at that point. Finally, buffers are applied to each reach line to create a polygon encompassing the entire reach, which is used in a subsequent script to extract river masks from that area. The script is meant to take a path to a standardized RivMapper input sheet .csv as an input, and iterate through each row to create reach polygons for the given rivers. Reach polygon buffers are output to a specified local folder.\n",
    "\n",
    "HydroRIVERS database: https://www.hydrosheds.org/page/hydroatlas\n",
    "\n",
    "Citation: Lehner, B., Verdin, K., Jarvis, A., 2008. New Global Hydrography Derived From Spaceborne Elevation Data. Eos, Transactions American Geophysical Union 89, 93â€“94. https://doi.org/10.1029/2008EO100001\n",
    "\n",
    "Logic for downstream increases in reach length, scaling with upstream drainage area: \"A reach is a continuous length of river corridor with consistent geometry and linear downstream increases in drainage area, which may be tens of meters long in a small river and tens of kilometers long in a major river.\" - Professor Ellen Wohl\n",
    "\n",
    "Author: James (Huck) Rees; PhD Student, UCSB Geography\n",
    "\n",
    "Date: January 7, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be3687",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98ef2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.ops import unary_union, split\n",
    "from shapely.geometry import LineString, MultiLineString, Point\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d9f236",
   "metadata": {},
   "source": [
    "## Initialize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc530b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Reads the input CSV containing the necessary parameters for processing.\n",
    "\n",
    "    Parameters:\n",
    "    csv_path (str): Path to the input CSV file.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame containing the parameters.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"CSV file not found: {csv_path}\")\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    required_columns = ['river_name', 'buffer_width', 'working_directory']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column in CSV: {col}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def reimport_river_segments(shapefile_path):\n",
    "    \"\"\"\n",
    "    Reimport river segments from a shapefile.\n",
    "\n",
    "    Parameters:\n",
    "    shapefile_path (str): Path to the shapefile.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: A GeoDataFrame containing the river segments.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(shapefile_path):\n",
    "        raise FileNotFoundError(f\"Shapefile not found: {shapefile_path}\")\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    if gdf.is_empty.any():\n",
    "        raise ValueError(\"Input shapefile contains empty geometries.\")\n",
    "    return gdf\n",
    "\n",
    "def transform_to_crs(gdf, epsg_code=3395):\n",
    "    \"\"\"\n",
    "    Transform the CRS of a GeoDataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    gdf (GeoDataFrame): GeoDataFrame to transform.\n",
    "    epsg_code (int): EPSG code of the target CRS.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: GeoDataFrame with transformed CRS.\n",
    "    \"\"\"\n",
    "    return gdf.to_crs(epsg=epsg_code)\n",
    "\n",
    "def merge_river_segments(river_segs):\n",
    "    \"\"\"\n",
    "    Merge river segments into a single LineString.\n",
    "\n",
    "    Parameters:\n",
    "    river_segs (GeoDataFrame): GeoDataFrame containing river segments.\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame: A GeoDataFrame containing the merged river segments.\n",
    "    \"\"\"\n",
    "    merged_line = unary_union(river_segs.geometry)\n",
    "    if isinstance(merged_line, MultiLineString):\n",
    "        all_coords = []\n",
    "        for line in merged_line.geoms:\n",
    "            all_coords.extend(line.coords)\n",
    "        merged_line = LineString(all_coords)\n",
    "    river_merged = gpd.GeoDataFrame(geometry=[merged_line], crs=river_segs.crs)\n",
    "    return river_merged\n",
    "\n",
    "def calculate_reach_len(upland_skm, modulator):\n",
    "    \"\"\"\n",
    "    Original coefficient based on excel relationship: 0.0668\n",
    "    Calculate reach length from upland_skm.\n",
    "\n",
    "    Parameters:\n",
    "    upland_skm (float): Upland area in square kilometers.\n",
    "\n",
    "    Returns:\n",
    "    float: Reach length in meters.\n",
    "    \"\"\"\n",
    "    return modulator * 0.0668 * upland_skm + 14316\n",
    "\n",
    "def get_upland_skm_at_distance(river_segs, distance):\n",
    "    \"\"\"\n",
    "    Sample UPLAND_SKM at a specified downstream distance.\n",
    "\n",
    "    Parameters:\n",
    "    river_segs (GeoDataFrame): GeoDataFrame containing river segments.\n",
    "    distance (float): Distance downstream in meters.\n",
    "\n",
    "    Returns:\n",
    "    float: UPLAND_SKM value at the specified distance.\n",
    "    \"\"\"\n",
    "    cumulative_length = 0\n",
    "    for _, segment in river_segs.iterrows():\n",
    "        segment_length = segment['LENGTH_KM'] * 1000  # Convert km to meters\n",
    "        if cumulative_length + segment_length >= distance:\n",
    "            return segment['UPLAND_SKM']\n",
    "        cumulative_length += segment_length\n",
    "    return river_segs.iloc[-1]['UPLAND_SKM']  # Return the UPLAND_SKM of the last segment if distance exceeds total length\n",
    "\n",
    "def create_reach_lengths(river_segs, modulator):\n",
    "    \"\"\"\n",
    "    Create reach lengths iteratively.\n",
    "\n",
    "    Parameters:\n",
    "    river_segs (GeoDataFrame): GeoDataFrame containing river segments.\n",
    "\n",
    "    Returns:\n",
    "    list: List of reach lengths in meters.\n",
    "    \"\"\"\n",
    "    reach_lengths = []\n",
    "    current_distance = 0\n",
    "    total_length = river_segs['LENGTH_KM'].sum() * 1000  # Total length in meters\n",
    "\n",
    "    while current_distance < total_length:\n",
    "        upland_skm = get_upland_skm_at_distance(river_segs, current_distance)\n",
    "        reach_length = calculate_reach_len(upland_skm, modulator)\n",
    "        reach_lengths.append(reach_length)\n",
    "        current_distance += reach_length\n",
    "\n",
    "    return reach_lengths\n",
    "\n",
    "def cut(line, distance):\n",
    "    \"\"\"\n",
    "    Cut a line at a specified distance from its starting point.\n",
    "\n",
    "    Parameters:\n",
    "    line (LineString): The line to be cut.\n",
    "    distance (float): The distance from the start of the line where the cut should be made.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two LineStrings. The first LineString is the portion of the original\n",
    "           line from the start to the cut point, and the second LineString is the portion from the\n",
    "           cut point to the end of the original line.\n",
    "    \"\"\"\n",
    "    # If the distance is 0 or greater than the line length, return the line and an empty LineString\n",
    "    if distance <= 0.0 or distance >= line.length:\n",
    "        return line, LineString()  # Return the original line and an empty LineString\n",
    "    \n",
    "    # Otherwise, split the line\n",
    "    for i, seg in enumerate(line.coords):\n",
    "        pd = line.project(Point(seg))\n",
    "        if pd == distance:\n",
    "            return LineString(line.coords[:i+1]), LineString(line.coords[i:])\n",
    "        if pd > distance:\n",
    "            cp = line.interpolate(distance)\n",
    "            return (\n",
    "                LineString(line.coords[:i] + [(cp.x, cp.y)]),\n",
    "                LineString([(cp.x, cp.y)] + line.coords[i:])\n",
    "            )\n",
    "\n",
    "def split_line_with_points(line, points):\n",
    "    \"\"\"\n",
    "    Split a LineString with a list of points.\n",
    "\n",
    "    Parameters:\n",
    "    line (LineString): The LineString to split.\n",
    "    points (list): List of Points at which to split the line.\n",
    "\n",
    "    Returns:\n",
    "    list: List of LineStrings resulting from the split.\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    current_line = line\n",
    "    for p in points:\n",
    "        d = current_line.project(p)\n",
    "        seg, current_line = cut(current_line, d)\n",
    "        segments.append(seg)\n",
    "    segments.append(current_line)\n",
    "    return segments\n",
    "\n",
    "def process_river_reaches(folder_name, modulator, output_reaches_partial_path, shapefile_partial_path):\n",
    "    \"\"\"\n",
    "    Main function to process river reaches.\n",
    "\n",
    "    Parameters:\n",
    "    shapefile_path (str): Path to the input shapefile.\n",
    "    output_reaches_path (str): Path to save the output shapefile.\n",
    "    \"\"\"\n",
    "    shapefile_path = f\"{shapefile_partial_path}/{folder_name}/{folder_name}.shp\"\n",
    "    river_segs = reimport_river_segments(shapefile_path)\n",
    "    river_segs = transform_to_crs(river_segs)\n",
    "    river_merged_gdf = merge_river_segments(river_segs)\n",
    "    river_merged = river_merged_gdf.geometry[0]  # Convert to shapely LineString\n",
    "\n",
    "    # Create reach lengths and points\n",
    "    reach_lengths = create_reach_lengths(river_segs, modulator)\n",
    "    cumulative_distances = [sum(reach_lengths[:i+1]) for i in range(len(reach_lengths))]\n",
    "    points = [river_merged.interpolate(distance) for distance in cumulative_distances]\n",
    "\n",
    "    # Split the river_merged line at the points\n",
    "    split_geometries = split_line_with_points(river_merged, points)\n",
    "\n",
    "    # Create a GeoDataFrame for the split reaches\n",
    "    river_reaches = gpd.GeoDataFrame(geometry=split_geometries, crs=river_merged_gdf.crs)\n",
    "\n",
    "    # Add downstream order, reach length, and distance downstream fields\n",
    "    river_reaches['ds_order'] = range(1, len(river_reaches) + 1)\n",
    "    river_reaches['reach_len'] = [segment.length for segment in river_reaches.geometry]\n",
    "    river_reaches['ds_dist'] = river_reaches['reach_len'].cumsum()\n",
    "    \n",
    "    # Delete artifact reaches with length that equals 0\n",
    "    river_reaches = river_reaches[river_reaches['reach_len'] != 0]\n",
    "    \n",
    "    # Delete the most downstream reach if it's too small\n",
    "    river_reaches = river_reaches.sort_values(by='ds_order', ascending=False)\n",
    "    record_largest_ds_order = river_reaches.iloc[0]\n",
    "    record_second_largest_ds_order = river_reaches.iloc[1]\n",
    "\n",
    "    # Compare their 'reach_len' values\n",
    "    if record_largest_ds_order['reach_len'] < 0.8 * record_second_largest_ds_order['reach_len']:\n",
    "        # Delete the record with the largest 'ds_order' value\n",
    "        river_reaches = river_reaches.drop(record_largest_ds_order.name)\n",
    "\n",
    "    # Reorder columns to move 'geometry' to the end\n",
    "    cols = [col for col in river_reaches.columns if col != 'geometry'] + ['geometry']\n",
    "    river_reaches = river_reaches[cols]\n",
    "    \n",
    "    output_file_name = f\"{output_reaches_partial_path}/{folder_name}/{folder_name}_reaches.shp\"\n",
    "\n",
    "    # Optionally, save the river_reaches to a shapefile\n",
    "    river_reaches.to_file(output_file_name)\n",
    "\n",
    "    return river_reaches\n",
    "\n",
    "def create_buffered_reaches(folder_name, output_buffers_partial_path, river_reaches, buffer_width):\n",
    "    \"\"\"\n",
    "    Create buffers for each river segment.\n",
    "\n",
    "    Parameters:\n",
    "    folder_name (str): Name of the folder to store outputs.\n",
    "    output_buffers_partial_path (str): Path to the directory for storing buffers.\n",
    "    river_reaches (GeoDataFrame): GeoDataFrame containing river reaches.\n",
    "    buffer_width (float): Multiplier for calculating buffer width.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Calculate buffer widths and create buffers\n",
    "    river_reaches['bufwid_m'] = river_reaches['reach_len'] * buffer_width\n",
    "    river_reaches['geometry'] = river_reaches.geometry.buffer(river_reaches['bufwid_m'])\n",
    "    river_reaches['bufar_m2'] = river_reaches.geometry.area\n",
    "\n",
    "    # Construct output path and ensure the directory exists\n",
    "    output_directory = os.path.join(output_buffers_partial_path, folder_name)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    output_buffers_path = os.path.join(output_directory, f\"{folder_name}.shp\")\n",
    "\n",
    "    # Save the buffered reaches to a shapefile\n",
    "    river_reaches.to_file(output_buffers_path)\n",
    "\n",
    "def main(csv_path):\n",
    "    \"\"\"\n",
    "    Main function to process river data based on input from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        csv_path (str): The path to the input CSV file.\n",
    "    \"\"\"\n",
    "    # Read the input CSV\n",
    "    input_df = read_input_csv(csv_path)\n",
    "\n",
    "    # Iterate over rows and process each river\n",
    "    for _, row in input_df.iterrows():\n",
    "        folder_name = row.get('river_name', 'Unknown River')\n",
    "        working_directory = row.get('working_directory')\n",
    "        modulator = row.get('reach_length_modulator')\n",
    "        buffer_width = row.get('buffer_width')\n",
    "\n",
    "        try:\n",
    "            # Ensure all necessary data is present\n",
    "            if not all([folder_name, working_directory, buffer_width]):\n",
    "                print(f\"Skipping {folder_name} due to missing data.\")\n",
    "                continue\n",
    "\n",
    "            shapefile_path = os.path.join(working_directory, \"HydroATLAS\", \"HydroRIVERS\", \"Extracted_Rivers\")\n",
    "            output_buffers_path = os.path.join(working_directory, \"RiverMapping\", \"Reaches\")\n",
    "            os.makedirs(output_buffers_path, exist_ok=True)\n",
    "\n",
    "            # Process the river reaches and create buffered reaches\n",
    "            river_reaches = process_river_reaches(folder_name, modulator, shapefile_path, shapefile_path)\n",
    "            create_buffered_reaches(folder_name, output_buffers_path, river_reaches, buffer_width)\n",
    "\n",
    "        except (FileNotFoundError, ValueError) as e:\n",
    "            print(f\"Skipping {folder_name}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while processing {folder_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295493c",
   "metadata": {},
   "source": [
    "## Enter input variables and run\n",
    "\n",
    "The user only needs to enter the path to the .csv file they wish to process from. An formatted example for the input datasheet may be found here: (need to add this in later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "024d145e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\shapely\\linear.py:88: RuntimeWarning: invalid value encountered in line_locate_point\n",
      "  return lib.line_locate_point(line, other)\n"
     ]
    }
   ],
   "source": [
    "csv_path = r\"D:\\Dissertation\\Data\\Geyman_river_datasheet.csv\" # Replace with the actual path to the CSV file\n",
    "main(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea5917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
