{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "097967ed",
   "metadata": {},
   "source": [
    "# Hydraulic Geometry Calculator\n",
    "\n",
    "The following code takes the standard RivMapper reach polygons, and clips and trims the Global Bankfull Discharge Dataset (GQBF) to each reach. Using this dataset. Using GQBF, the ArcticDEM, NASADEM, the BASED stream depth estimator API, and standard Python geospatial libraries, the code extracts the median wetted channel width, median bankfull discharge, channel length, channel slope, and estimated bankfull channel depth for each reach, outputting all metrics to a .csv and mapping elevation sampling points and exporting the channel map and slope regression to PNGs.\n",
    "\n",
    "Global River BankFull Discharge (GQBF): \n",
    "Liu, Y., Wortmann, M., & Slater, L. (2024). Global River BankFull Discharge (GQBF) (0.1) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.13855371\n",
    "\n",
    "NASADEM: https://developers.google.com/earth-engine/datasets/catalog/NASA_NASADEM_HGT_001\n",
    "\n",
    "ArcticDEM:https://www.pgc.umn.edu/data/arcticdem/\n",
    "\n",
    "Boost-Assisted Stream Estimator for Depth (BASED):https://github.com/jameshgrn/based_api\n",
    "\n",
    "Author: James (Huck) Rees; PhD Student, UCSB Geography\n",
    "\n",
    "Date: January 21, 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2916fabd",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4a3b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj\n",
    "from pyproj import CRS, Transformer\n",
    "import os\n",
    "from shapely.ops import unary_union, split, linemerge\n",
    "from shapely.geometry import LineString, Point\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import warnings\n",
    "import ee\n",
    "\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dfa812",
   "metadata": {},
   "source": [
    "## Initialize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9e2e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GQBF(river_name, reach_gdf, continent_abr, working_directory):\n",
    "    shapefile_path = os.path.join(working_directory, 'GQBF', 'Extracted_rivers', river_name, f\"{river_name}.shp\")\n",
    "    \n",
    "    if os.path.isfile(shapefile_path):\n",
    "        gdf = gpd.read_file(shapefile_path)\n",
    "    else:\n",
    "        gdf = extract_GQBF(river_name, reach_gdf, continent_abr, working_directory)\n",
    "\n",
    "    if gdf is not None and not gdf.empty:\n",
    "        trimmed_gdf = trim_GQBF(reach_gdf, gdf)\n",
    "        return trimmed_gdf\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_GQBF(river_name, reach_gdf, continent_abr, working_directory):\n",
    "    # Map HydroATLAS zone codes to GQBF continent abbreviations\n",
    "    continent_mapping = {\n",
    "        'ar': 'na',  # Arctic regions use North America geopackage\n",
    "        # Add other mappings here if needed\n",
    "    }\n",
    "    \n",
    "    # Convert continent abbreviation if needed\n",
    "    gqbf_continent = continent_mapping.get(continent_abr, continent_abr)\n",
    "    \n",
    "    gpkg_filename = f\"GQBFv0.1_reaches_{gqbf_continent}_EPSG4326.gpkg\"\n",
    "    gpkg_path = os.path.join(working_directory, 'GQBF', gpkg_filename)\n",
    "    \n",
    "    if not os.path.isfile(gpkg_path):\n",
    "        raise FileNotFoundError(f\"GeoPackage file not found: {gpkg_path}\")\n",
    "    \n",
    "    # Get bounding box of reach and read only relevant features\n",
    "    reach_bounds = tuple(reach_gdf.total_bounds)\n",
    "    gdf = gpd.read_file(gpkg_path, bbox=reach_bounds)\n",
    "    \n",
    "    if gdf.crs.to_epsg() != 4326:\n",
    "        gdf = gdf.to_crs(epsg=4326)\n",
    "    \n",
    "    # Rename columns to match shapefile truncated names\n",
    "    gdf = gdf.rename(columns={\n",
    "        'upstream_line_ids': 'upstream_l',\n",
    "        'downstream_line_ids': 'downstre_1',\n",
    "        'grwl_width_median': 'grwl_width'\n",
    "    })\n",
    "    \n",
    "    # Precise intersection check\n",
    "    filtered_gdf = gdf[gdf.intersects(reach_gdf.unary_union)]\n",
    "    \n",
    "    output_path = os.path.join(working_directory, 'GQBF', 'Extracted_rivers', river_name)\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    shapefile_path = os.path.join(output_path, f\"{river_name}.shp\")\n",
    "    \n",
    "    if not filtered_gdf.empty:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings('ignore', message='.*Column names longer than.*')\n",
    "            filtered_gdf.to_file(shapefile_path)\n",
    "    \n",
    "    return filtered_gdf\n",
    "\n",
    "def get_reach(river_name, working_directory):\n",
    "    reach_shapefile_path = os.path.join(working_directory, 'RiverMapping', 'Reaches', river_name, f\"{river_name}.shp\")\n",
    "\n",
    "    if not os.path.isfile(reach_shapefile_path):\n",
    "        raise FileNotFoundError(f\"Reach shapefile not found: {reach_shapefile_path}\")\n",
    "\n",
    "    reach_gdf = gpd.read_file(reach_shapefile_path)\n",
    "\n",
    "    if reach_gdf.crs is None:\n",
    "        raise ValueError(f\"Reach shapefile does not have a CRS: {reach_shapefile_path}\")\n",
    "    \n",
    "    if reach_gdf.crs.to_epsg() != 4326:\n",
    "        reach_gdf = reach_gdf.to_crs(epsg=4326)\n",
    "\n",
    "    return reach_gdf\n",
    "\n",
    "def trim_GQBF(reach_gdf, filtered_gdf):\n",
    "    ds_order_1_reaches = reach_gdf[reach_gdf['ds_order'] == 1]\n",
    "    trimmed_gqbf_gdf = filtered_gdf[filtered_gdf.intersects(ds_order_1_reaches.unary_union)].copy()\n",
    "    \n",
    "    def parse_upstream_l(value):\n",
    "        if isinstance(value, str):\n",
    "            return [int(v) for v in value.split(',') if v.strip()]  # Filter out empty strings\n",
    "        elif isinstance(value, int):\n",
    "            return [value]\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    trimmed_gqbf_gdf.loc[:, 'parsed_upstream_l'] = trimmed_gqbf_gdf['upstream_l'].apply(parse_upstream_l)\n",
    "    \n",
    "    upstream_end_gqbf_gdf = trimmed_gqbf_gdf[trimmed_gqbf_gdf.apply(lambda row: all(up not in trimmed_gqbf_gdf['reach_id'].values for up in row['parsed_upstream_l']), axis=1)].copy()\n",
    "    \n",
    "    if not upstream_end_gqbf_gdf.empty:\n",
    "        current_segment = upstream_end_gqbf_gdf.loc[upstream_end_gqbf_gdf['qbf'].idxmax()].copy()\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    mainstem_segments = []\n",
    "    while current_segment is not None:\n",
    "        mainstem_segments.append(current_segment)\n",
    "        \n",
    "        downstre_values = current_segment['downstre_1']\n",
    "        if isinstance(downstre_values, str):\n",
    "            downstream_ids = [int(v) for v in downstre_values.split(',')]\n",
    "        elif isinstance(downstre_values, int):\n",
    "            downstream_ids = [downstre_values]\n",
    "        else:\n",
    "            downstream_ids = []\n",
    "        \n",
    "        downstream_segments = trimmed_gqbf_gdf[trimmed_gqbf_gdf['reach_id'].isin(downstream_ids)]\n",
    "        if not downstream_segments.empty:\n",
    "            current_segment = downstream_segments.loc[downstream_segments['qbf'].idxmax()].copy()\n",
    "        else:\n",
    "            current_segment = None\n",
    "    \n",
    "    ordered_reach_ids = [seg['reach_id'] for seg in mainstem_segments]\n",
    "    segment_dict = {seg['reach_id']: seg for seg in mainstem_segments}\n",
    "    mainstem_gqbf_gdf = gpd.GeoDataFrame([segment_dict[rid] for rid in ordered_reach_ids])\n",
    "    mainstem_gqbf_gdf.crs = filtered_gdf.crs\n",
    "    \n",
    "    return mainstem_gqbf_gdf\n",
    "\n",
    "def get_elevation(lat, lon, max_retries=3):\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            point = ee.Geometry.Point([lon, lat])\n",
    "            \n",
    "            if lat >= 60:\n",
    "                dem = ee.Image('UMN/PGC/ArcticDEM/V3/2m_mosaic')\n",
    "                band = 'elevation'\n",
    "                scale = 32\n",
    "            else:\n",
    "                dem = ee.Image('NASA/NASADEM_HGT/001')\n",
    "                band = 'elevation'\n",
    "                scale = 30\n",
    "            \n",
    "            sample = dem.select(band).sample(point, scale).first()\n",
    "            \n",
    "            if sample:\n",
    "                elevation = sample.get(band).getInfo()\n",
    "                if elevation is not None and -500 < elevation < 9000:\n",
    "                    return elevation, None\n",
    "                else:\n",
    "                    return None, f\"Invalid elevation: {elevation}\"\n",
    "            \n",
    "            return None, \"No data at location\"\n",
    "            \n",
    "        except ee.EEException as e:\n",
    "            error_msg = str(e)\n",
    "            if 'User memory limit exceeded' in error_msg or 'Computation timed out' in error_msg:\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(2 ** attempt)\n",
    "                    continue\n",
    "            return None, f\"GEE Error: {error_msg[:100]}\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "            return None, f\"Error: {str(e)}\"\n",
    "    \n",
    "    return None, \"Max retries exceeded\"\n",
    "\n",
    "def get_slope(reach_gdf, gqbf_gdf, river_name, working_directory):\n",
    "    def get_point_elevation(point):\n",
    "        return get_elevation(point.y, point.x)\n",
    "    \n",
    "    slope_dict = {}\n",
    "    \n",
    "    for idx, reach in reach_gdf.iterrows():\n",
    "        ds_order = reach['ds_order']\n",
    "        \n",
    "        reach_segments = gqbf_gdf[gqbf_gdf.intersects(reach.geometry)].copy()\n",
    "        \n",
    "        if reach_segments.empty:\n",
    "            slope_dict[ds_order] = None\n",
    "            continue\n",
    "        \n",
    "        total_length = reach_segments['length'].sum()\n",
    "        \n",
    "        if total_length == 0:\n",
    "            slope_dict[ds_order] = None\n",
    "            continue\n",
    "        \n",
    "        # Sample elevations\n",
    "        n_samples = 25\n",
    "        target_distances = np.linspace(0, total_length, n_samples)\n",
    "        \n",
    "        segment_cumulative_distances = [0]\n",
    "        for _, seg in reach_segments.iterrows():\n",
    "            segment_cumulative_distances.append(segment_cumulative_distances[-1] + seg['length'])\n",
    "        \n",
    "        elevations = []\n",
    "        distances = []\n",
    "        sample_points = []\n",
    "        sample_numbers = []\n",
    "        \n",
    "        for i, target_dist in enumerate(target_distances):\n",
    "            seg_idx = 0\n",
    "            for j in range(len(segment_cumulative_distances) - 1):\n",
    "                if segment_cumulative_distances[j] <= target_dist < segment_cumulative_distances[j + 1]:\n",
    "                    seg_idx = j\n",
    "                    break\n",
    "            else:\n",
    "                seg_idx = len(reach_segments) - 1\n",
    "            \n",
    "            seg = reach_segments.iloc[seg_idx]\n",
    "            dist_from_seg_start = target_dist - segment_cumulative_distances[seg_idx]\n",
    "            fraction_in_seg = dist_from_seg_start / seg['length'] if seg['length'] > 0 else 0\n",
    "            fraction_in_seg = np.clip(fraction_in_seg, 0, 1)\n",
    "            point = seg.geometry.interpolate(fraction_in_seg, normalized=True)\n",
    "            \n",
    "            try:\n",
    "                elev, error = get_point_elevation(point)\n",
    "                if elev is not None:\n",
    "                    elevations.append(elev)\n",
    "                    distances.append(target_dist)\n",
    "                    sample_points.append(point)\n",
    "                    sample_numbers.append(i + 1)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if len(elevations) < 2:\n",
    "            slope_dict[ds_order] = None\n",
    "            continue\n",
    "        \n",
    "        # Outlier detection\n",
    "        elevations_array = np.array(elevations)\n",
    "        distances_array = np.array(distances)\n",
    "        sample_numbers_array = np.array(sample_numbers)\n",
    "        \n",
    "        median_elev = np.median(elevations_array)\n",
    "        q1 = np.percentile(elevations_array, 25)\n",
    "        q3 = np.percentile(elevations_array, 75)\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - max(2.5 * iqr, 3.0)\n",
    "        upper_bound = q3 + max(2.5 * iqr, 3.0)\n",
    "        \n",
    "        is_outlier = (elevations_array < lower_bound) | (elevations_array > upper_bound)\n",
    "        \n",
    "        elevations_clean = elevations_array[~is_outlier]\n",
    "        distances_clean = distances_array[~is_outlier]\n",
    "        sample_numbers_clean = sample_numbers_array[~is_outlier]\n",
    "        \n",
    "        if len(elevations_clean) < 2:\n",
    "            slope_dict[ds_order] = None\n",
    "            continue\n",
    "        \n",
    "        # Sort by distance\n",
    "        sort_indices = np.argsort(distances_clean)\n",
    "        distances_clean = distances_clean[sort_indices]\n",
    "        elevations_clean = elevations_clean[sort_indices]\n",
    "        sample_numbers_clean = sample_numbers_clean[sort_indices]\n",
    "        \n",
    "        # Calculate slope\n",
    "        slope_channel, intercept = np.polyfit(distances_clean, elevations_clean, 1)\n",
    "        gradient_magnitude = abs(slope_channel)\n",
    "        r_squared = np.corrcoef(distances_clean, elevations_clean)[0,1]**2\n",
    "        \n",
    "        slope_dict[ds_order] = gradient_magnitude\n",
    "        \n",
    "        # Create output directory\n",
    "        output_dir = os.path.join(working_directory, \"RiverMapping\", \"HydraulicGeometry\", river_name, \"Slope_regressions\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Plot 1: Channel map\n",
    "        fig1, ax1 = plt.subplots(figsize=(10, 8))\n",
    "        for i, (_, seg) in enumerate(reach_segments.iterrows()):\n",
    "            ax1.plot(*seg.geometry.xy, 'b-', linewidth=2, alpha=0.5)\n",
    "        \n",
    "        clean_indices = np.where(~is_outlier)[0]\n",
    "        for idx_val in clean_indices:\n",
    "            pt = sample_points[idx_val]\n",
    "            pt_num = sample_numbers_array[idx_val]\n",
    "            ax1.plot(pt.x, pt.y, 'go', markersize=6, zorder=5)\n",
    "            ax1.text(pt.x, pt.y, f' {pt_num}', fontsize=7, ha='left', va='bottom',\n",
    "                    bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.7))\n",
    "        \n",
    "        ax1.set_title(f'{river_name} - Reach {ds_order}: Sample Points', fontsize=12, fontweight='bold')\n",
    "        ax1.set_xlabel('Longitude')\n",
    "        ax1.set_ylabel('Latitude')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{river_name}_reach{ds_order}_map.png'), dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot 2: Elevation profile\n",
    "        fig2, ax2 = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        for i, (dist, elev, num) in enumerate(zip(distances_array, elevations_array, sample_numbers_array)):\n",
    "            if is_outlier[i]:\n",
    "                ax2.plot(dist, elev, 'rx', markersize=10, markeredgewidth=2, zorder=6)\n",
    "            else:\n",
    "                ax2.plot(dist, elev, 'bo', markersize=8, zorder=5)\n",
    "                ax2.text(dist, elev, f' {num}', fontsize=8, ha='left', va='bottom')\n",
    "        \n",
    "        fit_line = slope_channel * distances_clean + intercept\n",
    "        ax2.plot(distances_clean, fit_line, 'r-', linewidth=2.5, \n",
    "                label=f'Slope={slope_channel:.6f} (R²={r_squared:.3f})', zorder=4)\n",
    "        \n",
    "        ax2.set_title(f'{river_name} - Reach {ds_order}: Elevation Profile', fontsize=12, fontweight='bold')\n",
    "        ax2.set_xlabel('Distance along channel (m)')\n",
    "        ax2.set_ylabel('Elevation (m)')\n",
    "        ax2.legend(loc='best')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f'{river_name}_reach{ds_order}_profile.png'), dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    return slope_dict\n",
    "\n",
    "def load_based_model(working_directory):\n",
    "    model_path = os.path.join(working_directory, 'Gearon_etal_2024', 'based-api', 'based_us_sans_trampush_early_stopping_combat_overfitting.ubj')\n",
    "    \n",
    "    if not os.path.isfile(model_path):\n",
    "        raise FileNotFoundError(f\"BASED model file not found: {model_path}\")\n",
    "    \n",
    "    model = xgb.Booster()\n",
    "    model.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "def predict_depth_based(model, width, slope, discharge):\n",
    "    if width is None or slope is None or discharge is None:\n",
    "        return None\n",
    "    \n",
    "    if width <= 0 or discharge <= 0:\n",
    "        return None\n",
    "    \n",
    "    slope_abs = abs(slope)\n",
    "    if slope_abs == 0:\n",
    "        return None\n",
    "    \n",
    "    input_data = pd.DataFrame({\n",
    "        'width': [width],\n",
    "        'slope': [slope_abs],\n",
    "        'discharge': [discharge]\n",
    "    })\n",
    "    \n",
    "    dmatrix = xgb.DMatrix(input_data)\n",
    "    \n",
    "    try:\n",
    "        prediction = model.predict(dmatrix)\n",
    "        depth = float(prediction[0])\n",
    "        if depth <= 0:\n",
    "            return None\n",
    "        return depth\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def calculate_hydraulic_geom(river_name, continent_abr, working_directory):\n",
    "    print(f\"\\nProcessing {river_name}...\")\n",
    "    \n",
    "    reach_gdf = get_reach(river_name, working_directory)\n",
    "    gqbf_gdf = get_GQBF(river_name, reach_gdf, continent_abr, working_directory)\n",
    "    if gqbf_gdf is None or gqbf_gdf.empty:\n",
    "        print(f\"  ⚠ Warning: Could not extract valid GQBF mainstem for {river_name}\")\n",
    "        print(f\"     This may indicate an unusual network topology (e.g., upstream distributaries)\")\n",
    "        print(f\"     Skipping hydraulic geometry calculation for this river.\\n\")\n",
    "        return  \n",
    "    else:\n",
    "        print(\"We got the GQBF\")\n",
    "    slope_dict = get_slope(reach_gdf, gqbf_gdf, river_name, working_directory)\n",
    "    \n",
    "    try:\n",
    "        based_model = load_based_model(working_directory)\n",
    "    except:\n",
    "        based_model = None\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for _, reach in reach_gdf.iterrows():\n",
    "        ds_order = reach[\"ds_order\"]\n",
    "        reach_segments = gqbf_gdf[gqbf_gdf.intersects(reach.geometry)]\n",
    "\n",
    "        if not reach_segments.empty:\n",
    "            median_width = reach_segments[\"grwl_width\"].median()\n",
    "            median_qbf = reach_segments[\"qbf\"].median()\n",
    "            length = reach_segments[\"length\"].sum()\n",
    "        else:\n",
    "            median_width = median_qbf = length = None\n",
    "\n",
    "        slope = slope_dict.get(ds_order, None)\n",
    "        \n",
    "        depth = None\n",
    "        if based_model is not None:\n",
    "            depth = predict_depth_based(based_model, median_width, slope, median_qbf)\n",
    "\n",
    "        results.append({\n",
    "            \"ds_order\": ds_order,\n",
    "            \"median_width_m\": median_width,\n",
    "            \"median_qbf_m3s\": median_qbf,\n",
    "            \"length_m\": length,\n",
    "            \"slope\": slope,\n",
    "            \"BASED_depth_m\": depth\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    output_dir = os.path.join(working_directory, \"RiverMapping\", \"HydraulicGeometry\", river_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    output_csv_path = os.path.join(output_dir, f\"{river_name}_hydraulic_geometry.csv\")\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f\"  ✓ Completed: {output_csv_path}\")\n",
    "\n",
    "def process_hydraulic_geom_calculator(csv_file_path):\n",
    "    river_data = pd.read_csv(csv_file_path)\n",
    "\n",
    "    for index, row in river_data.iterrows():\n",
    "        river_name = row['river_name']\n",
    "        working_directory = row['working_directory']\n",
    "        continent_abbr = row['hydroatlas_zone']\n",
    "        \n",
    "        calculate_hydraulic_geom(river_name, continent_abbr, working_directory)\n",
    "    \n",
    "    print(\"\\n✓ All rivers processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9102d1e3",
   "metadata": {},
   "source": [
    "## Input RivMapper .csv path and run hydraulic geometry calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ed58fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Aladan_VerkhoyanskiyPerevoz...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Aladan_VerkhoyanskiyPerevoz\\Aladan_VerkhoyanskiyPerevoz_hydraulic_geometry.csv\n",
      "\n",
      "Processing Amazonas_Jatuarana...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Amazonas_Jatuarana\\Amazonas_Jatuarana_hydraulic_geometry.csv\n",
      "\n",
      "Processing Amur_Komsomolsk...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Amur_Komsomolsk\\Amur_Komsomolsk_hydraulic_geometry.csv\n",
      "\n",
      "Processing Benue_Umaisha...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Benue_Umaisha\\Benue_Umaisha_hydraulic_geometry.csv\n",
      "\n",
      "Processing BolshayaKet_Rodyonovka...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\BolshayaKet_Rodyonovka\\BolshayaKet_Rodyonovka_hydraulic_geometry.csv\n",
      "\n",
      "Processing Brahmaputra_Pasighat...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Brahmaputra_Pasighat\\Brahmaputra_Pasighat_hydraulic_geometry.csv\n",
      "\n",
      "Processing Chari_Bousso...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Chari_Bousso\\Chari_Bousso_hydraulic_geometry.csv\n",
      "\n",
      "Processing Chari_Guelengdeng...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Chari_Guelengdeng\\Chari_Guelengdeng_hydraulic_geometry.csv\n",
      "\n",
      "Processing Chari_Ndjamena...\n",
      "We got the GQBF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Chari_Ndjamena\\Chari_Ndjamena_hydraulic_geometry.csv\n",
      "\n",
      "Processing Chari_Sahr...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Chari_Sahr\\Chari_Sahr_hydraulic_geometry.csv\n",
      "\n",
      "Processing Fraser_Hope...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Fraser_Hope\\Fraser_Hope_hydraulic_geometry.csv\n",
      "\n",
      "Processing Gandak_Devghat...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Gandak_Devghat\\Gandak_Devghat_hydraulic_geometry.csv\n",
      "\n",
      "Processing Helmand_Kajaki...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Helmand_Kajaki\\Helmand_Kajaki_hydraulic_geometry.csv\n",
      "\n",
      "Processing Helmand_Malakhan...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Helmand_Malakhan\\Helmand_Malakhan_hydraulic_geometry.csv\n",
      "\n",
      "Processing Indus_Attock...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Indus_Attock\\Indus_Attock_hydraulic_geometry.csv\n",
      "\n",
      "Processing Irtysh_Bobrovsky...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Irtysh_Bobrovsky\\Irtysh_Bobrovsky_hydraulic_geometry.csv\n",
      "\n",
      "Processing Irtysh_Hanti-Mansisk...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Irtysh_Hanti-Mansisk\\Irtysh_Hanti-Mansisk_hydraulic_geometry.csv\n",
      "\n",
      "Processing Irtysh_Pavlodar...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Irtysh_Pavlodar\\Irtysh_Pavlodar_hydraulic_geometry.csv\n",
      "\n",
      "Processing Irtysh_Semiyarskoje...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Irtysh_Semiyarskoje\\Irtysh_Semiyarskoje_hydraulic_geometry.csv\n",
      "\n",
      "Processing Jutai_PortoSeguro...\n",
      "We got the GQBF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Jutai_PortoSeguro\\Jutai_PortoSeguro_hydraulic_geometry.csv\n",
      "\n",
      "Processing Kamchatka_Kozyrevsk...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Kamchatka_Kozyrevsk\\Kamchatka_Kozyrevsk_hydraulic_geometry.csv\n",
      "\n",
      "Processing Kan_Kansk...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Kan_Kansk\\Kan_Kansk_hydraulic_geometry.csv\n",
      "\n",
      "Processing MadreDeDios_CachuelaEsperanza...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\MadreDeDios_CachuelaEsperanza\\MadreDeDios_CachuelaEsperanza_hydraulic_geometry.csv\n",
      "\n",
      "Processing Magdalena_Calamar...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Magdalena_Calamar\\Magdalena_Calamar_hydraulic_geometry.csv\n",
      "\n",
      "Processing Magdalena_PuertoBerrio...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Magdalena_PuertoBerrio\\Magdalena_PuertoBerrio_hydraulic_geometry.csv\n",
      "\n",
      "Processing Manas_Mathanguri...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Manas_Mathanguri\\Manas_Mathanguri_hydraulic_geometry.csv\n",
      "\n",
      "Processing Mbam_Goura...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Mbam_Goura\\Mbam_Goura_hydraulic_geometry.csv\n",
      "\n",
      "Processing Mekong_Kratie...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Mekong_Kratie\\Mekong_Kratie_hydraulic_geometry.csv\n",
      "\n",
      "Processing Niger_Tossaye...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Niger_Tossaye\\Niger_Tossaye_hydraulic_geometry.csv\n",
      "\n",
      "Processing Ob_Barnaul...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Ob_Barnaul\\Ob_Barnaul_hydraulic_geometry.csv\n",
      "\n",
      "Processing Ob_Kolpashevo...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Ob_Kolpashevo\\Ob_Kolpashevo_hydraulic_geometry.csv\n",
      "\n",
      "Processing Ob_Mogochin...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Ob_Mogochin\\Ob_Mogochin_hydraulic_geometry.csv\n",
      "\n",
      "Processing Ob_Phominskoje...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Ob_Phominskoje\\Ob_Phominskoje_hydraulic_geometry.csv\n",
      "\n",
      "Processing Orinoco_CiudadBolivar...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Orinoco_CiudadBolivar\\Orinoco_CiudadBolivar_hydraulic_geometry.csv\n",
      "\n",
      "Processing Orinoco_Musinacio...\n",
      "We got the GQBF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Orinoco_Musinacio\\Orinoco_Musinacio_hydraulic_geometry.csv\n",
      "\n",
      "Processing Paraguay_Asuncion...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Paraguay_Asuncion\\Paraguay_Asuncion_hydraulic_geometry.csv\n",
      "\n",
      "Processing Paraguay_PortoMurtinho...\n",
      "We got the GQBF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Paraguay_PortoMurtinho\\Paraguay_PortoMurtinho_hydraulic_geometry.csv\n",
      "\n",
      "Processing Parana_Chapeton...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Parana_Chapeton\\Parana_Chapeton_hydraulic_geometry.csv\n",
      "\n",
      "Processing Porcupine_NearFortYukon...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Porcupine_NearFortYukon\\Porcupine_NearFortYukon_hydraulic_geometry.csv\n",
      "\n",
      "Processing Sangha_Ouesso...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Sangha_Ouesso\\Sangha_Ouesso_hydraulic_geometry.csv\n",
      "\n",
      "Processing Solimoes_Itapeua...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Solimoes_Itapeua\\Solimoes_Itapeua_hydraulic_geometry.csv\n",
      "\n",
      "Processing Solimoes_Manacapuru...\n",
      "We got the GQBF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Solimoes_Manacapuru\\Solimoes_Manacapuru_hydraulic_geometry.csv\n",
      "\n",
      "Processing SonghuaJiang_Haerbin...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\SonghuaJiang_Haerbin\\SonghuaJiang_Haerbin_hydraulic_geometry.csv\n",
      "\n",
      "Processing Vilyuy_KhatyrykKhoma...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Vilyuy_KhatyrykKhoma\\Vilyuy_KhatyrykKhoma_hydraulic_geometry.csv\n",
      "\n",
      "Processing Yangtze_Datong...\n",
      "We got the GQBF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\huckr\\miniconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Yangtze_Datong\\Yangtze_Datong_hydraulic_geometry.csv\n",
      "\n",
      "Processing Yellowstone_NearSidney...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Yellowstone_NearSidney\\Yellowstone_NearSidney_hydraulic_geometry.csv\n",
      "\n",
      "Processing Yukon_Eagle...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Yukon_Eagle\\Yukon_Eagle_hydraulic_geometry.csv\n",
      "\n",
      "Processing Zambezi_LukuluMission...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Zambezi_LukuluMission\\Zambezi_LukuluMission_hydraulic_geometry.csv\n",
      "\n",
      "Processing Zambezi_Matundo-Cais...\n",
      "We got the GQBF\n",
      "  ✓ Completed: E:\\Dissertation\\Data\\RiverMapping\\HydraulicGeometry\\Zambezi_Matundo-Cais\\Zambezi_Matundo-Cais_hydraulic_geometry.csv\n",
      "\n",
      "✓ All rivers processed successfully!\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = r\"E:\\Dissertation\\Data\\Zhaoetal2025_river_datasheet.csv\"\n",
    "process_hydraulic_geom_calculator(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1181c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
