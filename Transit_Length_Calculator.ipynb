{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8122f6",
   "metadata": {},
   "source": [
    "# Transit length (xtran) calculator\n",
    "\n",
    "The following code combines hydraulic geometry, WBMsed sediment flux data, floodplain reworking timescales (TR), and river length geometries (produced in RivMapper and drawn from HydroAtlas) to calculate the characteristic transit lengths (xtran) for each reach within a given river system. The equation is a sediment budget calculation that balances the incoming bed material flux with the volumetric rate of sediment accretion onto the floodplain.\n",
    "\n",
    "The transit length, or length scale, (xtran, sometimes denoted as Ls) equation is a well-documented method for estimating sediment transit distances, and is used in:\n",
    "Torres, M.A., Limaye, A.B., Ganti, V., Lamb, M.P., West, A.J., Fischer, W.W., 2017. Model predictions of long-lived storage of organic carbon in river deposits. Earth Surface Dynamics 5, 711–730. https://doi.org/10.5194/esurf-5-711-2017\n",
    "\n",
    "Pizzuto, J., Schenk, E.R., Hupp, C.R., Gellis, A., Noe, G., Williamson, E., Karwan, D.L., O’Neal, M., Marquard, J., Aalto, R., Newbold, D., 2014. Characteristic length scales and time-averaged transport velocities of suspended sediment in the mid-Atlantic Region, USA. Water Resources Research 50, 790–805. https://doi.org/10.1002/2013WR014485\n",
    "\n",
    "WBMsed dataset: \n",
    "Cohen, S., Syvitski, J., Ashley, T., Lammers, R., Fekete, B., Li, H.-Y., 2022. Spatial Trends and Drivers of Bedload and Suspended Sediment Fluxes in Global Rivers. Water Resources Research 58, e2021WR031583. https://doi.org/10.1029/2021WR031583\n",
    "\n",
    "HydroATLAS: \n",
    "Linke, S., Lehner, B., Ouellet Dallaire, C., Ariwi, J., Grill, G., Anand, M., Beames, P., Burchard-Levine, V., Maxwell, S., Moidu, H., Tan, F., Thieme, M., 2019. Global hydro-environmental sub-basin and river reach characteristics at high spatial resolution. Sci Data 6, 283. https://doi.org/10.1038/s41597-019-0300-6\n",
    "\n",
    "Author: James (Huck) Rees; PhD Student, UCSB Geography\n",
    "\n",
    "Date: April 9, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be4744d",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6f6622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pyproj import CRS\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5e0565",
   "metadata": {},
   "source": [
    "## Initialize functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a075462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_reach_length(working_directory: str, river_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the real reach lengths from a shapefile containing river reach geometries.\n",
    "\n",
    "    Parameters:\n",
    "        working_directory (str): Base path to the data directory.\n",
    "        river_name (str): Name of the river used to locate the shapefile.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with reach lengths in meters.\n",
    "    \"\"\"\n",
    "    # Construct the path to the shapefile\n",
    "    shapefile_path = os.path.join(\n",
    "        working_directory, \"HydroATLAS\", \"HydroRIVERS\", \"Extracted_Rivers\", river_name, f\"{river_name}_reaches.shp\"\n",
    "    )\n",
    "\n",
    "    # Load shapefile using geopandas\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "    # Print the Coordinate Reference System (CRS)\n",
    "    print(\"Original CRS:\", gdf.crs)\n",
    "\n",
    "    # Convert to WGS84 (lat/lon) for UTM zone determination\n",
    "    gdf_wgs84 = gdf.to_crs(epsg=4326)\n",
    "\n",
    "    # Calculate UTM zone from centroid longitude\n",
    "    centroid = gdf_wgs84.geometry.unary_union.centroid\n",
    "    lon = centroid.x\n",
    "    utm_zone = int((lon + 180) / 6) + 1\n",
    "    epsg_code = 32600 + utm_zone if centroid.y >= 0 else 32700 + utm_zone\n",
    "\n",
    "    print(\"Reprojecting to: EPSG:\", epsg_code)\n",
    "\n",
    "    # Reproject to appropriate UTM zone\n",
    "    gdf = gdf.to_crs(epsg=epsg_code)\n",
    "\n",
    "    # Compute length of each reach in meters and add as new column\n",
    "    gdf[\"real_reach_length_m\"] = gdf.geometry.length\n",
    "\n",
    "    # Return DataFrame with geometry removed, showing lengths\n",
    "    return gdf.drop(columns=[\"geometry\", \"reach_len\", \"ds_dist\"])\n",
    "\n",
    "def calculate_xtran(\n",
    "    working_directory: str,\n",
    "    river_name: str,\n",
    "    real_reach_lengths: pd.DataFrame,\n",
    "    bulk_density: float\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate cross-channel translation distances (x_tran) for each reach.\n",
    "\n",
    "    Parameters:\n",
    "        working_directory (str): Base path to the data directory.\n",
    "        river_name (str): Name of the river.\n",
    "        real_reach_lengths (pd.DataFrame): DataFrame containing real reach lengths.\n",
    "        bulk_density (float): Bulk density of sediment in kg/m^3.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with x_tran and n_stor values for each reach.\n",
    "    \"\"\"\n",
    "    # Construct the path to the hydraulic geometry CSV\n",
    "    hg_path = os.path.join(\n",
    "        working_directory, \"RiverMapping\", \"HydraulicGeometry\", river_name, f\"{river_name}_hydraulic_geometry.csv\"\n",
    "    )\n",
    "\n",
    "    # Load hydraulic geometry data\n",
    "    hydraulic_geometry = pd.read_csv(hg_path)\n",
    "    hydraulic_geometry = hydraulic_geometry.rename(columns={\"length_m\": \"GQBF_reach_length_m\"})\n",
    "\n",
    "    # Construct the path to the translation rate values CSV\n",
    "    tr_directory = os.path.join(\n",
    "        working_directory, \"RiverMapping\", \"Mobility\", river_name, \"TR_Distributions\"\n",
    "    )\n",
    "    \n",
    "    tr_csv_files = glob.glob(os.path.join(tr_directory, \"Reach_*TR_i.csv\"))\n",
    "    pattern = r\"Reach_(\\d+)_TR_i\\.csv\"\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for file_path in tr_csv_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = re.match(pattern, filename)\n",
    "        if not match:\n",
    "            continue\n",
    "        \n",
    "        ds_order = int(match.group(1))\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        if 'TR_i' not in df.columns:\n",
    "            raise ValueError(f\"File '{filename}' does not contain 'TR_i' column\")\n",
    "        \n",
    "        median_tr = df['TR_i'].median()\n",
    "        results.append({\"ds_order\": ds_order, \"TR_i\": median_tr})\n",
    "\n",
    "    # Load translation rate values\n",
    "    tr_vals = pd.DataFrame(results)\n",
    "\n",
    "    # Construct the path to the WBMsed data CSV\n",
    "    wbmsed_path = os.path.join(\n",
    "        working_directory, \"WBMsed\", \"Extracted_Rivers\", f\"{river_name}_wbmsed.csv\"\n",
    "    )\n",
    "\n",
    "    # Load WBMsed data\n",
    "    wbmsed = pd.read_csv(wbmsed_path)\n",
    "\n",
    "    # Merge all DataFrames on 'ds_order'\n",
    "    merged_df = real_reach_lengths.merge(hydraulic_geometry, on=\"ds_order\")\n",
    "    merged_df = merged_df.merge(tr_vals, on=\"ds_order\")\n",
    "    merged_df = merged_df.merge(wbmsed, on=\"ds_order\")\n",
    "\n",
    "    # Convert sediment flux from kg/s to m^3/year using bulk density\n",
    "    seconds_per_year = 365.25 * 24 * 60 * 60\n",
    "    merged_df['sediment_flux_m3_yr'] = (\n",
    "        (merged_df['mean_BedloadFlux_kg_s'] + merged_df['mean_SuspendedBedFlux_kg_s']) * seconds_per_year / bulk_density\n",
    "    )\n",
    "\n",
    "    # Compute x_tran in meters using sediment balance equation:\n",
    "    # sediment_flux_m3_yr = x_tran * depth * width / TR\n",
    "    # => x_tran = sediment_flux_m3_yr * TR / (depth * width)\n",
    "    merged_df['x_tran_m'] = (\n",
    "        merged_df['sediment_flux_m3_yr'] * merged_df['TR_i'] /\n",
    "        (merged_df['depth_for_calcs_m'] * merged_df['median_width_m'])\n",
    "    )\n",
    "\n",
    "    # Compute n_stor as real_reach_length / x_tran\n",
    "    merged_df['n_stor'] = merged_df['real_reach_length_m'] / merged_df['x_tran_m']\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def process_transit_lengths(csv_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Wrapper function to calculate x_tran values and save them to CSV.\n",
    "\n",
    "    Parameters:\n",
    "        working_directory (str): Base path to the data directory.\n",
    "        river_name (str): Name of the river.\n",
    "        real_reach_lengths (pd.DataFrame): DataFrame containing real reach lengths.\n",
    "        bulk_density (float): Bulk density of sediment in kg/m^3.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file containing input variables for multiple rivers\n",
    "    river_data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Loop through each row (each river) in the CSV\n",
    "    for index, row in river_data.iterrows():\n",
    "        # Extract necessary input values from the current CSV row\n",
    "        river_name = row['river_name']  # Name of the river\n",
    "        working_directory = row['working_directory']  # Directory for processing\n",
    "        bulk_density = row['sediment_bulkdensity_kg_m3'] # Sediment bulk density in kg per cubic meter\n",
    "    \n",
    "        # Calculate real reach lengths\n",
    "        real_reach_lengths = get_real_reach_length(working_directory, river_name)\n",
    "    \n",
    "        # Run function to calculate transit lengths\n",
    "        output_df = calculate_xtran(working_directory, river_name, real_reach_lengths, bulk_density)\n",
    "\n",
    "        # Construct output path\n",
    "        output_path = os.path.join(\n",
    "            working_directory, \"RiverMapping\", \"Mobility\", river_name, f\"{river_name}_transit_lengths.csv\"\n",
    "        )\n",
    "\n",
    "        # Ensure directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        # Write to CSV\n",
    "        output_df.to_csv(output_path, index=False)\n",
    "        print(f\"Transit data saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4452ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the path to the translation rate values CSV\n",
    "tr_directory = os.path.join(\n",
    "    r\"C:\\Users\\huckr\\Desktop\\UCSB\\Dissertation\\Data\", \"RiverMapping\", \"Mobility\", \"Beni\", \"TR_Distributions\"\n",
    ")\n",
    "    \n",
    "tr_csv_files = glob.glob(os.path.join(tr_directory, \"Reach_*TR_i.csv\"))\n",
    "pattern = r\"Reach_(\\d+)_TR_i\\.csv\"\n",
    "    \n",
    "results = []\n",
    "\n",
    "for file_path in tr_csv_files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    match = re.match(pattern, filename)\n",
    "    if not match:\n",
    "        continue\n",
    "        \n",
    "    ds_order = int(match.group(1))\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    if 'TR_i' not in df.columns:\n",
    "        raise ValueError(f\"File '{filename}' does not contain 'TR_i' column\")\n",
    "        \n",
    "    median_tr = df['TR_i'].max()\n",
    "    results.append({\"ds_order\": ds_order, \"TR_i\": median_tr})\n",
    "\n",
    "# Load translation rate values\n",
    "tr_vals = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca59912",
   "metadata": {},
   "source": [
    "## Process transit lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9eb7939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original CRS: EPSG:3395\n",
      "Reprojecting to: EPSG: 32719\n",
      "Transit data saved to: C:\\Users\\huckr\\Desktop\\UCSB\\Dissertation\\Data\\RiverMapping\\Mobility\\Beni\\Beni_transit_lengths.csv\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = r\"C:\\Users\\huckr\\Desktop\\UCSB\\Dissertation\\Data\\RiverMapping\\Beni_river_datasheet.csv\"\n",
    "process_transit_lengths(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511eea61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
